{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Gantry","text":"<p>A Python DICOM Object Model and Redaction Toolkit.</p> <p></p> <p>Gantry provides a high-performance, object-oriented interface for managing, analyzing, and de-identifying DICOM datasets. It is designed for large-scale ingestion, precise pixel redaction, and strict PHI compliance.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Object-Oriented API: Work with <code>Patient</code>, <code>Study</code>, <code>Series</code>, and <code>Instance</code> objects directly.</li> <li>Persistent Sessions: All metadata is indexed in a SQLite database, allowing you to pause/resume large jobs and providing an audit trail.</li> <li>Parallel Processing: Multi-process ingestion and export for maximum throughput.</li> <li>Robust Redaction:</li> <li>Metadata: Configurable tag removal, replacement, and shifting.</li> <li>Pixel Data: Machine-specific redaction zones (ROI) to scrub burned-in PHI.</li> <li>Reversibility: Optional cryptographic identity preservation.</li> <li>Codecs: Robust support for JPEG Lossless, JPEG 2000, and other compressed formats via <code>imagecodecs</code>.</li> <li>Free-threaded Python Ready: Fully compatible with Python 3.13t+ (no-GIL) for true parallelism.</li> <li>Deep Memory Management: Automatic pixel offloading allows processing datasets far exceeding available RAM.</li> </ul>"},{"location":"analytics/","title":"Analytics &amp; Reporting","text":"<p>Gantry is designed not just for de-identification, but for understanding your data. It includes built-in tools for compliance verification, cohort analysis, and data exploration.</p>"},{"location":"analytics/#compliance-reports","title":"Compliance Reports","text":"<p>For regulatory audits (HIPAA/GDPR), Gantry can generate a formal Compliance Report. This single-document artifact summarizes the entire session, ensuring transparent documentation of your de-identification process.</p> <pre><code># Generate a Markdown report\nsession.generate_report(\"compliance_report.md\")\n</code></pre> <p>The report includes:</p> <ol> <li>Validation Status: Uses Gantry's internal audit logic to grade the session (PASS / REVIEW_REQUIRED).</li> <li>Audit Trail: Aggregated counts of actions taken (e.g., number of patients anonymized, pixels redacted).</li> <li>Exceptions: A detailed list of any warnings or errors encountered (e.g., \"Corrupt pixel data in File X\", \"Burned-In Annotation found\").</li> <li>Manifest: A summary of the processed cohort (Top studies by size).</li> </ol> <p>Format Options</p> <p>Currently, Gantry supports Markdown (<code>.md</code>) reports. PDF support is planned for future releases via Pandoc integration.</p>"},{"location":"analytics/#cohort-analysis-eda","title":"Cohort Analysis (EDA)","text":"<p>Gantry treats your DICOM data as a structured database, not just a pile of files. You can leverage the <code>export_dataframe</code> method to extract a flattened inventory of your cohort for analysis with Pandas, Jupyter, or Tableau.</p>"},{"location":"analytics/#1-export-to-pandas","title":"1. Export to Pandas","text":"<pre><code># Export inventory to a Pandas DataFrame\n# expand_metadata=True parses the JSON attributes into columns\ndf = session.export_dataframe(expand_metadata=True)\n\n# Inspect the data\nprint(df.head())\nprint(df.groupby('Modality')['InstanceCount'].sum())\n</code></pre>"},{"location":"analytics/#2-parquet-export","title":"2. Parquet Export","text":"<p>For massive datasets (100k+ images), exporting to Parquet is recommended for performance and compatibility with external BI tools (PowerBI, Tableau, Apache Spark).</p> <pre><code># Export full cohort to Parquet\nsession.export_to_parquet(\"cohort_inventory.parquet\")\n</code></pre>"},{"location":"analytics/#query-based-export","title":"Query-Based Export","text":"<p>One of Gantry's most powerful features is Query-Based Export. Instead of exporting the entire session, you can filter the export using Pandas-style queries or a subset DataFrame.</p>"},{"location":"analytics/#use-case-export-only-thick-slice-cts","title":"Use Case: \"Export only thick-slice CTs\"","text":"<pre><code># 1. Get the inventory\ndf = session.export_dataframe(expand_metadata=True)\n\n# 2. Define your criteria (Standard Pandas syntax)\n# e.g., Keep only CT scans with SliceThickness &gt; 2.5mm\nsubset = df[ \n    (df['Modality'] == 'CT') &amp; \n    (df['SliceThickness'].astype(float) &gt; 2.5) \n]\n\nprint(f\"Filtering: {len(df)} -&gt; {len(subset)} instances.\")\n\n# 3. Feed the subset back into the exporter\nsession.export(\"export_thick_cts\", subset=subset)\n</code></pre>"},{"location":"analytics/#use-case-export-list-of-accession-numbers","title":"Use Case: \"Export List of Accession Numbers\"","text":"<p>You can also filter by a list of strict identifiers if you have an external manifest.</p> <pre><code># Filter by Series Instance UIDs\ntarget_series = [\"1.2.840...\", \"1.2.840...\"]\n\n# Filter the dataframe\nsubset = df[df['SeriesInstanceUID'].isin(target_series)]\n\nsession.export(\"export_selected_series\", subset=subset)\n</code></pre>"},{"location":"architecture/","title":"Architecture","text":"<p>Gantry acts as a smart indexing layer over your raw DICOM files. It does not modify your original data. Instead, it builds a lightweight metadata index (SQLite) and exposes a clean Python Object Model for manipulation.</p>"},{"location":"architecture/#1-the-session-facade","title":"1. The Session Facade","text":"<p>The <code>Session</code> object is your single entry point. It manages:</p> <ul> <li>Persistence: Auto-saving state to <code>gantry.db</code>.</li> <li>Inventory: Tracking Patients, Studies, and Series.</li> <li>Transactions: Atomic persistence of changes.</li> </ul>"},{"location":"architecture/#2-object-model","title":"2. Object Model","text":"<p>Gantry abstracts DICOM into a semantic hierarchy, removing the pain of manual tag iteration.</p> <pre><code>graph LR\n    Patient --&gt; Study\n    Study --&gt; Series\n    Series --&gt; Instance\n    Instance --&gt; Pixels((Pixel Data))</code></pre> <ul> <li>Patient: Root entity (Name, ID).</li> <li>Study: A distinct visit/exam.</li> <li>Series: A scan or reconstruction (e.g., \"ct_soft_kernel\").</li> <li>Instance: A single DICOM slice. Pixel data is extracted upfront; the heavyweight pixel array is sequestered in a binary sidecar immediately upon ingestion and loaded into memory only when needed.</li> </ul>"},{"location":"architecture/#3-safety-pipeline-the-8-checkpoints","title":"3. Safety Pipeline (The 8 Checkpoints)","text":"<p>Gantry enforces a strict checkpoint system to ensure data safety:</p> <ol> <li>Ingest: Load raw data into the managed session index.</li> <li>Examine: Inventory the cohort and equipment.</li> <li>Configure: Define privacy tags and redaction rules.</li> <li>Audit (Target): Measure PHI risks against the configuration.</li> <li>Backup: (Optional) Securely lock original identities for reversibility.</li> <li>Anonymize: Apply remediation to metadata (in-memory).</li> <li>Redact: Scrub pixel data for specific machines (in-memory).</li> <li>Verify: Re-audit the session to ensure a clean state.</li> <li>Export: Write clean DICOM files to disk.</li> </ol>"},{"location":"architecture/#4-persistence-architecture-hybrid-storage","title":"4. Persistence Architecture (Hybrid Storage)","text":"<p>Gantry uses <code>sqlite3</code> for metadata management, employing a Hybrid Storage Model to balance query performance with schema flexibility.</p>"},{"location":"architecture/#the-problem","title":"The Problem","text":"<p>DICOM data effectively comes in two shapes:</p> <ol> <li>Standard Tags: Always present, well-defined (e.g., <code>Modality</code>, <code>StudyDate</code>).</li> <li>Private Tags: Manufacturer-specific, sparse, and extremely numerous.</li> </ol> <p>Storing everything in a single table with 3000 columns is impossible. Storing everything in a vertical Entity-Attribute-Value (EAV) table is too slow for bulk loading.</p>"},{"location":"architecture/#the-solution-core-json-vertical-split","title":"The Solution: Core JSON + Vertical Split","text":"<p>Values are automatically split during persistence based on their Group ID:</p> Storage Location Table Column Content Rationale Core Attributes <code>instances</code> <code>attributes_json</code> All Standard Tags (Even Groups) + Binary Placeholders Speed. SQLite's JSONB operators allow us to load 10,000 instances in sub-second time without performing 10,000+ joins. Vertical Attributes <code>instance_attributes</code> <code>tag_group</code>, <code>tag_elem</code>, <code>value</code> Private Tags (Odd Groups) Flexibility. Private tags are sparse. This EAV storage prevents the Core JSON from becoming bloated with garbage data while keeping private tags queryable. Pixel Data <code>[name]_pixels.bin</code> Comparison to DB via Offset/Length Raw Byte Stream Offloading. Gigabytes of pixel data are kept out of the DB to prevent bloating and ensure the index remains lightweight."},{"location":"architecture/#database-schema-reference","title":"Database Schema Reference","text":"Table Purpose Key Columns <code>patients</code> Root entity. <code>patient_id</code> (PK), <code>patient_name</code> <code>studies</code> Represents a patient visit. <code>study_instance_uid</code> (PK), <code>study_date</code>, <code>patient_id_fk</code> <code>series</code> Represents a scan/sequence. <code>series_instance_uid</code> (PK), <code>modality</code>, <code>manufacturer</code>, <code>model_name</code>, <code>device_serial_number</code>, <code>study_id_fk</code> <code>instances</code> Represents a single DICOM file. <code>sop_instance_uid</code> (PK), <code>attributes_json</code>, <code>pixel_hash</code>, <code>file_path</code>, <code>series_id_fk</code> <code>instance_attributes</code> Storage for Private/Odd Group tags. <code>instance_uid</code> (FK), <code>group_id</code>, <code>element_id</code>, <code>value</code> <code>audit_log</code> Logs all modification actions. <code>timestamp</code>, <code>action_type</code>, <code>entity_uid</code>, <code>details</code> <code>phi_findings</code> Stores potential PHI detected during audit. <code>entity_uid</code>, <code>field_name</code>, <code>value</code>, <code>remediation_action</code>"},{"location":"architecture/#schema-visualization","title":"Schema Visualization","text":"<pre><code>erDiagram\n    PATIENTS ||--|{ STUDIES : contains\n    STUDIES ||--|{ SERIES : contains\n    SERIES ||--|{ INSTANCES : contains\n\n    PATIENTS {\n        string patient_id PK\n        string patient_name\n    }\n\n    STUDIES {\n        string study_instance_uid PK\n        date study_date\n    }\n\n    SERIES {\n        string series_instance_uid PK\n        string modality\n        string manufacturer\n        string model_name\n    }\n\n    INSTANCES {\n        string sop_instance_uid PK\n        json attributes_json \"Core Metadata\"\n        string pixel_hash \"Integrity Check\"\n    }\n\n    INSTANCES ||--o{ INSTANCE_ATTRIBUTES : \"owns private tags\"\n    INSTANCE_ATTRIBUTES {\n        string instance_uid FK\n        hex group_id\n        hex element_id\n        string value\n    }\n\n    INSTANCES ||--|| SIDECAR_FILE : \"references pixels\"\n    SIDECAR_FILE {\n        binary pixel_bytes\n    }\n\n    INSTANCES ||--o{ PHI_FINDINGS : \"triggers\"\n    PHI_FINDINGS {\n        string field_name\n        string value\n        string remediation\n    }\n\n    INSTANCES ||--o{ AUDIT_LOG : \"generates\"\n    AUDIT_LOG {\n        timestamp time\n        string action\n        string details\n    }</code></pre>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to the \"Gantry\" project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#060-2026-01-20","title":"[0.6.0] - 2026-01-20","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Hybrid Storage Model: Major refactor of the persistence layer to split metadata into Core Attributes (JSON) and Vertical Attributes (EAV Table). This allows Gantry to handle sparse private tags elegantly without bloating the main index, enabling unlimited private tag support.</li> <li>Sidecar Binary Offloading: Pixel data is now eagerly extracted to a parallel sidecar file (<code>_pixels.bin</code>) during ingestion. This drastically reduces the size of the SQLite index and ensures fast start-up times even for massive datasets.</li> <li>Configuration API 2.0:</li> <li>Introduced <code>gantry.configure()</code> / <code>session.create_config()</code> workflow.</li> <li>New <code>GantryConfiguration</code> class providing programmatic access to Rules, Redaction Zones, and PHI Tags.</li> <li>Automatic <code>version: 2.0</code> schema migration.</li> <li>Bytes Persistence: Full support for persisting raw <code>bytes</code> in metadata via the JSON Core layer, ensuring complex VRs (like <code>OB</code>/<code>OW</code>) survive round-trips correctly.</li> <li>Planar Configuration Support: Added native handling for <code>PlanarConfiguration=1</code> (RRRGGGBBB layout) in <code>SidecarPixelLoader</code>, fixing RGB corruption in some Ultrasound/Secondary Capture images.</li> <li>Deprecation Fix: Updated persistence to avoid deprecated SQLite date adapters for Python 3.12+.</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Database Schema: <code>gantry.db</code> now contains <code>instances</code> (horizontal) and <code>instance_attributes</code> (vertical) tables.</li> <li>API: <code>DicomSession.active_rules</code> is deprecated; use <code>DicomSession.configuration.rules</code> instead.</li> <li>API: <code>DicomSession.active_phi_tags</code> is deprecated; use <code>DicomSession.configuration.phi_tags</code> instead.</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Integrity Checks: Resolved a critical hash mismatch issue where updating pixels via <code>persist_pixel_data</code> failed to update the integrity hash.</li> <li>Config Scaffolding: Fixed a bug where the generated YAML config had commented-out keys due to header formatting issues.</li> <li>Shape Errors: Fixed <code>Unknown shape: (2,)</code> errors when loading minimal/flattened 1D pixel arrays; <code>set_pixel_data</code> now intelligently reshapes based on image metadata.</li> </ul>"},{"location":"changelog/#054-2026-01-14","title":"[0.5.4] - 2026-01-14","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Compliance Reporting: Added <code>session.generate_report()</code> to produce HIPAA/GDPR-ready Markdown reports containing:</li> <li>Cohort Manifest: Summary of processed studies.</li> <li>Audit Trail: Aggregated counts of all remediation actions.</li> <li>Exception Tracking: Detailed listing of warnings and errors.</li> <li>Safety Checks: Automated detection of high-risk tags (e.g., <code>BurnedInAnnotation=YES</code>).</li> <li>Safety: Added automatic validation failure in reports if \"Burned-In Annotation\" is detected without explicit handling.</li> </ul>"},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>Export Bug: Resolved issue where <code>DeviceSerialNumber</code> (0018,1000) was dropped during export, preventing machine detection in subsequent runs.</li> <li>UX: Suppressed excessive console output from <code>lock_identities</code> in interactive environments.</li> <li>Regression: Fixed <code>ingest</code> method visibility in <code>DicomSession</code>.</li> </ul>"},{"location":"changelog/#053-2026-01-13","title":"[0.5.3] - 2026-01-13","text":""},{"location":"changelog/#fixed_2","title":"Fixed","text":"<ul> <li>Free-Threaded Stability: Fixed a race condition in <code>PersistenceManager</code> during shutdown that caused data loss in no-GIL environments (Python 3.13t+).</li> <li>Export Reliability: Fixed a \"Pickling Error\" regression in <code>run_parallel</code> when using <code>maxtasksperchild</code> with memory leak mitigation.</li> <li>Export Safety: Enforced strict exception raising in export workers; failed decompression now correctly fails the export instead of failing silently.</li> <li>Testing: Resolved <code>MagicMock</code> serialization errors during tests ensuring test suite passes cleanly on all platforms.</li> <li>Debug Cleanup: Removed residual debug output from Sidecar pixel loading and Benchmark stress tests.</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Dependencies: Bumping version for maintenance release.</li> </ul>"},{"location":"changelog/#052-2026-01-08","title":"[0.5.2] - 2026-01-08","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>Free-Threaded Stability: Implemented Versioned Dirty Tracking in <code>DicomItem</code> to correctly handle concurrent modifications in no-GIL environments (Python 3.13t+).</li> <li>Memory Optimization: Implemented <code>Instance.unload_pixel_data()</code> and automatic pixel swapping to <code>_pixels.bin</code>. This allows the session to process datasets larger than available RAM by offloading modified pixels to disk.</li> <li>Global Export Parallelism: Export process now utilizes a global pool of workers across all patients, significantly improving throughput for datasets with many small studies.</li> <li>Async Audit Queue: Implemented an asynchronous queue for writing audit logs to SQLite, preventing database locking and contention during highly parallel operations.</li> <li>Redaction Progress UI: Consolidated multiple per-machine progress bars into a single, clean \"Redacting Rules\" indicator.</li> <li>Verbose Logging: Added <code>verbose</code> flag to Redaction Service methods to allow optional debugging of missing pixels/rules.</li> </ul>"},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>Removed Legacy Config: Dropped support for legacy list-based configuration files and internal list-parsing logic. Configuration must now be the standard Unified YAML format.</li> <li>Thread Tuning: Adjusted default parallel worker count to <code>1.5 * CPU_CORES</code> (previously <code>min(32, cpu+4)</code>).</li> <li>Warning Suppression: Redaction warnings (e.g., missing pixel data) are now suppressed by default to reduce console noise.</li> <li>Redaction Execution: Switched <code>redact()</code> to enforce threading (<code>force_threads=True</code>) to correctly handle in-memory state updates and avoid pickling errors with SQLite connections.</li> </ul>"},{"location":"changelog/#fixed_3","title":"Fixed","text":"<ul> <li>Persistence Race Condition: Fixed a critical race condition where modifications made during an asynchronous save operation were lost/overwritten.</li> <li>Memory Leak: Resolved memory accumulation in <code>lock_identities</code> by implementing batch chunking (<code>auto_persist_chunk_size</code>).</li> <li>Progress Reporting: Fixed broken/instant completion progress bars in <code>lock_identities</code>.</li> <li>Logging Regression: Fixed assertion failure in <code>test_full_logging_coverage</code> regarding suppressed log messages.</li> <li>NameError: Fixed a variable scoping issue in <code>RedactionService.process_machine_rules</code>.</li> <li>Parallel Redaction Bugs: Resolved <code>pickle</code> errors and state synchronization issues in parallel redaction by enforcing threading.</li> </ul>"},{"location":"changelog/#051-2025-12-31","title":"[0.5.1] - 2025-12-31","text":""},{"location":"changelog/#added_3","title":"Added","text":"<ul> <li>Python 3.13t+ Support: Full compatibility with Free-threaded Python (no-GIL).</li> <li>Benchmarks: Documented performance achieving ~770k instances/sec for metadata operations.</li> <li>Migration Tools: Added <code>gantry.utils.ctp_parser</code> to convert legacy CTP scripts to Gantry YAML.</li> </ul>"},{"location":"changelog/#changed_3","title":"Changed","text":"<ul> <li>Dependencies: Merged <code>[images]</code> extra into core install. Gantry now installs <code>pillow</code> and <code>imagecodecs</code> by default.</li> <li>Documentation: Complete rewrite of <code>README.md</code> to reflect v2.0 Architecture.</li> </ul>"},{"location":"changelog/#fixed_4","title":"Fixed","text":"<ul> <li>Decompression: Robust support for encapsulated Multi-Frame images and JPEG Lossless (Process 14) via <code>imagecodecs</code>.</li> <li>Robustness: Implemented automatic fallback to installed codecs if standard <code>pydicom</code> handler discovery fails (e.g. environment path issues).</li> <li>Handling: Fixed <code>UnboundLocalError</code> regressions in error reporting.</li> <li>Correctness: Fixed bug where encapsulated pixel data was passed incorrectly to decoders.</li> </ul>"},{"location":"changelog/#050-2025-12-18","title":"[0.5.0] - 2025-12-18","text":""},{"location":"changelog/#added_4","title":"Added","text":"<ul> <li>Performance:</li> <li>Split-Persistence: Introduced a binary sidecar (<code>_pixels.bin</code>) for high-speed append-only pixel storage, reducing SQLite metadata size by 99%+.</li> <li>Database Indexing: Added indexes to Foreign Keys (<code>patient_id_fk</code>, etc.) and <code>audit_log</code> for O(1) query performance.</li> <li>Multithreaded Redaction: <code>redact_pixels</code> now uses <code>ThreadPoolExecutor</code> to process Machine Rules in parallel, achieving near-linear speedup on multi-core systems.</li> <li>Optimization:</li> <li>Inverted Redaction Loop: Refactored logic to iterate images once per machine (O(M)) instead of applying every rule to every image (O(NM)).</li> <li>Empty Zone Skipping: Automatically skips processing machines with no configured ROIs.</li> <li>Benchmarks:</li> <li>Verified throughput of 140,000 metadata inserts/sec and 580 MB/s pixel writes in stress tests.</li> <li>UX:</li> <li>Added realtime <code>tqdm</code> progress bars for redaction.</li> </ul>"},{"location":"changelog/#fixed_5","title":"Fixed","text":"<ul> <li>Multiprocessing: Fixed \"Pickling Error\" on Windows/spawn start methods by creating lightweight copies of the object graph for worker communication.</li> <li>Redaction: Fixed crash when <code>get_pixel_data</code> returns <code>None</code> (missing file).</li> <li>Redaction: Fixed \"Completely Outside\" warning logic for RGB images (interpreting Channels as Columns).</li> </ul>"},{"location":"changelog/#041-2025-12-12","title":"[0.4.1] - 2025-12-12","text":""},{"location":"changelog/#added_5","title":"Added","text":"<ul> <li>Configuration Actions: Support for <code>REMOVE</code> and <code>EMPTY</code> actions in <code>privacy_config.json</code> for precise tag handling.</li> <li>Ingest Summary: <code>ingest</code> command now provides a detailed count of imported objects.</li> </ul>"},{"location":"changelog/#fixed_6","title":"Fixed","text":"<ul> <li>Persistence Priority: Fixed \"Split Brain\" issue where remediated <code>Study</code>/<code>Series</code> metadata was overwritten by original file attributes during export.</li> <li>Export Error: Fixed validation strictness to allow export of files with stripped Command Set (Group 0000) tags.</li> <li>API Consistency: Unified <code>scan_for_phi</code> and <code>audit</code> methods.</li> </ul>"},{"location":"changelog/#040-2025-12-11","title":"[0.4.0] - 2025-12-11","text":""},{"location":"changelog/#added_6","title":"Added","text":"<ul> <li>Features:</li> <li>Safe Export: New <code>export(safe=True)</code> mode ensuring no PHI leaves the system.</li> <li>Reversible Anonymization: Securely embed encrypted original identities (<code>gantry.key</code>).</li> <li>Manual Persistence: Changed default behavior to manual <code>.save()</code> for better user control.</li> <li>Background Persistence: Non-blocking saves via <code>PersistenceManager</code>.</li> <li>PHI Analysis Reports: <code>scan_for_phi</code> now returns a rich <code>PhiReport</code> object with Pandas DataFrame support.</li> <li>Parallel Processing: Multi-process support for Import and PHI Scanning.</li> <li>Improvements:</li> <li>Console Output: Suppressed noisy <code>pydicom</code> warnings and improved <code>tqdm</code> progress bars.</li> <li>Batch UX: Better feedback during long-running operations.</li> <li>Test Coverage: specific tests for <code>crypto</code>, <code>config</code>, and <code>safe_export</code>.</li> </ul>"},{"location":"changelog/#fixed_7","title":"Fixed","text":"<ul> <li>Regression: Addressed silent failure in pixel export when source files are missing.</li> <li>Bug: Fixed <code>TypeError</code> in Remediation Date Shifting.</li> <li>Bug: Fixed <code>MultiValue</code> JSON serialization error in persistence.</li> <li>Bug: Fixed <code>ValueError</code> regarding Group 0000 elements during export.</li> </ul>"},{"location":"changelog/#030-2025-12-11","title":"[0.3.0] - 2025-12-11","text":""},{"location":"changelog/#added_7","title":"Added","text":"<ul> <li>Robust Persistence (SQLite): Replaced <code>Pickle</code> with <code>SQLite</code> for session storage (<code>gantry.db</code>). Allows for scale and external querying.</li> <li>Audit Trail: Implemented a comprehensive audit system. Actions such as <code>Redaction</code> and <code>Remediation</code> are now logged to the <code>audit_log</code> table in the database.</li> <li>Automated PHI Remediation:</li> <li>Metadata Anonymization: Automatically detects and anonymizes Patient Names and IDs.</li> <li>Deterministic Date Shifting: Shifts study dates by a consistent offset (based on Patient ID hash) to preserve temporal relationships while obscuring actual dates.</li> <li><code>apply_remediation</code> API: Added top-level API to <code>DicomSession</code> to easily apply fixes found by the privacy inspector.</li> <li>Documentation: Significant updates to <code>README.md</code> and architecture documentation.</li> </ul>"},{"location":"changelog/#changed_4","title":"Changed","text":"<ul> <li>Breaking Change: The internal persistence format has changed from <code>.pkl</code> to <code>.db</code>. Existing sessions from v0.2.0 cannot be loaded and must be re-imported.</li> <li>Dependency Update: Added <code>sqlite3</code> (stdlib) as a core dependency for the store backend.</li> </ul>"},{"location":"changelog/#020-2025-12-10","title":"[0.2.0] - 2025-12-10","text":""},{"location":"changelog/#added_8","title":"Added","text":"<ul> <li>JSON Configuration Validation: <code>ConfigLoader</code> now rejects rules with missing fields or invalid/illegal ROI definitions.</li> <li>ROI Safety Checks: Redaction operations now explicitly check image bounds, clipping ROIs to the image dimensions and warning if they are completely out of bounds.</li> <li>File Deduplication: <code>DicomImporter</code> now detects and skips files that have already been imported into the current session.</li> </ul>"},{"location":"changelog/#fixed_8","title":"Fixed","text":"<ul> <li>Recursive Sequence Import: Nested sequences (e.g., in Structured Reports) are now correctly recursed and indexed.</li> <li>Pixel Depth Export: <code>DicomExporter</code> now correctly preserves 8-bit usage for relevant modalities (e.g., US, SC) instead of hardcoding 12/16-bit depth.</li> </ul>"},{"location":"changelog/#010-2025-12-09","title":"[0.1.0] - 2025-12-09","text":""},{"location":"changelog/#added_9","title":"Added","text":"<ul> <li>Core Architecture: Implemented the semantic object graph (<code>Patient</code> \u2192 <code>Study</code> \u2192 <code>Series</code> \u2192 <code>Instance</code>) to replace flat dictionary handling.</li> <li>Facade Interface: Added <code>gantry.Session</code> class as the primary entry point for user interaction, managing imports, persistence, and inventory.</li> <li>Lazy Loading: Implemented a Proxy Pattern for <code>Instance</code> objects. Metadata is loaded into memory during import, while heavy pixel data is read from disk only upon request.</li> <li>De-Identification Service: Added <code>RedactionService</code> to modify pixel data (burn-in removal) based on specific machine serial numbers.</li> <li>Configuration Management: Added support for <code>redaction_rules.json</code> to define Redaction Regions of Interest (ROIs) externally.</li> <li>Machine Indexing: Created <code>MachinePixelIndex</code> to efficiently group and retrieve instances by their Equipment attributes (Manufacturer, Model, Serial Number).</li> <li>Builder Pattern: Added <code>DicomBuilder</code> (and fluent sub-builders) to allow programmatic construction of complex DICOM hierarchies for testing and synthetic data generation.</li> <li>IOD Validation: Implemented <code>IODValidator</code> to enforce Type 1 and Type 2 attribute compliance for standard SOP Classes (e.g., CT Image Storage) before export.</li> <li>Persistence: Added <code>pickle</code>-based serialization to save and resume session state (<code>DicomStore</code>).</li> <li>Import/Export: Created <code>DicomImporter</code> for fast metadata scanning and <code>DicomExporter</code> for writing valid, standards-compliant <code>.dcm</code> files.</li> </ul>"},{"location":"changelog/#security","title":"Security","text":"<ul> <li>Pixel data redaction is performed in-memory and committed to new files; original files are treated as read-only during the session to prevent accidental data loss.</li> </ul>"},{"location":"configuration/","title":"Configuration Guide","text":"<p>Gantry uses a Unified YAML Configuration (v2.0) to control all aspects of de-identification, including PHI tag rules, date shifting, and pixel redaction.</p> <p>This file allows you to define a reproducible privacy policy that can be shared across your team or version controlled.</p>"},{"location":"configuration/#quick-reference","title":"Quick Reference","text":"Section Description privacy_profile Base set of rules (e.g., \"basic\", \"comprehensive\"). date_jitter Randomly shifts dates to preserve intervals while hiding exact dates. remove_private_tags Removes vendor-specific private tags (odd groups). phi_tags overrides or adds specific tag rules (e.g., <code>PatientName</code>). machines Defines burn-in redaction zones for specific equipment."},{"location":"configuration/#complete-example","title":"Complete Example","text":"<p>Save this as <code>gantry_config.yaml</code>:</p> <pre><code># 1. Privacy Profile (Base Rules)\n# Options: \"basic\", \"comprehensive\", or path to external YAML\nprivacy_profile: \"basic\"\n\n# 2. Date Jitter\n# Shifts all dates by a random amount within this range.\n# The shift is deterministic per-patient (consistent across studies).\ndate_jitter:\n  min_days: -30\n  max_days: -10\n\n# 3. Private Tags\n# Remove all odd-group tags (vendor specific) unless whitelisted?\nremove_private_tags: true\n\n# 4. Custom PHI Tags (Overrides Profile)\nphi_tags:\n  \"0010,0010\": \n    action: \"REMOVE\"\n    name: \"PatientName\"\n\n  \"0010,0020\": \n    action: \"REPLACE\"\n    name: \"PatientID\"\n    value: \"ANONYMIZED\" # Matches default if omitted\n\n  \"0008,0080\":\n    action: \"KEEP\" # Exception: Keep InstitutionName\n\n# 5. Pixel Redaction Rules (Machine Specific)\nmachines:\n  - serial_number: \"US-12345\"\n    model_name: \"Voluson E10\"\n    redaction_zones:\n      # [row_start, row_end, col_start, col_end]\n      - [0, 50, 0, 800]   # Top Banner\n      - [900, 1024, 0, 400] # Bottom Left Details\n</code></pre>"},{"location":"configuration/#detailed-options","title":"Detailed Options","text":""},{"location":"configuration/#1-privacy-profile","title":"1. Privacy Profile","text":"<p>Sets the baseline behavior for thousands of DICOM tags.</p> <pre><code>privacy_profile: \"comprehensive\"\n</code></pre> <ul> <li><code>basic</code>: Implements the DICOM PS3.15 Annex E Basic Profile. Retains some descriptors but removes direct identifiers.</li> <li><code>comprehensive</code>: Aggressive de-identification. Removes almost all non-structural text fields.</li> <li>External File: You can provide a path to another YAML file (e.g., <code>./profiles/my_hospital_standard.yaml</code>) to inherit its rules.</li> </ul>"},{"location":"configuration/#2-date-jitter","title":"2. Date Jitter","text":"<p>Shifts all date attributes (<code>DA</code>, <code>DT</code>) by a random number of days.</p> <ul> <li>Logic: Gantry generates a secret random offset for each <code>PatientID</code>. This offset is consistent for that patient across all their studies and series, preserving temporal relationships (intervals) while hiding the absolute dates.</li> <li> <p>Config:</p> <pre><code>date_jitter:\n  min_days: -10\n  max_days: 10\n</code></pre> </li> </ul>"},{"location":"configuration/#3-private-tags","title":"3. Private Tags","text":"<p>DICOM Private Tags (Odd Group Numbers, e.g., <code>0009,xxxx</code>) often contain hidden PHI strings dumped by the machine.</p> <pre><code>remove_private_tags: true\n</code></pre> <ul> <li><code>true</code>: Removes ALL private tags. (Recommended for safety).</li> <li><code>false</code>: Retains them (Use only if you are sure they are safe or strictly needed for analysis).</li> </ul>"},{"location":"configuration/#4-phi-tags","title":"4. PHI Tags","text":"<p>Define specific rules for individual DICOM tags. Keys must be uppercase hex strings (e.g. <code>\"0010,0010\"</code>).</p> <p>Supported Actions:</p> Action Logic Example Config <code>REPLACE</code> Replaces value with \"ANONYMIZED\" (or custom string). <code>action: \"REPLACE\", value: \"Project-X\"</code> <code>REMOVE</code> Completely deletes the tag from the dataset. <code>action: \"REMOVE\"</code> <code>EMPTY</code> Sets the tag value to an empty string. <code>action: \"EMPTY\"</code> <code>SHIFT</code> Applies the per-patient Date Jitter offset (Dates only). <code>action: \"SHIFT\"</code> <code>KEEP</code> Explicitly retains the original value (Exception to profile). <code>action: \"KEEP\"</code> <p>Example:</p> <pre><code>phi_tags:\n  \"0008,1030\": { \"action\": \"EMPTY\", \"name\": \"StudyDescription\" }\n  \"0010,0030\": { \"action\": \"SHIFT\", \"name\": \"PatientBirthDate\" }\n</code></pre>"},{"location":"configuration/#5-pixel-redaction-machines","title":"5. Pixel Redaction (Machines)","text":"<p>Automatically scrubs burned-in text (pixels) for specific devices. Gantry identifies the machine using the <code>DeviceSerialNumber</code> (0018,1000) tag.</p> <pre><code>machines:\n  - serial_number: \"SN-9999\"\n    model_name: \"Documentation Only\"\n    redaction_zones:\n      - [0, 100, 0, 500]\n</code></pre> <ul> <li><code>serial_number</code> (Required): Exact match for <code>0018,1000</code>.</li> <li><code>redaction_zones</code>: List of regions to zero out.</li> <li>Format: <code>[y1, y2, x1, x2]</code> (Row Start, Row End, Col Start, Col End).</li> <li>Coordinates are 0-indexed.</li> </ul>"},{"location":"configuration/#6-programmatic-configuration-api-20","title":"6. Programmatic Configuration (API 2.0)","text":"<p>In addition to YAML files, you can manage the configuration dynamically using Python code via the <code>session.configuration</code> property.</p>"},{"location":"configuration/#accessing-configuration","title":"Accessing Configuration","text":"<pre><code>import gantry\n\nsession = gantry.Session(data_directory=\"./dicom_data\")\n\n# improved: Access the GantryConfiguration object directly\nconfig = session.configuration\n\nprint(config.rules)    # List active redaction rules\nprint(config.phi_tags) # List active PHI tag overrides\n</code></pre>"},{"location":"configuration/#methods","title":"Methods","text":""},{"location":"configuration/#add_ruleserial_number-manufacturerunknown-modelunknown-zonesnone","title":"<code>add_rule(serial_number, manufacturer=\"Unknown\", model=\"Unknown\", zones=None)</code>","text":"<p>Add a new machine redaction rule dynamically.</p> <pre><code># Add a rule for a specific ultrasound machine\nsession.configuration.add_rule(\n    serial_number=\"US-5555\",\n    manufacturer=\"GE\",\n    model=\"Voluson\",\n    zones=[[0, 50, 0, 800]] # [y1, y2, x1, x2]\n)\n</code></pre>"},{"location":"configuration/#delete_ruleserial_number","title":"<code>delete_rule(serial_number)</code>","text":"<p>Remove a rule by serial number.</p> <pre><code>session.configuration.delete_rule(\"US-5555\")\n</code></pre>"},{"location":"configuration/#set_phi_tagtag-action-replacementnone","title":"<code>set_phi_tag(tag, action, replacement=None)</code>","text":"<p>Update the policy for a specific DICOM tag.</p> <pre><code># Force removal of PatientWeight\nsession.configuration.set_phi_tag(\"0010,1030\", \"REMOVE\")\n\n# Replace StudyDescription with a constant\nsession.configuration.set_phi_tag(\"0008,1030\", \"REPLACE\", replacement=\"RESEARCH STUDY\")\n</code></pre>"},{"location":"configuration/#generating-configuration-templates","title":"Generating Configuration Templates","text":"<p>You can generate a starter <code>gantry_config.yaml</code> based on your current session inventory. This is useful for bootstrapping a new configuration file that includes all detected machines.</p> <pre><code># Inspects data, finds all unique machine serials, and writes a config file\nsession.create_config(\"my_new_policy.yaml\")\n</code></pre>"},{"location":"configuration/#7-environment-variables","title":"7. Environment Variables","text":"<p>You can tune the system performance and behavior using environment variables. These can be set in your shell or in a <code>.env</code> file in the project root.</p> Variable Default Description <code>GANTRY_LOG_LEVEL</code> <code>DEBUG</code> Logging verbosity (<code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>). <code>GANTRY_DB_PATH</code> <code>gantry.db</code> Path to the SQLite session database. <code>GANTRY_MAX_WORKERS</code> Auto Override the number of parallel worker processes. Default is <code>CPU_COUNT * 1.5</code>. <code>GANTRY_CHUNKSIZE</code> <code>1</code> Batch size for inter-process communication. Increasing this (e.g. to 5 or 10) can improve performance for very small items. <code>GANTRY_MAX_TASKS_PER_CHILD</code> Unlimited Restart worker processes after N tasks to release memory. Useful if you suspect memory leaks in underlying libraries. <code>GANTRY_DISABLE_GC</code> <code>0</code> Set to <code>1</code> to disable Garbage Collection in worker processes. This can speed up processing significantly but increases memory usage. <code>GANTRY_FORCE_THREADS</code> <code>0</code> Set to <code>1</code> to force using Threads instead of Processes (bypass multiprocessing). Useful for debugging or when running in environments that don't support <code>fork</code>. <code>GANTRY_SHOW_PROGRESS</code> <code>1</code> Set to <code>0</code> to globally disable all progress bars (tqdm). Useful for cleaner logs in CI/CD environments."},{"location":"installation/","title":"Installation","text":"<p>Gantry requires Python 3.9+.</p> <pre><code>pip install \"git+https://github.com/kvnlng/Gantry.git\"\n</code></pre> <p>Note</p> <p>The <code>imagecodecs</code> dependency is included and strongly recommended for handling JPEG Lossless and other compressed Transfer Syntaxes.</p>"},{"location":"installation/#system-requirements","title":"System Requirements","text":"<p>Gantry's parallel processing engine is designed to maximize CPU utilization. However, heavy operations like JPEG 2000 compression require significant memory per worker.</p> <ul> <li>Memory: Gantry is memory-intensive during specific operations (e.g., Pixel Redaction, J2K Export).</li> <li>Minimum: 2GB RAM per vCPU.</li> <li>Recommended (Heavy Workloads): 8GB RAM per vCPU (e.g., for massive multi-frame J2K compression).</li> <li>Concurrency: By default, Gantry uses all available cores (<code>1:1</code> ratio). Use <code>GANTRY_MAX_WORKERS</code> env var to limit this if OOM occurs.</li> </ul>"},{"location":"migration/","title":"Migration Tools","text":""},{"location":"migration/#clinical-trial-processor-ctp","title":"Clinical Trial Processor (CTP)","text":"<p>Gantry includes a utility to convert legacy CTP <code>DicomPixelAnonymizer.script</code> files into Gantry's YAML configuration format.</p> <pre><code># Convert CTP script to Gantry YAML\npython -m gantry.utils.ctp_parser /path/to/anonymizer.script output_rules.yaml\n</code></pre> <p>This parser extracts:</p> <ul> <li>Manufacturer/Model matching criteria.</li> <li>Redaction zones (automatically converting <code>x,y,w,h</code> to <code>r1,r2,c1,c2</code>).</li> </ul>"},{"location":"ocr/","title":"Intelligent Pixel Analysis (OCR)","text":"<p>Gantry includes a powerful Optical Character Recognition (OCR) engine designed to detect and verify burned-in text within DICOM pixel data. This feature moves beyond simple text detection, offering Intelligent Redaction Verification to validate your anonymization rules.</p>"},{"location":"ocr/#overview","title":"Overview","text":"<p>The OCR module uses Tesseract to scan pixel data for text. It allows you to:</p> <ol> <li>Audit your dataset for missed PHI (burned-in names, dates, etc.).</li> <li>Verify that your configured redaction zones actully cover the text present in the image.</li> <li>Auto-Remediate your configuration by suggesting new or expanded zones based on findings.</li> </ol>"},{"location":"ocr/#prerequisites","title":"Prerequisites","text":"<p>To use OCR features, you must have the Tesseract binary installed on your system:</p> macOSLinux (Ubuntu/Debian) <pre><code>brew install tesseract\n</code></pre> <pre><code>sudo apt-get install tesseract-ocr\n</code></pre>"},{"location":"ocr/#intelligent-verification","title":"Intelligent Verification","text":"<p>The core workflow is Verification. Instead of just finding all text (which includes safe text like anatomical labels), Gantry filters findings based on your Redaction Rules.</p>"},{"location":"ocr/#how-it-works","title":"How it Works","text":"<ol> <li>Match: Gantry identifies the Redaction Rule for each instance (matched by Serial Number).</li> <li>Scan: It detects all text regions in the image.</li> <li>Filter: It checks if each text region is covered by a configured <code>redaction_zone</code>.<ul> <li>Safe: Text &gt; 80% covered by a zone. (Ignored)</li> <li>Partial Leak: Text partially covered (0-80%). (Flagged)</li> <li>New Leak: Text completely uncovered. (Flagged)</li> </ul> </li> </ol>"},{"location":"ocr/#running-a-scan","title":"Running a Scan","text":"<p>To avoid scanning the entire cohort, Gantry scans only machines that are present in your configuration (<code>priv_config.yaml</code>). Unconfigured machines are skipped.</p> <p>You can also focus the scan on a single machine:</p> <pre><code>from gantry.session import DicomSession\n\nsession = DicomSession(\"my_project.db\")\nsession.ingest(\"dicom_data/\")\n\n# Run the intelligent scan (only configured machines)\nreport = session.scan_pixel_content()\n\n# OR: Focus on a specific serial number\nreport = session.scan_pixel_content(serial_number=\"SN-12345\")\n\nprint(f\"Found {len(report)} leaks.\")\nfor finding in report:\n    print(f\"{finding.metadata['leak_type']}: {finding.value} in {finding.entity_uid}\")\n</code></pre>"},{"location":"ocr/#setting-up-new-machines-zone-discovery","title":"Setting Up New Machines (Zone Discovery)","text":"<p>When you add a new machine to your configuration (Scaffolding), it typically has no redaction zones defined. Gantry will skip configured machines that have empty redaction zones to prevent noise.</p> <p>To find the initial zones:</p> <ol> <li> <p>Run Discovery:</p> <pre><code>zones = session.discover_redaction_zones(serial_number=\"SN-NEW\", sample_size=50)\nprint(f\"Suggested Zones: {zones}\")\n</code></pre> <p>This analyzes a sample of images to find \"hotspots\" of burned-in text.</p> </li> <li> <p>Update Configuration:     Add the suggested zones to your <code>priv_config.yaml</code>.</p> </li> <li> <p>Validate:     Run <code>session.scan_pixel_content(\"SN-NEW\")</code> to confirm that the leaks are now covered.</p> </li> </ol>"},{"location":"ocr/#automated-remediation","title":"Automated Remediation","text":"<p>Gantry can analyze the \"Partial\" and \"New\" leaks to suggest updates to your configuration file.</p>"},{"location":"ocr/#auto-remediation-workflow","title":"Auto-Remediation Workflow","text":"<pre><code># 1. Scan\nreport = session.scan_pixel_content()\n\n# 2. Apply Suggestions\n# This analyzes the report and updates the in-memory configuration\ncount = session.auto_remediate_config(report)\n\nif count &gt; 0:\n    print(f\"Applied {count} fixes.\")\n\n    # 3. Validation Scan (Optional)\n    # Re-run to confirm leaks are gone\n    report_v2 = session.scan_pixel_content()\n    assert len(report_v2) == 0\n\n    # 4. Save Config\n    session.configuration.save_config(\"updated_priv_config.yaml\")\n</code></pre>"},{"location":"ocr/#configuration-reference","title":"Configuration Reference","text":"<p>Your <code>priv_config.yaml</code> defines the zones used for verification.</p> <pre><code>machines:\n  - serial_number: \"SN-12345\"\n    model_name: \"CT-Scanner-X\"\n    redaction_zones:\n      # [x, y, width, height]\n      - [0, 0, 200, 100]       # Top-Left Info Box\n      - [400, 400, 100, 50]    # Bottom-Right Label\n</code></pre>"},{"location":"ocr/#api-reference","title":"API Reference","text":""},{"location":"ocr/#gantry.session.DicomSession.scan_pixel_content","title":"<code>gantry.session.DicomSession.scan_pixel_content(serial_number=None)</code>","text":"<p>Scans instances in the session for burned-in text using OCR.</p> <p>Performs \"Intelligent Verification\":. Only scans instances belonging to machines (Serial Numbers) that are present in the current configuration. Unconfigured machines are skipped.</p> <p>Parameters:</p> Name Type Description Default <code>serial_number</code> <code>str</code> <p>If provided, restricts the scan to ONLY                            machines with this serial number.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>PhiReport</code> <code>PhiReport</code> <p>A report containing findings of filtered (uncovered) burned-in text.</p> Source code in <code>gantry/session.py</code> <pre><code>def scan_pixel_content(self, serial_number: str = None) -&gt; \"PhiReport\":\n    \"\"\"\n    Scans instances in the session for burned-in text using OCR.\n\n    Performs \"Intelligent Verification\":.\n    Only scans instances belonging to machines (Serial Numbers) that are present\n    in the current configuration. Unconfigured machines are skipped.\n\n    Args:\n        serial_number (str, optional): If provided, restricts the scan to ONLY\n                                       machines with this serial number.\n\n    Returns:\n        PhiReport: A report containing findings of filtered (uncovered) burned-in text.\n    \"\"\"\n    get_logger().info(\"Scanning pixel content for text (OCR)...\")\n    print(\"Scanning pixel content for text (OCR)...\")\n\n    # Gather all instances with their equipment context\n    current_rules = self.configuration.rules\n\n    # Build set of valid serials from config\n    configured_serials = {r.get(\"serial_number\") for r in current_rules if r.get(\"serial_number\")}\n\n    worker_items = []\n    skipped_count = 0\n\n    for p in self.store.patients:\n        for st in p.studies:\n            for se in st.series:\n                equip = se.equipment\n                if not equip or not equip.device_serial_number:\n                    skipped_count += len(se.instances)\n                    continue\n\n                sn = equip.device_serial_number\n\n                # Filter 1: Must be in Config\n                # We check if we have a rule for this serial\n                matched_rule = None\n                for r in current_rules:\n                    if r.get(\"serial_number\") == sn:\n                        matched_rule = r\n                        break\n\n                if not matched_rule:\n                    skipped_count += len(se.instances)\n                    continue\n\n                # Rule Refinement: Skip if NO ZONES defined (Scaffolded state)\n                # Unless user explicitly wants to scan? No, user req says skip.\n                if not matched_rule.get(\"redaction_zones\"):\n                     # Log once per serial?\n                     # For now just skip\n                     skipped_count += len(se.instances)\n                     continue\n\n                # Filter 2: Explicit User Filter\n                if serial_number and sn != serial_number:\n                    continue\n\n                for inst in se.instances:\n                    worker_items.append((inst, equip, current_rules))\n\n    if not worker_items:\n        msg = \"No matching configured instances found to scan.\"\n        if skipped_count &gt; 0:\n            msg += f\" (Skipped {skipped_count} unconfigured instances)\"\n        print(msg)\n        return PhiReport([])\n\n    results = run_parallel(_verify_worker, worker_items, desc=\"OCR Verification\")\n\n    all_findings = []\n    for r in results:\n        all_findings.extend(r)\n\n    print(f\"OCR Scan Complete. Found {len(all_findings)} suspicious regions (Uncovered).\")\n    return PhiReport(all_findings)\n</code></pre>"},{"location":"ocr/#gantry.session.DicomSession.auto_remediate_config","title":"<code>gantry.session.DicomSession.auto_remediate_config(report)</code>","text":"<p>Analyzes the provided OCR report and automatically updates the session's configuration to fix detected leaks (by expanding zones or adding new ones).</p> <p>Parameters:</p> Name Type Description Default <code>report</code> <code>PhiReport</code> <p>The findings from .scan_pixel_content()</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of rules updated.</p> Source code in <code>gantry/session.py</code> <pre><code>def auto_remediate_config(self, report: \"PhiReport\") -&gt; int:\n    \"\"\"\n    Analyzes the provided OCR report and automatically updates the session's\n    configuration to fix detected leaks (by expanding zones or adding new ones).\n\n    Args:\n        report (PhiReport): The findings from .scan_pixel_content()\n\n    Returns:\n        int: The number of rules updated.\n    \"\"\"\n    get_logger().info(\"Analyzing report for auto-remediation...\")\n\n    suggestions = ConfigAutomator.suggest_config_updates(report, self.configuration)\n\n    if not suggestions:\n        print(\"No configuration updates suggested.\")\n        return 0\n\n    print(f\"Generated {len(suggestions)} suggestions for config updates.\")\n\n    count = ConfigAutomator.apply_suggestions(self, suggestions)\n\n    if count &gt; 0:\n        print(f\"Applied {count} updates to in-memory configuration.\")\n        print(\"Tip: Run .scan_pixel_content() again to verify fix, then .configuration.save_config() to persist.\")\n\n    return count\n\n    return count\n</code></pre>"},{"location":"performance/","title":"Performance","text":"<p>Gantry is designed for massive scale. Recent stress tests verify robust linear scaling on datasets up to 100GB.</p> <p></p>"},{"location":"performance/#100gb-scalability-test","title":"100GB Scalability Test","text":"<ul> <li>Input: 101,000 files (50GB Single-Frame + 50GB Multi-Frame).</li> <li>Import Speed: Uses Sidecar Generation to extract pixel data upfront, ensuring constant-time access during analysis.</li> <li>Export Speed: High-speed streaming write using cached sidecar data.</li> <li>Memory: Peaks at stable levels regardless of dataset size due to aggressive offloading.</li> </ul> <p>The architecture uses O(1) memory streaming, ensuring it never runs out of RAM even when processing terabytes of data.</p>"},{"location":"performance/#memory-management-architecture","title":"Memory Management Architecture","text":"<p>Gantry employs a \"Deep Memory Management\" strategy to handle large-scale datasets on consumer hardware.</p>"},{"location":"performance/#1-process-isolation-redaction","title":"1. Process Isolation (Redaction)","text":"<p>Pixel redaction is the most memory-intensive operation (loading 500MB+ arrays). Gantry uses Process Isolation (<code>ProcessPoolExecutor</code>) to execute these tasks.</p> <ul> <li>Each worker process loads the pixel data, applies redactions, and then exits.</li> <li>This guarantees that the operating system reclaims all memory resources immediately after each task, preventing fragmentation or reference leaks in the main process.</li> </ul>"},{"location":"performance/#2-streaming-ingest","title":"2. Streaming Ingest","text":"<p>The ingestion pipeline uses a streaming generator pattern with a <code>chunksize=1</code>.</p> <ul> <li>Files are processed one by one.</li> <li>Results are yielded immediately to the database.</li> <li>The IPC queue never buffers more than a single item, keeping memory footprint constant (O(1)) regardless of input size.</li> </ul>"},{"location":"performance/#3-zero-copy-persistence","title":"3. Zero-Copy Persistence","text":"<p>To prevent memory spikes during export:</p> <ul> <li>Pixel data is passed directly from NumPy arrays to the storage backend.</li> <li>We utilize buffer interfaces and on-the-fly <code>zlib</code> compression to avoid creating intermediate Python byte strings (which would double memory usage).</li> </ul>"},{"location":"performance/#scalability-benchmarks","title":"Scalability Benchmarks","text":"<p>Recent stress tests (January 2026) verified robust sub-linear scaling capabilities.</p> Phase Files Raw Data Max RSS (Memory) Status Scaling Factor Phase 0 1 ~500 MB ~0.5 GB Success 1x Phase 1 10 ~5 GB ~3.8 GB Success ~7.6x Phase 2 100 ~50 GB ~11.3 GB Success &lt;3x <p>Key Finding: Increasing the dataset size by 10x (10 to 100 files) only resulted in a 3x increase in peak memory usage. This demonstrates that Gantry effectively decouples memory consumption from dataset size.</p> <p>Timing results:</p> Phase Total Instances Ingest Duration Examine Duration Audit Duration Backup Duration Anonymize Duration Redact Duration Export Duration Total Time Phase 0 (1 Multi-Frame Files) 1 2.20 0.0001 0.0014 0.0061 0.0066 1.85 2.97 7.04 Phase 1 (10 Multi-Frame Files) 10 22.45 0.0001 0.0024 0.0060 0.0064 9.33 9.94 41.74 Phase 2 (100 Multi-Frame Files) 100 177.36 0.0002 0.0042 0.0124 0.0244 74.21 58.13 309.74 <p>Test machine: * machine-type: n2-highmem-16 * image-family: ubuntu-2204-lts * image-project: ubuntu-os-cloud * boot-disk-size: 1TB * boot-disk-type: pd-ssd</p>"},{"location":"performance/#micro-benchmarks-metadata-operations","title":"Micro-Benchmarks (Metadata Operations)","text":"Operation Scale Time (Mac M3 Max) Throughput Identity Locking 100,000 Instances ~0.13 s 769k / sec Persist Findings 100,000 Issues ~0.13 s 770k / sec"},{"location":"quickstart/","title":"Quick Start","text":""},{"location":"quickstart/#1-initialize-a-session","title":"1. Initialize a Session","text":"<p>Gantry uses a persistent session to manage your workflow. Unlike scripts that run once and forget, a Session creates a local SQLite database (<code>gantry.db</code>) to index your data. This allows you to pause, resume, and audit your work without re-scanning thousands of files.</p> <pre><code>from gantry import Session\n\n# Initialize a new session (creates 'gantry.db' by default)\nsession = Session(\"my_project.db\")\n</code></pre>"},{"location":"quickstart/#2-ingest-examine","title":"2. Ingest &amp; Examine","text":"<p>Ingestion builds a lightweight metadata index of your DICOM files. Gantry scans your folders recursively, extracting patient/study/series information into the database without moving or modifying your original files. It is resilient to nested directories and non-DICOM clutter.</p> <pre><code>session.ingest(\"/path/to/dicom/data\")\nsession.save() # Persist the index to disk\n\n# Print a summary of the cohort and equipment\nsession.examine()\n</code></pre>"},{"location":"quickstart/#3-configure-audit","title":"3. Configure &amp; Audit","text":"<p>Before changing anything, define your privacy rules. Use <code>create_config</code> to generate a scaffolding based on your inventory, then <code>audit</code> to scan that inventory against your rules. This \"Measure Twice, Cut Once\" approach lets you identify all PHI risks before applying any irreversible changes.</p> <pre><code># Create a default configuration file (v2.0 YAML)\nsession.create_config(\"config.yaml\")\n\n# Load the configuration (rules, tags, jitter)\nsession.load_config(\"config.yaml\")\n\n# Run an audit to find PHI\nreport = session.audit() \nsession.save_analysis(report)\n\nprint(f\"Found {len(report)} potential PHI issues.\")\n</code></pre>"},{"location":"quickstart/#4-backup-identity-optional","title":"4. Backup Identity (Optional)","text":"<p>To enable reversible anonymization, generate a cryptographic key and \"lock\" the original patient identities into a secure, encrypted DICOM tag. This must be done before anonymization.</p> <pre><code># Enable encryption (generates 'gantry.key')\nsession.enable_reversible_anonymization()\n\n# cryptographically lock identities for all patients found in the audit\n# cryptographically lock identities for all patients found in the audit\n# Optional: Specify custom tags to preserve (defaults to Name, ID, DOB, Sex, Accession)\nsession.lock_identities(report, tags_to_lock=[\"0010,0010\", \"0010,0020\", \"0010,0030\"])\nsession.save()\n</code></pre>"},{"location":"quickstart/#5-anonymize-redact-export","title":"5. Anonymize, Redact &amp; Export","text":"<p>Remediation is a multi-stage process performed in-memory:</p> <ol> <li>Anonymize: Strips or replaces metadata tags (PatientID, Names, Dates) based on your config.</li> <li>Redact: Loads pixel data and scrubs burned-in PHI from defined regions.</li> <li>Export: The final \"Gatekeeper\". Writes clean files to a new directory. Setting <code>safe=True</code> ensures the export halts if any verification checks fail (e.g., corrupt images or missing codecs).</li> </ol> <pre><code># Apply metadata remediation (anonymization) using the findings\nsession.anonymize(report)\n\n# Apply pixel redaction rules (requires config to be loaded)\nsession.redact()\n\n# Export only safe (clean) data to a new folder\n# Compression=\"j2k\" optionally compresses output to JPEG 2000\nsession.export(\"/path/to/export_clean\", safe=True, compression=\"j2k\")\n</code></pre> <p>Progress for the save, memory release, and export phases will be displayed:</p> <pre><code>Preparing for export (Auto-Save &amp; Memory Release)...\nReleasing Memory: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:02&lt;00:00, 2000.00img/s]\nMemory Cleanup: Released 5000 images from RAM.\nExecuting Redaction Rules...\nRedacting: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 150/150 [00:05&lt;00:00, 28.00img/s]\nExporting session to output_folder (safe=True)...\nExporting:  15%|\u2588\u2588\u258c       | 15/100 [00:05&lt;00:30,  2.80patient/s]\n</code></pre>"},{"location":"quickstart/#6-recover-identity-optional","title":"6. Recover Identity (Optional)","text":"<p>If you have a valid key (<code>gantry.key</code>) and need to retrieve the original identity of an anonymized patient:</p> <pre><code># Load the session containing anonymized data\nsession = Session(\"my_project.db\")\nsession.enable_reversible_anonymization(\"gantry.key\")\n\n# Recover the original PatientName and PatientID\n# Recover the original identity and restore attributes in-memory\n# restore=True (default) automatically updates all instances with original values\nsession.recover_patient_identity(\"ANON_12345\", restore=True)\n\n# Now, accessing p.patient_name or instance attributes returns original data\nprint(f\"Restored: {session.store.patients[0].patient_name}\")\n</code></pre>"},{"location":"roadmap/","title":"Project Roadmap","text":"<p>This document outlines the development plan for Gantry. We welcome contributions from the community to help us achieve these milestones!</p>"},{"location":"roadmap/#current-status-v060-architecture-analytics","title":"\ud83d\udccd Current Status: v0.6.0 (Architecture &amp; Analytics)","text":"<ul> <li>[x] Hybrid Persistence: Split-storage (JSON + Table) for unlimited private tags.</li> <li>[x] Unified Configuration: API-driven config management (<code>GantryConfiguration</code>).</li> <li>[x] Sidecar Offloading: Eager binary extraction for fast session loading.</li> <li>[x] Compliance Reporting: Generate reports verifying dataset compliance against a selected privacy profile.</li> <li>[x] Dataframe Export: Expose a method to flatten <code>Patient -&gt; Study -&gt; Series -&gt; Instance</code> hierarchy into a comprehensive parquet file.</li> <li>[x] Query-based Export: Export subsets of data based on metadata queries (e.g., \"Modality == 'CT'\").</li> <li>[x] Export Manifest: Automatic generation of visual (HTML) and machine-readable (CSV/JSON) manifests listing all exported files and their key metadata.</li> <li>[x] Structured Reporting (SR) Support: Support for deep parsing and anonymization of DICOM Structured Reports.</li> <li>[x] Legacy Config Removal: Streamlined codebase by removing list-based config support.</li> </ul>"},{"location":"roadmap/#upcoming-milestones","title":"\ud83d\ude80 Upcoming Milestones","text":""},{"location":"roadmap/#v070-the-connector-networking-refinement","title":"v0.7.0 - The Connector (Networking &amp; Refinement)","text":"<p>Focus: Integrating Gantry into clinical workflows and deepening analysis capabilities.</p> <ul> <li>[ ] PACS Integration: Implement C-STORE, C-FIND, C-MOVE using <code>pynetdicom</code> to query and pull studies directly.</li> <li>[ ] Research Export Formats: Native support for exporting to NIfTI and BIDS standards.</li> <li>[ ] Pixel Content Analysis (OCR): Detect burned-in text using OCR (Tesseract) / Cloud Vision to automatically flag sensitive images.</li> <li>[ ] Audit Reporting: Export comprehensive CSV reports of the session inventory, including details on what was redacted or modified.</li> <li>[x] Sidecar Compaction: Tool to rewrite sidecar file and reclaim space from redacted/deleted instances.</li> </ul>"},{"location":"roadmap/#v080-cloud-scale","title":"v0.8.0 - Cloud Scale","text":"<p>Focus: Native support for cloud storage to handle massive datasets.</p> <ul> <li>[ ] Persistence Abstraction: Decouple storage logic to enable cloud backends and future plugins.</li> <li>[ ] Cloud Storage Adapters: Native ingestion/export for S3, Google Cloud Storage, and Azure Blob.</li> </ul>"},{"location":"roadmap/#v100-production-release","title":"v1.0.0 - Production Release","text":"<ul> <li>[ ] API Freeze: Lock down the <code>DicomSession</code> interface.</li> <li>[ ] Documentation: Complete API reference and tutorials on ReadTheDocs or Wiki.</li> <li>[ ] PyPI Release: Publish package to the Python Package Index.</li> </ul>"},{"location":"roadmap/#v110-zero-code-cli","title":"v1.1.0 - Zero Code (CLI)","text":"<p>Focus: Making Gantry accessible to non-programmers and CI pipelines.</p> <ul> <li>[ ] Gantry CLI: A rich command-line interface for auditing and anonymizing datasets.</li> </ul>"},{"location":"roadmap/#future-ideas-backlog","title":"\ud83d\udd2e Future Ideas (Backlog)","text":"<ul> <li>3D Defacing: Algorithmically remove facial features from 3D volumes (MRI/CT).</li> <li>Plugin System: Hooks for custom user scripts during ingest/audit/export loops.</li> <li>GUI Wrapper for <code>DicomSession</code>.</li> <li>Official Docker Image: Optimized container build for Gantry with pre-configured codecs and dependencies.</li> </ul>"},{"location":"api/entities/","title":"Entities API","text":""},{"location":"api/entities/#gantry.entities","title":"<code>gantry.entities</code>","text":""},{"location":"api/entities/#gantry.entities.DicomItem","title":"<code>DicomItem</code>  <code>dataclass</code>","text":"<p>Base class for any entity that holds DICOM attributes and sequences.</p> <p>This class provides a dictionary-like interface for managing DICOM attributes and handles hierarchical dirty tracking for persistence.</p> <p>Attributes:</p> Name Type Description <code>attributes</code> <code>Dict[str, Any]</code> <p>A dictionary mapping generic DICOM tags to values.</p> <code>sequences</code> <code>Dict[str, DicomSequence]</code> <p>A dictionary mapping tags to nested DicomSequences.</p> Source code in <code>gantry/entities.py</code> <pre><code>@dataclass(slots=True)\nclass DicomItem:\n    \"\"\"\n    Base class for any entity that holds DICOM attributes and sequences.\n\n    This class provides a dictionary-like interface for managing DICOM attributes\n    and handles hierarchical dirty tracking for persistence.\n\n    Attributes:\n        attributes (Dict[str, Any]): A dictionary mapping generic DICOM tags to values.\n        sequences (Dict[str, DicomSequence]): A dictionary mapping tags to nested DicomSequences.\n    \"\"\"\n    # init=False to avoid constructor conflicts during inheritance\n    attributes: Dict[str, Any] = field(init=False)\n    sequences: Dict[str, DicomSequence] = field(init=False)\n\n    # Versioning for robust persistence\n    _mod_count: int = field(init=False, default=0)\n    _saved_mod_count: int = field(init=False, default=-1)\n\n    def __post_init__(self):\n        self.attributes = {}\n        self.sequences = {}\n        # Initial state is dirty (1 &gt; 0)\n        self._mod_count = 1\n        self._saved_mod_count = 0\n\n    @property\n    def _dirty(self) -&gt; bool:\n        return self._mod_count &gt; self._saved_mod_count\n\n    @_dirty.setter\n    def _dirty(self, value: bool):\n        # Legacy support: setting True increments version\n        if value:\n            self._mod_count += 1\n        else:\n            # Unsafe clear: assumes current state is saved\n            self._saved_mod_count = self._mod_count\n\n    def mark_saved(self, version_saved: int):\n        \"\"\"\n        Marks specific version as saved. Robust against concurrent edits.\n\n        Args:\n            version_saved (int): The modification count that was successfully persisted.\n        \"\"\"\n        if version_saved &gt; self._saved_mod_count:\n            self._saved_mod_count = version_saved\n\n    def set_attr(self, tag: str, value: Any):\n        \"\"\"\n        Sets a generic attribute by its hex tag (e.g., '0010,0010').\n\n        Args:\n            tag (str): The DICOM tag string.\n            value (Any): The value to set.\n        \"\"\"\n        self.attributes[tag] = value\n        self._mod_count += 1\n\n    def add_sequence_item(self, tag: str, item: 'DicomItem'):\n        \"\"\"\n        Appends a new item to a sequence, creating the sequence if needed.\n\n        Args:\n            tag (str): The DICOM tag for the sequence.\n            item (DicomItem): The item to append.\n        \"\"\"\n        if tag not in self.sequences:\n            self.sequences[tag] = DicomSequence(tag=tag)\n        self.sequences[tag].items.append(item)\n        self._mod_count += 1\n\n    def mark_clean(self):\n        \"\"\"Mark the entity and all its items as clean by syncing modification counts.\n\n        This is a legacy method that forces the entity to be marked as clean by\n        updating the saved modification count to match the current modification count.\n        Also recursively marks all items in all sequences as clean.\n        \"\"\"\n        # Legacy: force clean\n        self._saved_mod_count = self._mod_count\n        for seq in self.sequences.values():\n            for item in seq.items:\n                item.mark_clean()\n</code></pre>"},{"location":"api/entities/#gantry.entities.DicomItem.add_sequence_item","title":"<code>add_sequence_item(tag, item)</code>","text":"<p>Appends a new item to a sequence, creating the sequence if needed.</p> <p>Parameters:</p> Name Type Description Default <code>tag</code> <code>str</code> <p>The DICOM tag for the sequence.</p> required <code>item</code> <code>DicomItem</code> <p>The item to append.</p> required Source code in <code>gantry/entities.py</code> <pre><code>def add_sequence_item(self, tag: str, item: 'DicomItem'):\n    \"\"\"\n    Appends a new item to a sequence, creating the sequence if needed.\n\n    Args:\n        tag (str): The DICOM tag for the sequence.\n        item (DicomItem): The item to append.\n    \"\"\"\n    if tag not in self.sequences:\n        self.sequences[tag] = DicomSequence(tag=tag)\n    self.sequences[tag].items.append(item)\n    self._mod_count += 1\n</code></pre>"},{"location":"api/entities/#gantry.entities.DicomItem.mark_clean","title":"<code>mark_clean()</code>","text":"<p>Mark the entity and all its items as clean by syncing modification counts.</p> <p>This is a legacy method that forces the entity to be marked as clean by updating the saved modification count to match the current modification count. Also recursively marks all items in all sequences as clean.</p> Source code in <code>gantry/entities.py</code> <pre><code>def mark_clean(self):\n    \"\"\"Mark the entity and all its items as clean by syncing modification counts.\n\n    This is a legacy method that forces the entity to be marked as clean by\n    updating the saved modification count to match the current modification count.\n    Also recursively marks all items in all sequences as clean.\n    \"\"\"\n    # Legacy: force clean\n    self._saved_mod_count = self._mod_count\n    for seq in self.sequences.values():\n        for item in seq.items:\n            item.mark_clean()\n</code></pre>"},{"location":"api/entities/#gantry.entities.DicomItem.mark_saved","title":"<code>mark_saved(version_saved)</code>","text":"<p>Marks specific version as saved. Robust against concurrent edits.</p> <p>Parameters:</p> Name Type Description Default <code>version_saved</code> <code>int</code> <p>The modification count that was successfully persisted.</p> required Source code in <code>gantry/entities.py</code> <pre><code>def mark_saved(self, version_saved: int):\n    \"\"\"\n    Marks specific version as saved. Robust against concurrent edits.\n\n    Args:\n        version_saved (int): The modification count that was successfully persisted.\n    \"\"\"\n    if version_saved &gt; self._saved_mod_count:\n        self._saved_mod_count = version_saved\n</code></pre>"},{"location":"api/entities/#gantry.entities.DicomItem.set_attr","title":"<code>set_attr(tag, value)</code>","text":"<p>Sets a generic attribute by its hex tag (e.g., '0010,0010').</p> <p>Parameters:</p> Name Type Description Default <code>tag</code> <code>str</code> <p>The DICOM tag string.</p> required <code>value</code> <code>Any</code> <p>The value to set.</p> required Source code in <code>gantry/entities.py</code> <pre><code>def set_attr(self, tag: str, value: Any):\n    \"\"\"\n    Sets a generic attribute by its hex tag (e.g., '0010,0010').\n\n    Args:\n        tag (str): The DICOM tag string.\n        value (Any): The value to set.\n    \"\"\"\n    self.attributes[tag] = value\n    self._mod_count += 1\n</code></pre>"},{"location":"api/entities/#gantry.entities.DicomSequence","title":"<code>DicomSequence</code>  <code>dataclass</code>","text":"<p>Represents a DICOM Sequence (SQ) containing multiple DicomItems.</p> <p>Attributes:</p> Name Type Description <code>tag</code> <code>str</code> <p>The DICOM tag for this sequence (e.g., \"0008,1111\").</p> <code>items</code> <code>List[DicomItem]</code> <p>A list of DicomItem objects contained in this sequence.</p> Source code in <code>gantry/entities.py</code> <pre><code>@dataclass(slots=True)\nclass DicomSequence:\n    \"\"\"\n    Represents a DICOM Sequence (SQ) containing multiple DicomItems.\n\n    Attributes:\n        tag (str): The DICOM tag for this sequence (e.g., \"0008,1111\").\n        items (List[DicomItem]): A list of DicomItem objects contained in this sequence.\n    \"\"\"\n    tag: str\n    items: List['DicomItem'] = field(default_factory=list)\n</code></pre>"},{"location":"api/entities/#gantry.entities.Equipment","title":"<code>Equipment</code>  <code>dataclass</code>","text":"<p>Immutable Equipment definition. Frozen=True allows hashing, enabling unique set generation.</p> <p>Attributes:</p> Name Type Description <code>manufacturer</code> <code>str</code> <p>The manufacturer of the equipment.</p> <code>model_name</code> <code>str</code> <p>The model name of the equipment.</p> <code>device_serial_number</code> <code>str</code> <p>The serial number (optional).</p> Source code in <code>gantry/entities.py</code> <pre><code>@dataclass(frozen=True, slots=True)\nclass Equipment:\n    \"\"\"\n    Immutable Equipment definition.\n    Frozen=True allows hashing, enabling unique set generation.\n\n    Attributes:\n        manufacturer (str): The manufacturer of the equipment.\n        model_name (str): The model name of the equipment.\n        device_serial_number (str): The serial number (optional).\n    \"\"\"\n    manufacturer: str\n    model_name: str\n    device_serial_number: str = \"\"\n</code></pre>"},{"location":"api/entities/#gantry.entities.Instance","title":"<code>Instance</code>  <code>dataclass</code>","text":"<p>               Bases: <code>DicomItem</code></p> <p>Represents a single DICOM image (SOP Instance). Manages lazy loading of pixel data.</p> Source code in <code>gantry/entities.py</code> <pre><code>@dataclass(slots=True)\nclass Instance(DicomItem):\n    \"\"\"\n    Represents a single DICOM image (SOP Instance).\n    Manages lazy loading of pixel data.\n    \"\"\"\n    sop_instance_uid: str = \"\"\n    sop_class_uid: str = \"\"\n    instance_number: int = 0\n\n    # Persistence: Link to original file for lazy loading\n    file_path: Optional[str] = None\n\n    # Transient: Actual pixel data (NOT persisted to pickle)\n    pixel_array: Optional[np.ndarray] = field(default=None, repr=False)\n\n    # Transient: Lazy Loader (Callable that returns np.ndarray)\n    # Used for Sidecar or deferred logic\n    _pixel_loader: Optional[Callable[[], np.ndarray]] = field(default=None, repr=False)\n\n    # Transient: Hash for Integrity Check\n    _pixel_hash: Optional[str] = field(default=None, repr=False)\n\n    # Transient: Track if dates have been shifted in memory\n    date_shifted: bool = field(default=False, init=False)\n\n    # Transient: Index of all text-based nodes for O(1) PHI scanning\n    # List of (DicomItem_Reference, Tag_String)\n    text_index: List[Tuple['DicomItem', str]] = field(default_factory=list, init=False, repr=False)\n\n    def __post_init__(self):\n        # Inlined from DicomItem to avoid super() mismatch issues with slots/reloads\n        self.attributes = {}\n        self.sequences = {}\n\n        # Versioning\n        self._mod_count = 1\n        self._saved_mod_count = 0\n\n        self.set_attr(\"0008,0018\", self.sop_instance_uid)\n        self.set_attr(\"0008,0016\", self.sop_class_uid)\n        self.set_attr(\"0020,0013\", self.instance_number)\n\n    def regenerate_uid(self):\n        \"\"\"\n        Generates a new, globally unique SOP Instance UID.\n\n        Call this whenever pixel data is modified to ensure the instance is treated\n        as a new distinct entity, preventing collisions with the original data.\n\n        This method:\n            1. Generates a new SOP Instance UID.\n            2. Updates the internal object property.\n            3. Updates the '0008,0018' DICOM attribute.\n            4. Detaches the instance from its physical file path (since consistent hash changed).\n        \"\"\"\n        # 1. Generate new UID using pydicom's generator (or your org root)\n        new_uid = generate_uid()\n\n        # 2. Update the Object Property\n        self.sop_instance_uid = new_uid\n\n        # 3. Update the DICOM Attribute Dictionary\n        self.set_attr(\"0008,0018\", new_uid)\n\n        # 4. Detach from physical file\n        # Since this object is now a \"new\" instance in memory,\n        # it no longer matches the file on disk.\n        self.file_path = None\n\n        get_logger().debug(f\"  -&gt; Identity regenerated: {new_uid}\")\n\n    def unload_pixel_data(self) -&gt; bool:\n        \"\"\"\n        Clears the cached pixel_array from memory to free resources.\n\n        Only performs the clear if the data can be re-loaded (i.e., `file_path`\n        or `_pixel_loader` is present).\n\n        Returns:\n            bool: True if unloaded successfully,\n                 False if it was unsafe to unload (data would be lost).\n        \"\"\"\n        if self.pixel_array is None:\n            return True\n\n        if self.file_path or self._pixel_loader:\n            self.pixel_array = None\n            # print(f\"DEBUG: Unloaded pixels for {self.sop_instance_uid}\")\n            return True\n        else:\n            # Data is in memory only (e.g. modified but not saved)\n            print(f\"DEBUG: FAILED TO UNLOAD {self.sop_instance_uid} - No file path or loader!\")\n            return False\n\n    def get_pixel_data(self) -&gt; Optional[np.ndarray]:\n        \"\"\"\n        Returns pixel_array. Loads from disk if not in memory.\n\n        This method attempts to:\n            1. Return already cached `pixel_array`.\n            2. Use `_pixel_loader` (Sidecar) if available.\n            3. Read from `file_path` using `pydicom`.\n            4. Fallback to `gantry.imagecodecs_handler` if pydicom fails.\n\n        Returns:\n            Optional[np.ndarray]: The pixel data as a numpy array, or None if missing/load failed.\n\n        Raises:\n            RuntimeError: If loading fails due to transfer syntax issues or missing codecs.\n            FileNotFoundError: If the file path does not exist.\n        \"\"\"\n        if self.pixel_array is not None:\n            return self.pixel_array\n\n        if self._pixel_loader:\n            try:\n                # Invoke callback (e.g. sidecar read)\n                arr = self._pixel_loader()\n                # Use set_pixel_data to ensure attributes (rows, cols) are synced\n                # This is critical if the loader returns a raw array but\n                # attributes were not yet set/restored\n                self.set_pixel_data(arr)\n                return self.pixel_array\n            except Exception as e:\n                raise RuntimeError(f\"Pixel Loader failed for {self.sop_instance_uid}: {e}\") from e\n\n        if self.file_path and os.path.exists(self.file_path):\n            try:\n                # Read pixel data on demand\n                ds = None\n                try:\n                    ds = pydicom.dcmread(self.file_path)\n\n                    self.set_pixel_data(ds.pixel_array)  # Cache it in memory\n                    return self.pixel_array\n                except (AttributeError, TypeError):\n                    # No pixel data element\n                    return None\n                except Exception as e:\n                    if \"no pixel data\" in str(e).lower():\n                        return None\n                    # Re-raise to be handled by outer except\n                    raise e\n\n            except Exception as e:\n                # Try explicit fallback to gantry.imagecodecs_handler\n                # Pydicom sometimes fails to iterate handlers correctly or swallows errors.\n                try:\n                    if ds is not None and h.is_available() and h.supports_transfer_syntax(ds.file_meta.TransferSyntaxUID):\n                        arr = h.get_pixel_data(ds)\n                        self.set_pixel_data(arr)\n                        return self.pixel_array\n                except (ImportError, AttributeError, RuntimeError):\n                    # Fallback failed, proceed to raise original error\n                    pass\n\n                # Try to get Transfer Syntax UID for better debugging\n                ts_uid = \"Unknown\"\n                if ds is not None and hasattr(ds, \"file_meta\"):\n                    ts_uid = getattr(ds.file_meta, \"TransferSyntaxUID\", \"Unknown\")\n\n                if \"missing dependencies\" in str(e) or \"decompress\" in str(e):\n                    # Enhanced debug output\n                    handlers = []\n                    try:\n                        # pydicom is already imported globally\n                        handlers = [str(h) for h in pydicom.config.pixel_data_handlers]\n                    except Exception:\n                        pass\n\n                    raise RuntimeError(\n                        f\"Failed to decompress pixel data for {os.path.basename(self.file_path)} \"\n                        f\"(Transfer Syntax: {ts_uid}).\\n\"\n                        f\"Underlying Error: {e}\\n\"\n                        f\"Active pydicom handlers: {handlers}\\n\"\n                        \"Missing image codecs. Please ensure 'pillow', 'pylibjpeg', or 'gdcm' are installed.\"\n                    ) from e\n\n                # If we just caught the re-raised \"no pixel data\" exception, it would be handled above,\n                # but if dcmread fails completely or something else happens:\n                raise RuntimeError(f\"Lazy load failed for {self.file_path}: {e}\") from e\n\n        raise FileNotFoundError(f\"Pixels missing and file not found: {self.file_path}\")\n\n    def set_pixel_data(self, array: np.ndarray):\n        \"\"\"\n        Sets the pixel array and automatically updates metadata tags.\n\n        Updates tags:\n            - Rows (0028,0010)\n            - Columns (0028,0011)\n            - SamplesPerPixel (0028,0002)\n            - NumberOfFrames (0028,0008) (if &gt; 1)\n            - PhotometricInterpretation (0028,0004) (RGB if samples &gt;= 3)\n            - PlanarConfiguration (0028,0006) (0 if RGB)\n\n        Args:\n            array (np.ndarray): The pixel data to set. Can be 1D, 2D, 3D, or 4D.\n        \"\"\"\n        self.pixel_array = array\n        shape = array.shape\n        ndim = len(shape)\n\n        # Defaults\n        samples = 1\n        frames = 1\n\n        if ndim == 1:\n            # Flattened array (e.g. from Sidecar loader)\n            # Attempt to reshape using existing metadata if available\n            try:\n                r = int(self.attributes.get(\"0028,0010\", 0))\n                c = int(self.attributes.get(\"0028,0011\", 0))\n                s = int(self.attributes.get(\"0028,0002\", 1))\n                f = int(self.attributes.get(\"0028,0008\", 1))\n\n                expected_size = r * c * s * f\n                if expected_size &gt; 0 and array.size &gt;= expected_size:\n                    # Truncate padding if present (DICOM alignment)\n                    if array.size &gt; expected_size:\n                        array = array[:expected_size]\n\n                    # Reshape logic\n                    if f &gt; 1:\n                        array = array.reshape((f, r, c, s)) if s &gt; 1 else array.reshape((f, r, c))\n                    elif s &gt; 1:\n                        array = array.reshape((r, c, s))\n                    else:\n                        array = array.reshape((r, c))\n                    self.pixel_array = array\n                    return  # Done, attributes already match\n                elif expected_size == 0:\n                    # Metadata missing, treat as linear?\n                    pass\n\n            except ValueError:\n                pass\n\n            # Only raise if we couldn't resolve it\n            if len(array.shape) == 1:  # Still 1D\n                rows, cols = 1, shape[0]\n\n        elif ndim == 2:\n            rows, cols = shape\n        elif ndim == 3:\n            if shape[-1] in [3, 4]:\n                rows, cols, samples = shape\n            else:\n                frames, rows, cols = shape\n        elif ndim == 4:\n            frames, rows, cols, samples = shape\n        else:\n            raise ValueError(f\"Unknown shape: {shape}\")\n\n        self.set_attr(\"0028,0010\", rows)\n        self.set_attr(\"0028,0011\", cols)\n        self.set_attr(\"0028,0002\", samples)\n        if frames &gt; 1:\n            self.set_attr(\"0028,0008\", str(frames))\n        if samples &gt;= 3:\n            self.set_attr(\"0028,0004\", \"RGB\")\n            self.set_attr(\"0028,0006\", 0)  # Force Interleaved (standard numpy)\n        else:\n            # Preserve existing PhotometricInterpretation (e.g. MONOCHROME1)\n            # Only set default if missing\n            if not self.attributes.get(\"0028,0004\"):\n                self.set_attr(\"0028,0004\", \"MONOCHROME2\")\n\n        # Ensure BitsAllocated matches array data type\n        # SidecarPixelLoader relies on this to determine uint8 vs uint16\n        bits = array.itemsize * 8\n        self.set_attr(\"0028,0100\", bits)\n\n        self._mod_count += 1\n</code></pre>"},{"location":"api/entities/#gantry.entities.Instance.get_pixel_data","title":"<code>get_pixel_data()</code>","text":"<p>Returns pixel_array. Loads from disk if not in memory.</p> This method attempts to <ol> <li>Return already cached <code>pixel_array</code>.</li> <li>Use <code>_pixel_loader</code> (Sidecar) if available.</li> <li>Read from <code>file_path</code> using <code>pydicom</code>.</li> <li>Fallback to <code>gantry.imagecodecs_handler</code> if pydicom fails.</li> </ol> <p>Returns:</p> Type Description <code>Optional[ndarray]</code> <p>Optional[np.ndarray]: The pixel data as a numpy array, or None if missing/load failed.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If loading fails due to transfer syntax issues or missing codecs.</p> <code>FileNotFoundError</code> <p>If the file path does not exist.</p> Source code in <code>gantry/entities.py</code> <pre><code>def get_pixel_data(self) -&gt; Optional[np.ndarray]:\n    \"\"\"\n    Returns pixel_array. Loads from disk if not in memory.\n\n    This method attempts to:\n        1. Return already cached `pixel_array`.\n        2. Use `_pixel_loader` (Sidecar) if available.\n        3. Read from `file_path` using `pydicom`.\n        4. Fallback to `gantry.imagecodecs_handler` if pydicom fails.\n\n    Returns:\n        Optional[np.ndarray]: The pixel data as a numpy array, or None if missing/load failed.\n\n    Raises:\n        RuntimeError: If loading fails due to transfer syntax issues or missing codecs.\n        FileNotFoundError: If the file path does not exist.\n    \"\"\"\n    if self.pixel_array is not None:\n        return self.pixel_array\n\n    if self._pixel_loader:\n        try:\n            # Invoke callback (e.g. sidecar read)\n            arr = self._pixel_loader()\n            # Use set_pixel_data to ensure attributes (rows, cols) are synced\n            # This is critical if the loader returns a raw array but\n            # attributes were not yet set/restored\n            self.set_pixel_data(arr)\n            return self.pixel_array\n        except Exception as e:\n            raise RuntimeError(f\"Pixel Loader failed for {self.sop_instance_uid}: {e}\") from e\n\n    if self.file_path and os.path.exists(self.file_path):\n        try:\n            # Read pixel data on demand\n            ds = None\n            try:\n                ds = pydicom.dcmread(self.file_path)\n\n                self.set_pixel_data(ds.pixel_array)  # Cache it in memory\n                return self.pixel_array\n            except (AttributeError, TypeError):\n                # No pixel data element\n                return None\n            except Exception as e:\n                if \"no pixel data\" in str(e).lower():\n                    return None\n                # Re-raise to be handled by outer except\n                raise e\n\n        except Exception as e:\n            # Try explicit fallback to gantry.imagecodecs_handler\n            # Pydicom sometimes fails to iterate handlers correctly or swallows errors.\n            try:\n                if ds is not None and h.is_available() and h.supports_transfer_syntax(ds.file_meta.TransferSyntaxUID):\n                    arr = h.get_pixel_data(ds)\n                    self.set_pixel_data(arr)\n                    return self.pixel_array\n            except (ImportError, AttributeError, RuntimeError):\n                # Fallback failed, proceed to raise original error\n                pass\n\n            # Try to get Transfer Syntax UID for better debugging\n            ts_uid = \"Unknown\"\n            if ds is not None and hasattr(ds, \"file_meta\"):\n                ts_uid = getattr(ds.file_meta, \"TransferSyntaxUID\", \"Unknown\")\n\n            if \"missing dependencies\" in str(e) or \"decompress\" in str(e):\n                # Enhanced debug output\n                handlers = []\n                try:\n                    # pydicom is already imported globally\n                    handlers = [str(h) for h in pydicom.config.pixel_data_handlers]\n                except Exception:\n                    pass\n\n                raise RuntimeError(\n                    f\"Failed to decompress pixel data for {os.path.basename(self.file_path)} \"\n                    f\"(Transfer Syntax: {ts_uid}).\\n\"\n                    f\"Underlying Error: {e}\\n\"\n                    f\"Active pydicom handlers: {handlers}\\n\"\n                    \"Missing image codecs. Please ensure 'pillow', 'pylibjpeg', or 'gdcm' are installed.\"\n                ) from e\n\n            # If we just caught the re-raised \"no pixel data\" exception, it would be handled above,\n            # but if dcmread fails completely or something else happens:\n            raise RuntimeError(f\"Lazy load failed for {self.file_path}: {e}\") from e\n\n    raise FileNotFoundError(f\"Pixels missing and file not found: {self.file_path}\")\n</code></pre>"},{"location":"api/entities/#gantry.entities.Instance.regenerate_uid","title":"<code>regenerate_uid()</code>","text":"<p>Generates a new, globally unique SOP Instance UID.</p> <p>Call this whenever pixel data is modified to ensure the instance is treated as a new distinct entity, preventing collisions with the original data.</p> This method <ol> <li>Generates a new SOP Instance UID.</li> <li>Updates the internal object property.</li> <li>Updates the '0008,0018' DICOM attribute.</li> <li>Detaches the instance from its physical file path (since consistent hash changed).</li> </ol> Source code in <code>gantry/entities.py</code> <pre><code>def regenerate_uid(self):\n    \"\"\"\n    Generates a new, globally unique SOP Instance UID.\n\n    Call this whenever pixel data is modified to ensure the instance is treated\n    as a new distinct entity, preventing collisions with the original data.\n\n    This method:\n        1. Generates a new SOP Instance UID.\n        2. Updates the internal object property.\n        3. Updates the '0008,0018' DICOM attribute.\n        4. Detaches the instance from its physical file path (since consistent hash changed).\n    \"\"\"\n    # 1. Generate new UID using pydicom's generator (or your org root)\n    new_uid = generate_uid()\n\n    # 2. Update the Object Property\n    self.sop_instance_uid = new_uid\n\n    # 3. Update the DICOM Attribute Dictionary\n    self.set_attr(\"0008,0018\", new_uid)\n\n    # 4. Detach from physical file\n    # Since this object is now a \"new\" instance in memory,\n    # it no longer matches the file on disk.\n    self.file_path = None\n\n    get_logger().debug(f\"  -&gt; Identity regenerated: {new_uid}\")\n</code></pre>"},{"location":"api/entities/#gantry.entities.Instance.set_pixel_data","title":"<code>set_pixel_data(array)</code>","text":"<p>Sets the pixel array and automatically updates metadata tags.</p> Updates tags <ul> <li>Rows (0028,0010)</li> <li>Columns (0028,0011)</li> <li>SamplesPerPixel (0028,0002)</li> <li>NumberOfFrames (0028,0008) (if &gt; 1)</li> <li>PhotometricInterpretation (0028,0004) (RGB if samples &gt;= 3)</li> <li>PlanarConfiguration (0028,0006) (0 if RGB)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>ndarray</code> <p>The pixel data to set. Can be 1D, 2D, 3D, or 4D.</p> required Source code in <code>gantry/entities.py</code> <pre><code>def set_pixel_data(self, array: np.ndarray):\n    \"\"\"\n    Sets the pixel array and automatically updates metadata tags.\n\n    Updates tags:\n        - Rows (0028,0010)\n        - Columns (0028,0011)\n        - SamplesPerPixel (0028,0002)\n        - NumberOfFrames (0028,0008) (if &gt; 1)\n        - PhotometricInterpretation (0028,0004) (RGB if samples &gt;= 3)\n        - PlanarConfiguration (0028,0006) (0 if RGB)\n\n    Args:\n        array (np.ndarray): The pixel data to set. Can be 1D, 2D, 3D, or 4D.\n    \"\"\"\n    self.pixel_array = array\n    shape = array.shape\n    ndim = len(shape)\n\n    # Defaults\n    samples = 1\n    frames = 1\n\n    if ndim == 1:\n        # Flattened array (e.g. from Sidecar loader)\n        # Attempt to reshape using existing metadata if available\n        try:\n            r = int(self.attributes.get(\"0028,0010\", 0))\n            c = int(self.attributes.get(\"0028,0011\", 0))\n            s = int(self.attributes.get(\"0028,0002\", 1))\n            f = int(self.attributes.get(\"0028,0008\", 1))\n\n            expected_size = r * c * s * f\n            if expected_size &gt; 0 and array.size &gt;= expected_size:\n                # Truncate padding if present (DICOM alignment)\n                if array.size &gt; expected_size:\n                    array = array[:expected_size]\n\n                # Reshape logic\n                if f &gt; 1:\n                    array = array.reshape((f, r, c, s)) if s &gt; 1 else array.reshape((f, r, c))\n                elif s &gt; 1:\n                    array = array.reshape((r, c, s))\n                else:\n                    array = array.reshape((r, c))\n                self.pixel_array = array\n                return  # Done, attributes already match\n            elif expected_size == 0:\n                # Metadata missing, treat as linear?\n                pass\n\n        except ValueError:\n            pass\n\n        # Only raise if we couldn't resolve it\n        if len(array.shape) == 1:  # Still 1D\n            rows, cols = 1, shape[0]\n\n    elif ndim == 2:\n        rows, cols = shape\n    elif ndim == 3:\n        if shape[-1] in [3, 4]:\n            rows, cols, samples = shape\n        else:\n            frames, rows, cols = shape\n    elif ndim == 4:\n        frames, rows, cols, samples = shape\n    else:\n        raise ValueError(f\"Unknown shape: {shape}\")\n\n    self.set_attr(\"0028,0010\", rows)\n    self.set_attr(\"0028,0011\", cols)\n    self.set_attr(\"0028,0002\", samples)\n    if frames &gt; 1:\n        self.set_attr(\"0028,0008\", str(frames))\n    if samples &gt;= 3:\n        self.set_attr(\"0028,0004\", \"RGB\")\n        self.set_attr(\"0028,0006\", 0)  # Force Interleaved (standard numpy)\n    else:\n        # Preserve existing PhotometricInterpretation (e.g. MONOCHROME1)\n        # Only set default if missing\n        if not self.attributes.get(\"0028,0004\"):\n            self.set_attr(\"0028,0004\", \"MONOCHROME2\")\n\n    # Ensure BitsAllocated matches array data type\n    # SidecarPixelLoader relies on this to determine uint8 vs uint16\n    bits = array.itemsize * 8\n    self.set_attr(\"0028,0100\", bits)\n\n    self._mod_count += 1\n</code></pre>"},{"location":"api/entities/#gantry.entities.Instance.unload_pixel_data","title":"<code>unload_pixel_data()</code>","text":"<p>Clears the cached pixel_array from memory to free resources.</p> <p>Only performs the clear if the data can be re-loaded (i.e., <code>file_path</code> or <code>_pixel_loader</code> is present).</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if unloaded successfully,  False if it was unsafe to unload (data would be lost).</p> Source code in <code>gantry/entities.py</code> <pre><code>def unload_pixel_data(self) -&gt; bool:\n    \"\"\"\n    Clears the cached pixel_array from memory to free resources.\n\n    Only performs the clear if the data can be re-loaded (i.e., `file_path`\n    or `_pixel_loader` is present).\n\n    Returns:\n        bool: True if unloaded successfully,\n             False if it was unsafe to unload (data would be lost).\n    \"\"\"\n    if self.pixel_array is None:\n        return True\n\n    if self.file_path or self._pixel_loader:\n        self.pixel_array = None\n        # print(f\"DEBUG: Unloaded pixels for {self.sop_instance_uid}\")\n        return True\n    else:\n        # Data is in memory only (e.g. modified but not saved)\n        print(f\"DEBUG: FAILED TO UNLOAD {self.sop_instance_uid} - No file path or loader!\")\n        return False\n</code></pre>"},{"location":"api/entities/#gantry.entities.Patient","title":"<code>Patient</code>  <code>dataclass</code>","text":"<p>Root of the object hierarchy. Groups Studies by Patient ID.</p> <p>Attributes:</p> Name Type Description <code>patient_id</code> <code>str</code> <p>The primary patient identifier.</p> <code>patient_name</code> <code>str</code> <p>The patient's name.</p> <code>studies</code> <code>List[Study]</code> <p>List of studies belonging to this patient.</p> Source code in <code>gantry/entities.py</code> <pre><code>@dataclass(slots=True)\nclass Patient:\n    \"\"\"\n    Root of the object hierarchy. Groups Studies by Patient ID.\n\n    Attributes:\n        patient_id (str): The primary patient identifier.\n        patient_name (str): The patient's name.\n        studies (List[Study]): List of studies belonging to this patient.\n    \"\"\"\n    patient_id: str\n    patient_name: str\n    studies: List[Study] = field(default_factory=list)\n    _dirty: bool = field(default=True, init=False)\n\n    def __post_init__(self):\n        self._dirty = True\n\n    def mark_clean(self):\n        \"\"\"\n        Marks the current entity and all associated studies as clean.\n\n        Resets the '_dirty' flag to False for this entity and recursively calls\n        'mark_clean' on all studies to ensure their '_dirty' flags are also reset.\n        \"\"\"\n        self._dirty = False\n        for s in self.studies:\n            s.mark_clean()\n</code></pre>"},{"location":"api/entities/#gantry.entities.Patient.mark_clean","title":"<code>mark_clean()</code>","text":"<p>Marks the current entity and all associated studies as clean.</p> <p>Resets the '_dirty' flag to False for this entity and recursively calls 'mark_clean' on all studies to ensure their '_dirty' flags are also reset.</p> Source code in <code>gantry/entities.py</code> <pre><code>def mark_clean(self):\n    \"\"\"\n    Marks the current entity and all associated studies as clean.\n\n    Resets the '_dirty' flag to False for this entity and recursively calls\n    'mark_clean' on all studies to ensure their '_dirty' flags are also reset.\n    \"\"\"\n    self._dirty = False\n    for s in self.studies:\n        s.mark_clean()\n</code></pre>"},{"location":"api/entities/#gantry.entities.Series","title":"<code>Series</code>  <code>dataclass</code>","text":"<p>Groups Instances by Series Instance UID. Typically represents a single scan or reconstruction.</p> <p>Attributes:</p> Name Type Description <code>series_instance_uid</code> <code>str</code> <p>The unique identifier for the series.</p> <code>modality</code> <code>str</code> <p>The modality type (e.g., 'CT', 'MR').</p> <code>series_number</code> <code>int</code> <p>The series number.</p> <code>equipment</code> <code>Optional[Equipment]</code> <p>The equipment used for this series.</p> <code>instances</code> <code>List[Instance]</code> <p>List of instances belonging to this series.</p> Source code in <code>gantry/entities.py</code> <pre><code>@dataclass(slots=True)\nclass Series:\n    \"\"\"\n    Groups Instances by Series Instance UID.\n    Typically represents a single scan or reconstruction.\n\n    Attributes:\n        series_instance_uid (str): The unique identifier for the series.\n        modality (str): The modality type (e.g., 'CT', 'MR').\n        series_number (int): The series number.\n        equipment (Optional[Equipment]): The equipment used for this series.\n        instances (List[Instance]): List of instances belonging to this series.\n    \"\"\"\n    series_instance_uid: str\n    modality: str\n    series_number: int\n    equipment: Optional[Equipment] = None\n    instances: List[Instance] = field(default_factory=list)\n    _dirty: bool = field(default=True, init=False)\n\n    def __post_init__(self):\n        self._dirty = True\n\n    def mark_clean(self):\n        \"\"\"\n        Marks the current object and all its instances as clean by setting their '_dirty' attribute to False.\n        \"\"\"\n        self._dirty = False\n        for i in self.instances:\n            i.mark_clean()\n</code></pre>"},{"location":"api/entities/#gantry.entities.Series.mark_clean","title":"<code>mark_clean()</code>","text":"<p>Marks the current object and all its instances as clean by setting their '_dirty' attribute to False.</p> Source code in <code>gantry/entities.py</code> <pre><code>def mark_clean(self):\n    \"\"\"\n    Marks the current object and all its instances as clean by setting their '_dirty' attribute to False.\n    \"\"\"\n    self._dirty = False\n    for i in self.instances:\n        i.mark_clean()\n</code></pre>"},{"location":"api/entities/#gantry.entities.Study","title":"<code>Study</code>  <code>dataclass</code>","text":"<p>Groups Series by Study Instance UID. Represents a single patient visit or examination.</p> <p>Attributes:</p> Name Type Description <code>study_instance_uid</code> <code>str</code> <p>The unique identifier for the study.</p> <code>study_date</code> <code>Any</code> <p>The date of the study.</p> <code>series</code> <code>List[Series]</code> <p>List of series belonging to this study.</p> <code>date_shifted</code> <code>bool</code> <p>Whether dates in this study have been shifted.</p> <code>study_time</code> <code>Optional[str]</code> <p>The time of the study.</p> Source code in <code>gantry/entities.py</code> <pre><code>@dataclass(slots=True)\nclass Study:\n    \"\"\"\n    Groups Series by Study Instance UID.\n    Represents a single patient visit or examination.\n\n    Attributes:\n        study_instance_uid (str): The unique identifier for the study.\n        study_date (Any): The date of the study.\n        series (List[Series]): List of series belonging to this study.\n        date_shifted (bool): Whether dates in this study have been shifted.\n        study_time (Optional[str]): The time of the study.\n    \"\"\"\n    study_instance_uid: str\n    study_date: Any\n    series: List[Series] = field(default_factory=list)\n    date_shifted: bool = False\n    study_time: Optional[str] = None\n    _dirty: bool = field(default=True, init=False)\n\n    def __post_init__(self):\n        self._dirty = True\n\n    def mark_clean(self):\n        \"\"\"\n        Marks the current object and all associated series as clean by setting their '_dirty' attribute to False.\n        \"\"\"\n        self._dirty = False\n        for s in self.series:\n            s.mark_clean()\n</code></pre>"},{"location":"api/entities/#gantry.entities.Study.mark_clean","title":"<code>mark_clean()</code>","text":"<p>Marks the current object and all associated series as clean by setting their '_dirty' attribute to False.</p> Source code in <code>gantry/entities.py</code> <pre><code>def mark_clean(self):\n    \"\"\"\n    Marks the current object and all associated series as clean by setting their '_dirty' attribute to False.\n    \"\"\"\n    self._dirty = False\n    for s in self.series:\n        s.mark_clean()\n</code></pre>"},{"location":"api/ocr/","title":"Intelligent OCR API","text":""},{"location":"api/ocr/#zone-discovery","title":"Zone Discovery","text":""},{"location":"api/ocr/#gantry.discovery.ZoneDiscoverer","title":"<code>gantry.discovery.ZoneDiscoverer</code>","text":"<p>Analyzes a set of instances to discover common locations of burned-in text. Used to suggest initial redaction zones for a machine.</p> Source code in <code>gantry/discovery.py</code> <pre><code>class ZoneDiscoverer:\n    \"\"\"\n    Analyzes a set of instances to discover common locations of burned-in text.\n    Used to suggest initial redaction zones for a machine.\n    \"\"\"\n\n    @staticmethod\n    def discover_zones(instances: List[Instance], _min_occurrence: float = 0.1) -&gt; List[List[int]]:\n        \"\"\"\n        scans instances and returns a list of suggested zones [x, y, w, h].\n\n        Args:\n            instances: List of DICOM instances to scan.\n            min_occurrence: Fraction of instances that must contain text in a region\n                            for it to be considered a \"zone\" (Not strictly used in MVP).\n\n        Returns:\n            List[List[int]]: List of suggested zones.\n        \"\"\"\n        all_regions = []\n\n        for inst in instances:\n            regions = analyze_pixels(inst)\n            all_regions.extend(regions)\n\n        if not all_regions:\n            return []\n\n        # Convert to working format\n        boxes = [list(r.box) for r in all_regions] # [[x,y,w,h], ...]\n\n        merged_boxes = ZoneDiscoverer._merge_overlapping_boxes(boxes)\n\n        final_zones = []\n        for box in merged_boxes:\n            if box[2] &gt; 5 and box[3] &gt; 5: # Min size 5x5\n                final_zones.append(box)\n\n        return final_zones\n\n    @staticmethod\n    def _merge_overlapping_boxes(boxes: List[List[int]]) -&gt; List[List[int]]:\n        \"\"\"\n        Iteratively merges overlapping boxes until no overlaps remain.\n        \"\"\"\n        if not boxes:\n            return []\n\n        n = len(boxes)\n\n        # Build adjacency graph (indices)\n        adj = [[] for _ in range(n)]\n\n        # O(N^2) comparison - fine for N &lt; ~2000\n        for i in range(n):\n            for j in range(i + 1, n):\n                if ZoneDiscoverer._boxes_overlap(boxes[i], boxes[j]):\n                    adj[i].append(j)\n                    adj[j].append(i)\n\n        # Find connected components (BFS)\n        visited = [False] * n\n        merged_results = []\n\n        for i in range(n):\n            if not visited[i]:\n                # Start new component\n                visited[i] = True\n                component = [boxes[i]]\n                queue = [i]\n\n                while queue:\n                    curr = queue.pop(0)\n                    for neighbor in adj[curr]:\n                        if not visited[neighbor]:\n                            visited[neighbor] = True\n                            component.append(boxes[neighbor])\n                            queue.append(neighbor)\n\n                # Merge component\n                # Start with first box\n                ux, uy, uw, uh = component[0]\n                ur = ux + uw\n                ub = uy + uh\n\n                for k in range(1, len(component)):\n                    b = component[k]\n                    ux = min(ux, b[0])\n                    uy = min(uy, b[1])\n                    ur = max(ur, b[0] + b[2])\n                    ub = max(ub, b[1] + b[3])\n\n                merged_results.append([ux, uy, ur - ux, ub - uy])\n\n        return merged_results\n\n    @staticmethod\n    def _boxes_overlap(b1, b2) -&gt; bool:\n        # b = [x, y, w, h]\n        l1, t1, r1, b1_ = b1[0], b1[1], b1[0]+b1[2], b1[1]+b1[3]\n        l2, t2, r2, b2_ = b2[0], b2[1], b2[0]+b2[2], b2[1]+b2[3]\n\n        return not (r1 &lt; l2 or l1 &gt; r2 or b1_ &lt; t2 or t1 &gt; b2_)\n</code></pre>"},{"location":"api/ocr/#gantry.discovery.ZoneDiscoverer.discover_zones","title":"<code>discover_zones(instances, _min_occurrence=0.1)</code>  <code>staticmethod</code>","text":"<p>scans instances and returns a list of suggested zones [x, y, w, h].</p> <p>Parameters:</p> Name Type Description Default <code>instances</code> <code>List[Instance]</code> <p>List of DICOM instances to scan.</p> required <code>min_occurrence</code> <p>Fraction of instances that must contain text in a region             for it to be considered a \"zone\" (Not strictly used in MVP).</p> required <p>Returns:</p> Type Description <code>List[List[int]]</code> <p>List[List[int]]: List of suggested zones.</p> Source code in <code>gantry/discovery.py</code> <pre><code>@staticmethod\ndef discover_zones(instances: List[Instance], _min_occurrence: float = 0.1) -&gt; List[List[int]]:\n    \"\"\"\n    scans instances and returns a list of suggested zones [x, y, w, h].\n\n    Args:\n        instances: List of DICOM instances to scan.\n        min_occurrence: Fraction of instances that must contain text in a region\n                        for it to be considered a \"zone\" (Not strictly used in MVP).\n\n    Returns:\n        List[List[int]]: List of suggested zones.\n    \"\"\"\n    all_regions = []\n\n    for inst in instances:\n        regions = analyze_pixels(inst)\n        all_regions.extend(regions)\n\n    if not all_regions:\n        return []\n\n    # Convert to working format\n    boxes = [list(r.box) for r in all_regions] # [[x,y,w,h], ...]\n\n    merged_boxes = ZoneDiscoverer._merge_overlapping_boxes(boxes)\n\n    final_zones = []\n    for box in merged_boxes:\n        if box[2] &gt; 5 and box[3] &gt; 5: # Min size 5x5\n            final_zones.append(box)\n\n    return final_zones\n</code></pre>"},{"location":"api/ocr/#verification","title":"Verification","text":""},{"location":"api/ocr/#gantry.verification.RedactionVerifier","title":"<code>gantry.verification.RedactionVerifier</code>","text":"<p>Verifies pixel redaction strategies by comparing OCR results against configured redaction zones.</p> Source code in <code>gantry/verification.py</code> <pre><code>class RedactionVerifier:\n    \"\"\"\n    Verifies pixel redaction strategies by comparing OCR results\n    against configured redaction zones.\n    \"\"\"\n\n    def __init__(self, rules: List[Dict[str, Any]] = None):\n        \"\"\"\n        Args:\n            rules (List[Dict]): A list of redaction rules (config['machines']).\n        \"\"\"\n        self.rules = rules or []\n\n    def get_matching_rule(self, equipment: Any) -&gt; Dict[str, Any]:\n        \"\"\"\n        Finds the redaction rule that applies to this equipment.\n        Uses exact Serial Number match first, then Model/Manufacturer logic.\n        \"\"\"\n        if not equipment:\n            return None\n\n        target_serial = equipment.device_serial_number\n        if not target_serial:\n            return None\n\n        # 1. Exact Serial Match\n        for rule in self.rules:\n            if rule.get(\"serial_number\") == target_serial:\n                return rule\n\n        # 2. Check Model/Manufacturer (if serial not found or not required by rule?)\n        # For verification, we stick to strict serial matching as per current architecture\n        # unless there's a fallback mechanism. \n        # For now, strict match.\n        return None\n\n    def is_covered(self, text_box: Tuple[int, int, int, int], zone_box: Tuple[int, int, int, int], threshold=0.50) -&gt; bool:\n        \"\"\"\n        Checks if the text_box is significantly covered by the zone_box.\n\n        Args:\n            text_box: (x, y, w, h)\n            zone_box: (x, y, w, h)\n            threshold: Fraction of text area that must be covered (0.0 - 1.0).\n\n        Returns:\n            bool: True if covered.\n        \"\"\"\n        tx, ty, tw, th = text_box\n        zx, zy, zw, zh = zone_box\n\n        # Calculate Intersection\n        x_left = max(tx, zx)\n        y_top = max(ty, zy)\n        x_right = min(tx + tw, zx + zw)\n        y_bottom = min(ty + th, zy + zh)\n\n        if x_right &lt; x_left or y_bottom &lt; y_top:\n            return False\n\n        intersection_area = (x_right - x_left) * (y_bottom - y_top)\n        text_area = tw * th\n\n        if text_area == 0:\n            return False\n\n        coverage = intersection_area / text_area\n        return coverage &gt;= threshold\n\n    def verify_instance(self, instance: Instance, equipment: Any = None) -&gt; List[PhiFinding]:\n        \"\"\"\n        Runs OCR on the instance.\n        - If text is fully matched (&gt;= 80% coverage): considered Safe (Ignored).\n        - If text is partially matched (&gt; 0% but &lt; 80%): Reported as PARTIAL_LEAK.\n        - If text is not matched (0%): Reported as NEW_LEAK.\n        \"\"\"\n        text_regions = analyze_pixels(instance)\n\n        if not text_regions:\n            return []\n\n        rule = self.get_matching_rule(equipment)\n        zones = []\n        if rule:\n            raw_zones = rule.get(\"redaction_zones\", [])\n            zones = raw_zones\n\n        findings = []\n\n        for region in text_regions:\n            best_coverage = 0.0\n            best_zone = None\n\n            # Check against all zones to find BEST coverage\n            for zone in zones:\n                if len(zone) &gt;= 4:\n                    z_box = (zone[0], zone[1], zone[2], zone[3])\n\n                    # Calculate logic manually here or reuse is_covered logic but return float?\n                    # Let's inline the area math or split helper.\n\n                    tx, ty, tw, th = region.box\n                    zx, zy, zw, zh = z_box\n\n                    x_left = max(tx, zx)\n                    y_top = max(ty, zy)\n                    x_right = min(tx + tw, zx + zw)\n                    y_bottom = min(ty + th, zy + zh)\n\n                    if x_right &gt; x_left and y_bottom &gt; y_top:\n                        intersection_area = (x_right - x_left) * (y_bottom - y_top)\n                        text_area = tw * th\n                        if text_area &gt; 0:\n                            cov = intersection_area / text_area\n                            if cov &gt; best_coverage:\n                                best_coverage = cov\n                                best_zone = zone\n\n            # Decision Logic\n            threshold_safe = 0.80  # Configurable?\n\n            clean_text = region.text.replace('\\n', ' ').strip()\n            if len(clean_text) &lt;= 2:\n                continue # Skip noise\n\n            if best_coverage &gt;= threshold_safe:\n                # Safe, ignore\n                continue\n\n            # It's a finding\n            if best_coverage &gt; 0.0:\n                reason = \"Partial Leak\"\n                f_type = \"PARTIAL_LEAK\"\n            else:\n                reason = \"New Leak (Uncovered)\"\n                f_type = \"NEW_LEAK\"\n\n            f = PhiFinding(\n                entity_uid=instance.sop_instance_uid,\n                entity_type=\"Instance\",\n                field_name=f\"PixelData[Frame={region.frame_index}]\",\n                value=clean_text,\n                reason=f\"{reason} (Cov: {best_coverage:.2f})\",\n                entity=instance,\n                metadata={\n                    \"leak_type\": f_type,\n                    \"coverage_score\": best_coverage,\n                    \"text_box\": region.box,  # (x, y, w, h)\n                    \"best_zone\": best_zone,\n                    \"rule_serial\": rule.get(\"serial_number\") if rule else None\n                }\n            )\n            findings.append(f)\n\n        return findings\n</code></pre>"},{"location":"api/ocr/#gantry.verification.RedactionVerifier.__init__","title":"<code>__init__(rules=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>rules</code> <code>List[Dict]</code> <p>A list of redaction rules (config['machines']).</p> <code>None</code> Source code in <code>gantry/verification.py</code> <pre><code>def __init__(self, rules: List[Dict[str, Any]] = None):\n    \"\"\"\n    Args:\n        rules (List[Dict]): A list of redaction rules (config['machines']).\n    \"\"\"\n    self.rules = rules or []\n</code></pre>"},{"location":"api/ocr/#gantry.verification.RedactionVerifier.get_matching_rule","title":"<code>get_matching_rule(equipment)</code>","text":"<p>Finds the redaction rule that applies to this equipment. Uses exact Serial Number match first, then Model/Manufacturer logic.</p> Source code in <code>gantry/verification.py</code> <pre><code>def get_matching_rule(self, equipment: Any) -&gt; Dict[str, Any]:\n    \"\"\"\n    Finds the redaction rule that applies to this equipment.\n    Uses exact Serial Number match first, then Model/Manufacturer logic.\n    \"\"\"\n    if not equipment:\n        return None\n\n    target_serial = equipment.device_serial_number\n    if not target_serial:\n        return None\n\n    # 1. Exact Serial Match\n    for rule in self.rules:\n        if rule.get(\"serial_number\") == target_serial:\n            return rule\n\n    # 2. Check Model/Manufacturer (if serial not found or not required by rule?)\n    # For verification, we stick to strict serial matching as per current architecture\n    # unless there's a fallback mechanism. \n    # For now, strict match.\n    return None\n</code></pre>"},{"location":"api/ocr/#gantry.verification.RedactionVerifier.is_covered","title":"<code>is_covered(text_box, zone_box, threshold=0.5)</code>","text":"<p>Checks if the text_box is significantly covered by the zone_box.</p> <p>Parameters:</p> Name Type Description Default <code>text_box</code> <code>Tuple[int, int, int, int]</code> <p>(x, y, w, h)</p> required <code>zone_box</code> <code>Tuple[int, int, int, int]</code> <p>(x, y, w, h)</p> required <code>threshold</code> <p>Fraction of text area that must be covered (0.0 - 1.0).</p> <code>0.5</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if covered.</p> Source code in <code>gantry/verification.py</code> <pre><code>def is_covered(self, text_box: Tuple[int, int, int, int], zone_box: Tuple[int, int, int, int], threshold=0.50) -&gt; bool:\n    \"\"\"\n    Checks if the text_box is significantly covered by the zone_box.\n\n    Args:\n        text_box: (x, y, w, h)\n        zone_box: (x, y, w, h)\n        threshold: Fraction of text area that must be covered (0.0 - 1.0).\n\n    Returns:\n        bool: True if covered.\n    \"\"\"\n    tx, ty, tw, th = text_box\n    zx, zy, zw, zh = zone_box\n\n    # Calculate Intersection\n    x_left = max(tx, zx)\n    y_top = max(ty, zy)\n    x_right = min(tx + tw, zx + zw)\n    y_bottom = min(ty + th, zy + zh)\n\n    if x_right &lt; x_left or y_bottom &lt; y_top:\n        return False\n\n    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n    text_area = tw * th\n\n    if text_area == 0:\n        return False\n\n    coverage = intersection_area / text_area\n    return coverage &gt;= threshold\n</code></pre>"},{"location":"api/ocr/#gantry.verification.RedactionVerifier.verify_instance","title":"<code>verify_instance(instance, equipment=None)</code>","text":"<p>Runs OCR on the instance. - If text is fully matched (&gt;= 80% coverage): considered Safe (Ignored). - If text is partially matched (&gt; 0% but &lt; 80%): Reported as PARTIAL_LEAK. - If text is not matched (0%): Reported as NEW_LEAK.</p> Source code in <code>gantry/verification.py</code> <pre><code>def verify_instance(self, instance: Instance, equipment: Any = None) -&gt; List[PhiFinding]:\n    \"\"\"\n    Runs OCR on the instance.\n    - If text is fully matched (&gt;= 80% coverage): considered Safe (Ignored).\n    - If text is partially matched (&gt; 0% but &lt; 80%): Reported as PARTIAL_LEAK.\n    - If text is not matched (0%): Reported as NEW_LEAK.\n    \"\"\"\n    text_regions = analyze_pixels(instance)\n\n    if not text_regions:\n        return []\n\n    rule = self.get_matching_rule(equipment)\n    zones = []\n    if rule:\n        raw_zones = rule.get(\"redaction_zones\", [])\n        zones = raw_zones\n\n    findings = []\n\n    for region in text_regions:\n        best_coverage = 0.0\n        best_zone = None\n\n        # Check against all zones to find BEST coverage\n        for zone in zones:\n            if len(zone) &gt;= 4:\n                z_box = (zone[0], zone[1], zone[2], zone[3])\n\n                # Calculate logic manually here or reuse is_covered logic but return float?\n                # Let's inline the area math or split helper.\n\n                tx, ty, tw, th = region.box\n                zx, zy, zw, zh = z_box\n\n                x_left = max(tx, zx)\n                y_top = max(ty, zy)\n                x_right = min(tx + tw, zx + zw)\n                y_bottom = min(ty + th, zy + zh)\n\n                if x_right &gt; x_left and y_bottom &gt; y_top:\n                    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n                    text_area = tw * th\n                    if text_area &gt; 0:\n                        cov = intersection_area / text_area\n                        if cov &gt; best_coverage:\n                            best_coverage = cov\n                            best_zone = zone\n\n        # Decision Logic\n        threshold_safe = 0.80  # Configurable?\n\n        clean_text = region.text.replace('\\n', ' ').strip()\n        if len(clean_text) &lt;= 2:\n            continue # Skip noise\n\n        if best_coverage &gt;= threshold_safe:\n            # Safe, ignore\n            continue\n\n        # It's a finding\n        if best_coverage &gt; 0.0:\n            reason = \"Partial Leak\"\n            f_type = \"PARTIAL_LEAK\"\n        else:\n            reason = \"New Leak (Uncovered)\"\n            f_type = \"NEW_LEAK\"\n\n        f = PhiFinding(\n            entity_uid=instance.sop_instance_uid,\n            entity_type=\"Instance\",\n            field_name=f\"PixelData[Frame={region.frame_index}]\",\n            value=clean_text,\n            reason=f\"{reason} (Cov: {best_coverage:.2f})\",\n            entity=instance,\n            metadata={\n                \"leak_type\": f_type,\n                \"coverage_score\": best_coverage,\n                \"text_box\": region.box,  # (x, y, w, h)\n                \"best_zone\": best_zone,\n                \"rule_serial\": rule.get(\"serial_number\") if rule else None\n            }\n        )\n        findings.append(f)\n\n    return findings\n</code></pre>"},{"location":"api/ocr/#automation","title":"Automation","text":""},{"location":"api/ocr/#gantry.automation.ConfigAutomator","title":"<code>gantry.automation.ConfigAutomator</code>","text":"<p>Analyzes OCR findings and generates suggestions to update the redaction configuration.</p> Source code in <code>gantry/automation.py</code> <pre><code>class ConfigAutomator:\n    \"\"\"\n    Analyzes OCR findings and generates suggestions to update the redaction configuration.\n    \"\"\"\n\n    @staticmethod\n    def suggest_config_updates(report: PhiReport, _current_config: GantryConfiguration) -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        Generates a list of suggested configuration changes.\n\n        Returns:\n            List[Dict]: A list of 'suggestion' objects:\n            {\n                \"serial\": str,\n                \"action\": \"ADD_ZONE\" | \"EXPAND_ZONE\",\n                \"zone\": [x, y, w, h],\n                \"reason\": str\n            }\n        \"\"\"\n        suggestions = []\n\n        # Group findings by machine serial\n        findings_by_serial = defaultdict(list)\n\n        for finding in report:\n            meta = finding.metadata\n            if not meta:\n                continue\n\n            serial = meta.get(\"rule_serial\")\n            if serial:\n                findings_by_serial[serial].append(finding)\n            else:\n                # Todo: Handle findings with no matching rule (Unknown Serial or No config entry)\n                pass\n\n        for serial, findings in findings_by_serial.items():\n            # In a real system we might merge zones here.\n            for f in findings:\n                meta = f.metadata\n                l_type = meta.get(\"leak_type\")\n                text_box = meta.get(\"text_box\") # x,y,w,h\n\n                if not text_box:\n                    continue\n\n                if l_type == \"PARTIAL_LEAK\":\n                    # Suggest expanding the best_zone to cover text_box\n                    best_zone = meta.get(\"best_zone\")\n                    if best_zone:\n                        # Calculate union box\n                        tx, ty, tw, th = text_box\n                        zx, zy, zw, zh = best_zone\n\n                        ux = min(tx, zx)\n                        uy = min(ty, zy)\n                        ur = max(tx+tw, zx+zw)\n                        ub = max(ty+th, zy+zh)\n\n                        union_zone = [int(ux), int(uy), int(ur-ux), int(ub-uy)]\n\n                        suggestions.append({\n                            \"serial\": serial,\n                            \"action\": \"EXPAND_ZONE\",\n                            \"original_zone\": best_zone,\n                            \"new_zone\": union_zone,\n                            \"reason\": f\"Partial leak detected ({f.value}). Expanded to cover.\"\n                        })\n\n                elif l_type == \"NEW_LEAK\":\n                    # Suggest adding the text box as a new zone\n                    # Add some padding?\n                    # Ensure ints\n                    zone = [int(x) for x in text_box]\n\n                    suggestions.append({\n                        \"serial\": serial,\n                        \"action\": \"ADD_ZONE\",\n                        \"zone\": list(zone),\n                        \"reason\": f\"New leak detected ({f.value}). Added new zone.\"\n                    })\n\n        return suggestions\n\n    @staticmethod\n    def apply_suggestions(session: 'DicomSession', suggestions: List[Dict[str, Any]]) -&gt; int:\n        \"\"\"\n        Applies the suggestions to the session's in-memory configuration.\n        Returns: Number of changes applied.\n        \"\"\"\n        count = 0\n        rules = session.configuration.rules\n\n        for sug in suggestions:\n            serial = sug[\"serial\"]\n            action = sug[\"action\"]\n\n            # Find the rule object\n            target_rule = None\n            for r in rules:\n                if r.get(\"serial_number\") == serial:\n                    target_rule = r\n                    break\n\n            if not target_rule:\n                continue\n\n            if action == \"ADD_ZONE\":\n                zone = sug[\"zone\"]\n                # Check duplicates?\n                if zone not in target_rule[\"redaction_zones\"]:\n                    target_rule[\"redaction_zones\"].append(zone)\n                    count += 1\n\n            elif action == \"EXPAND_ZONE\":\n                old_zone = sug[\"original_zone\"]\n                new_zone = sug[\"new_zone\"]\n\n                # Find index of old_zone\n                zones = target_rule[\"redaction_zones\"]\n                try:\n                    # Convert to list for comparison just in case\n                    idx = -1\n                    for i, z in enumerate(zones):\n                        if list(z) == list(old_zone):\n                            idx = i\n                            break\n\n                    if idx &gt;= 0:\n                        zones[idx] = new_zone\n                        count += 1\n                except ValueError:\n                    pass\n\n        return count\n</code></pre>"},{"location":"api/ocr/#gantry.automation.ConfigAutomator.suggest_config_updates","title":"<code>suggest_config_updates(report, _current_config)</code>  <code>staticmethod</code>","text":"<p>Generates a list of suggested configuration changes.</p> <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>List[Dict]: A list of 'suggestion' objects:</p> <code>List[Dict[str, Any]]</code> <p>{ \"serial\": str, \"action\": \"ADD_ZONE\" | \"EXPAND_ZONE\", \"zone\": [x, y, w, h], \"reason\": str</p> <code>List[Dict[str, Any]]</code> <p>}</p> Source code in <code>gantry/automation.py</code> <pre><code>@staticmethod\ndef suggest_config_updates(report: PhiReport, _current_config: GantryConfiguration) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Generates a list of suggested configuration changes.\n\n    Returns:\n        List[Dict]: A list of 'suggestion' objects:\n        {\n            \"serial\": str,\n            \"action\": \"ADD_ZONE\" | \"EXPAND_ZONE\",\n            \"zone\": [x, y, w, h],\n            \"reason\": str\n        }\n    \"\"\"\n    suggestions = []\n\n    # Group findings by machine serial\n    findings_by_serial = defaultdict(list)\n\n    for finding in report:\n        meta = finding.metadata\n        if not meta:\n            continue\n\n        serial = meta.get(\"rule_serial\")\n        if serial:\n            findings_by_serial[serial].append(finding)\n        else:\n            # Todo: Handle findings with no matching rule (Unknown Serial or No config entry)\n            pass\n\n    for serial, findings in findings_by_serial.items():\n        # In a real system we might merge zones here.\n        for f in findings:\n            meta = f.metadata\n            l_type = meta.get(\"leak_type\")\n            text_box = meta.get(\"text_box\") # x,y,w,h\n\n            if not text_box:\n                continue\n\n            if l_type == \"PARTIAL_LEAK\":\n                # Suggest expanding the best_zone to cover text_box\n                best_zone = meta.get(\"best_zone\")\n                if best_zone:\n                    # Calculate union box\n                    tx, ty, tw, th = text_box\n                    zx, zy, zw, zh = best_zone\n\n                    ux = min(tx, zx)\n                    uy = min(ty, zy)\n                    ur = max(tx+tw, zx+zw)\n                    ub = max(ty+th, zy+zh)\n\n                    union_zone = [int(ux), int(uy), int(ur-ux), int(ub-uy)]\n\n                    suggestions.append({\n                        \"serial\": serial,\n                        \"action\": \"EXPAND_ZONE\",\n                        \"original_zone\": best_zone,\n                        \"new_zone\": union_zone,\n                        \"reason\": f\"Partial leak detected ({f.value}). Expanded to cover.\"\n                    })\n\n            elif l_type == \"NEW_LEAK\":\n                # Suggest adding the text box as a new zone\n                # Add some padding?\n                # Ensure ints\n                zone = [int(x) for x in text_box]\n\n                suggestions.append({\n                    \"serial\": serial,\n                    \"action\": \"ADD_ZONE\",\n                    \"zone\": list(zone),\n                    \"reason\": f\"New leak detected ({f.value}). Added new zone.\"\n                })\n\n    return suggestions\n</code></pre>"},{"location":"api/ocr/#pixel-analysis","title":"Pixel Analysis","text":""},{"location":"api/ocr/#gantry.pixel_analysis","title":"<code>gantry.pixel_analysis</code>","text":""},{"location":"api/ocr/#gantry.pixel_analysis.analyze_pixels","title":"<code>analyze_pixels(instance)</code>","text":"<p>Analyzes the pixel data of a DICOM Instance for burned-in text. Returns list of TextRegion objects (raw findings, not filtered).  Caller is responsible for filtering against rules.</p> Source code in <code>gantry/pixel_analysis.py</code> <pre><code>def analyze_pixels(instance: Instance) -&gt; List[TextRegion]:\n    \"\"\"\n    Analyzes the pixel data of a DICOM Instance for burned-in text.\n    Returns list of TextRegion objects (raw findings, not filtered).\n     Caller is responsible for filtering against rules.\n    \"\"\"\n    all_regions = []\n\n    if not HAS_OCR:\n        return all_regions\n\n    try:\n        pixel_array = instance.get_pixel_data()\n        if pixel_array is None:\n            return all_regions\n\n        frames = []\n        shape = pixel_array.shape\n\n        # Heuristic to detect frames vs RGB (Same as before)\n        if pixel_array.ndim == 2:\n            frames.append(pixel_array)\n        elif pixel_array.ndim == 3:\n            if pixel_array.shape[-1] in [3, 4]:\n                frames.append(pixel_array)\n            else:\n                for i in range(shape[0]):\n                    frames.append(pixel_array[i])\n        elif pixel_array.ndim == 4:\n             for i in range(shape[0]):\n                    frames.append(pixel_array[i])\n\n        for i, frame in enumerate(frames):\n            regions = detect_text_regions(frame, frame_idx=i)\n            all_regions.extend(regions)\n\n    except Exception as e:\n        logger.error(f\"Failed to analyze pixels for {instance.sop_instance_uid}: {e}\")\n\n    return all_regions\n</code></pre>"},{"location":"api/ocr/#gantry.pixel_analysis.detect_text_regions","title":"<code>detect_text_regions(pixel_data, frame_idx=0)</code>","text":"<p>Runs OCR on the provided pixel data and returns text regions with bounding boxes.</p> <p>Parameters:</p> Name Type Description Default <code>pixel_data</code> <code>ndarray</code> <p>The image data.</p> required <code>frame_idx</code> <code>int</code> <p>The frame index associated with this data (for reporting).</p> <code>0</code> <p>Returns:</p> Type Description <code>List[TextRegion]</code> <p>List[TextRegion]: Detected text regions.</p> Source code in <code>gantry/pixel_analysis.py</code> <pre><code>def detect_text_regions(pixel_data: np.ndarray, frame_idx: int = 0) -&gt; List[TextRegion]:\n    \"\"\"\n    Runs OCR on the provided pixel data and returns text regions with bounding boxes.\n\n    Args:\n        pixel_data (np.ndarray): The image data.\n        frame_idx (int): The frame index associated with this data (for reporting).\n\n    Returns:\n        List[TextRegion]: Detected text regions.\n    \"\"\"\n    regions = []\n    if not HAS_OCR:\n        return regions\n\n    try:\n        # Normalize pixel types for PIL\n        if pixel_data.dtype != np.uint8:\n            p_min = pixel_data.min()\n            p_max = pixel_data.max()\n            if p_max &gt; p_min:\n                norm = ((pixel_data - p_min) / (p_max - p_min)) * 255.0\n                img_data = norm.astype(np.uint8)\n            else:\n                img_data = np.zeros(pixel_data.shape, dtype=np.uint8)\n        else:\n            img_data = pixel_data\n\n        img = Image.fromarray(img_data)\n\n        # Use image_to_data for detailed box info\n        # config optimized for sparse text\n        config = r'--oem 3 --psm 11'\n\n        # Output is a dict with lists: level, page_num, block_num, par_num, line_num, word_num, left, top, width, height, conf, text\n        data = pytesseract.image_to_data(img, config=config, output_type=pytesseract.Output.DICT)\n\n        n_boxes = len(data['text'])\n        for i in range(n_boxes):\n            text = data['text'][i].strip()\n            conf = int(data['conf'][i])\n\n            # Filter low confidence and empty text\n            if conf &gt; 0 and len(text) &gt; 0:\n                (x, y, w, h) = (data['left'][i], data['top'][i], data['width'][i], data['height'][i])\n                regions.append(TextRegion(\n                    text=text,\n                    box=(x, y, w, h),\n                    confidence=float(conf),\n                    frame_index=frame_idx\n                ))\n\n    except Exception as e:\n        logger.error(f\"OCR failed: {e}\")\n\n    return regions\n</code></pre>"},{"location":"api/persistence/","title":"Persistence API","text":""},{"location":"api/persistence/#gantry.persistence","title":"<code>gantry.persistence</code>","text":"<p>Persistence layer for Gantry.</p> <p>This module provides the SqliteStore class which manages the storage and retrieval of DICOM entities (Patients, Studies, Series, Instances) using a SQLite database. It also handles sidecar storage for pixel data to keep the database lightweight.</p>"},{"location":"api/persistence/#gantry.persistence.SqliteStore","title":"<code>SqliteStore</code>","text":"<p>Handles persistence of the Object Graph to a SQLite database.</p> <p>This class manages: - CRUD operations for the Patient-&gt;Study-&gt;Series-&gt;Instance hierarchy. - Sidecar retrieval and compaction logic. - An asynchronous Audit Log for tracking modifications and errors.</p> Source code in <code>gantry/persistence.py</code> <pre><code>class SqliteStore:\n    \"\"\"\n    Handles persistence of the Object Graph to a SQLite database.\n\n    This class manages:\n    - CRUD operations for the Patient-&gt;Study-&gt;Series-&gt;Instance hierarchy.\n    - Sidecar retrieval and compaction logic.\n    - An asynchronous Audit Log for tracking modifications and errors.\n    \"\"\"\n\n    SCHEMA = \"\"\"\n    CREATE TABLE IF NOT EXISTS patients (\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\n        patient_id TEXT NOT NULL,\n        patient_name TEXT,\n        UNIQUE(patient_id)\n    );\n\n    CREATE TABLE IF NOT EXISTS studies (\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\n        patient_id_fk INTEGER,\n        study_instance_uid TEXT NOT NULL,\n        study_date TEXT,\n        FOREIGN KEY(patient_id_fk) REFERENCES patients(id),\n        UNIQUE(study_instance_uid)\n    );\n\n    CREATE TABLE IF NOT EXISTS series (\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\n        study_id_fk INTEGER,\n        series_instance_uid TEXT NOT NULL,\n        modality TEXT,\n        series_number INTEGER,\n        manufacturer TEXT,\n        model_name TEXT,\n        device_serial_number TEXT,\n        FOREIGN KEY(study_id_fk) REFERENCES studies(id),\n        UNIQUE(series_instance_uid)\n    );\n\n    CREATE TABLE IF NOT EXISTS instances (\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\n        series_id_fk INTEGER,\n        sop_instance_uid TEXT NOT NULL,\n        sop_class_uid TEXT,\n        instance_number INTEGER,\n        file_path TEXT,\n        pixel_file_id INTEGER DEFAULT 0,\n        pixel_offset INTEGER,\n        pixel_length INTEGER,\n        pixel_hash TEXT,\n        compress_alg TEXT,\n        attributes_json TEXT, -- Core attributes (Horizontal)\n        FOREIGN KEY(series_id_fk) REFERENCES series(id),\n        UNIQUE(sop_instance_uid)\n    );\n\n    CREATE TABLE IF NOT EXISTS instance_attributes (\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\n        instance_uid TEXT NOT NULL,\n        group_id TEXT NOT NULL,\n        element_id TEXT NOT NULL,\n        atom_index INTEGER DEFAULT 0,\n        value_rep TEXT,\n        value_text TEXT,\n        FOREIGN KEY(instance_uid) REFERENCES instances(sop_instance_uid) ON DELETE CASCADE,\n        UNIQUE(instance_uid, group_id, element_id, atom_index)\n    );\n\n    CREATE TABLE IF NOT EXISTS audit_log (\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\n        timestamp TEXT,\n        action_type TEXT,\n        entity_uid TEXT,\n        details TEXT\n    );\n    CREATE TABLE IF NOT EXISTS phi_findings (\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\n        timestamp TEXT,\n        entity_uid TEXT,\n        entity_type TEXT,\n        field_name TEXT,\n        value TEXT,\n        reason TEXT,\n        patient_id TEXT,\n        remediation_action TEXT,\n        remediation_value TEXT,\n        details_json TEXT\n    );\n\n    -- Indexing for Performance\n    CREATE INDEX IF NOT EXISTS idx_studies_patient_fk ON studies(patient_id_fk);\n    CREATE INDEX IF NOT EXISTS idx_series_study_fk ON series(study_id_fk);\n    CREATE INDEX IF NOT EXISTS idx_instances_series_fk ON instances(series_id_fk);\n    CREATE INDEX IF NOT EXISTS idx_audit_entity ON audit_log(entity_uid);\n    CREATE INDEX IF NOT EXISTS idx_findings_entity ON phi_findings(entity_uid);\n    CREATE INDEX IF NOT EXISTS idx_inst_attr_uid ON instance_attributes(instance_uid);\n    \"\"\"\n\n    def __init__(self, db_path: str):\n        \"\"\"\n        Initialize the SQLite store.\n\n        Args:\n            db_path (str): Path to the SQLite DB file. Use \":memory:\" for transient storage.\n        \"\"\"\n        self.db_path = db_path\n        self.logger = get_logger()\n        if db_path == \":memory:\":\n            # Use a temporary file for sidecar if DB is in-memory\n            # SidecarManager currently requires a file path (append-only logic)\n            # Create a temp file that persists until process exit (or manual cleanup)\n            # We use NamedTemporaryFile but close it so SidecarManager can open/lock it.\n            tf = tempfile.NamedTemporaryFile(suffix=\"_pixels.bin\", delete=False)\n            self.sidecar_path = tf.name\n            tf.close()\n            # Shared memory connection for :memory: database to persist across transactions\n            self._memory_conn = sqlite3.connect(\":memory:\", check_same_thread=False)\n            self._memory_conn.row_factory = sqlite3.Row\n            self._memory_lock = threading.Lock()\n        else:\n            self.sidecar_path = os.path.splitext(db_path)[0] + \"_pixels.bin\"\n            self._memory_conn = None\n            self._memory_lock = None\n\n        self.sidecar = SidecarManager(self.sidecar_path)\n        self._init_db()\n\n        # Async Audit Queue\n        self.audit_queue = queue.Queue()\n        self._stop_event = threading.Event()\n        self._audit_thread = threading.Thread(\n            target=self._audit_worker, daemon=True, name=\"AuditWorker\")\n        self._audit_thread.start()\n\n    def __getstate__(self):\n        \"\"\"Exclude threading primitives from pickling.\"\"\"\n        state = self.__dict__.copy()\n        keys_to_remove = [\n            '_memory_lock',\n            '_memory_conn',\n            'audit_queue',\n            '_stop_event',\n            '_audit_thread']\n        for k in keys_to_remove:\n            state.pop(k, None)\n        return state\n\n    def __setstate__(self, state):\n        \"\"\"Recreate threading primitives on unpickling.\"\"\"\n        self.__dict__.update(state)\n\n        # Restore non-pickleable attributes\n        if self.db_path == \":memory:\":\n            self._memory_lock = threading.Lock()\n            self._memory_conn = None  # Connection lost on pickle transfer\n        else:\n            self._memory_lock = None\n            self._memory_conn = None\n\n        self.audit_queue = queue.Queue()\n        self._stop_event = threading.Event()\n        self._audit_thread = threading.Thread(\n            target=self._audit_worker, daemon=True, name=\"AuditWorker\")\n        self._audit_thread.start()\n\n    @contextlib.contextmanager\n    def _get_connection(self):\n        \"\"\"\n        Context manager for database connections.\n        Handles persistent connection for :memory: databases.\n        \"\"\"\n        if self._memory_conn:\n            # For in-memory DB, reuse the single connection.\n            # We must serialize access because sqlite3 connections are not thread-safe\n            # for concurrent writes even with check_same_thread=False.\n            with self._memory_lock:\n                try:\n                    # print(f\"DEBUG: Acquired lock. Yielding conn {id(self._memory_conn)}\") #\n                    # Reduced spam\n                    yield self._memory_conn\n                    self._memory_conn.commit()\n                    # print(\"DEBUG: Commit successful\")\n                except Exception as e:\n                    # print(f\"DEBUG: Rollback due to {e}\")\n                    conn.rollback()\n                    raise e\n                    self._memory_conn.rollback()\n                    raise\n        else:\n            # File-based DB: create fresh connection per transaction\n            conn = sqlite3.connect(self.db_path, timeout=900.0)\n            conn.execute(\"PRAGMA synchronous=NORMAL\")\n            conn.commit()\n            conn.row_factory = sqlite3.Row\n            try:\n                yield conn\n                conn.commit()\n            except Exception as e:\n                conn.rollback()\n                raise\n            finally:\n                conn.close()\n\n    def _init_db(self):\n        with self._get_connection() as conn:\n            conn.execute(\"PRAGMA journal_mode = WAL;\")\n            conn.execute(\"PRAGMA auto_vacuum = FULL;\")\n            conn.execute(\"PRAGMA synchronous = NORMAL;\")\n            conn.executescript(self.SCHEMA)\n\n    def _create_pixel_loader(self, offset, length, alg, instance, pixel_hash=None):\n        \"\"\"Helper to create a lazy pixel loader for the sidecar.\"\"\"\n        # Use instance to populate primitives\n        return SidecarPixelLoader(self.sidecar_path, offset, length, alg, instance=instance, pixel_hash=pixel_hash)\n\n    def _audit_worker(self):\n        \"\"\"Background thread to batch write audit logs.\"\"\"\n        batch = []\n        while not self._stop_event.is_set():\n            try:\n                # Collect items with timeout\n                try:\n                    item = self.audit_queue.get(timeout=1.0)\n                    batch.append(item)\n\n                    # Drain queue up to limit\n                    while len(batch) &lt; 100:\n                        try:\n                            item = self.audit_queue.get_nowait()\n                            batch.append(item)\n                        except queue.Empty:\n                            break\n\n                except queue.Empty:\n                    pass\n\n                if batch:\n                    self.log_audit_batch(batch)\n                    batch = []\n\n            except Exception as e:\n                # Don't crash thread\n                self.logger.error(f\"Audit Worker Error: {e}\")\n\n        # Flush remaining\n        while not self.audit_queue.empty():\n            try:\n                batch.append(self.audit_queue.get_nowait())\n            except BaseException:\n                break\n        if batch:\n            self.log_audit_batch(batch)\n\n    def stop(self):\n        \"\"\"Stops the audit worker and flushes queue.\"\"\"\n        self._stop_event.set()\n        if self._audit_thread.is_alive():\n            self._audit_thread.join(timeout=2.0)\n        self.flush_audit_queue()\n\n    def flush_audit_queue(self):\n        \"\"\"Manually processes all pending items in the audit queue.\"\"\"\n        batch = []\n        while not self.audit_queue.empty():\n            try:\n                batch.append(self.audit_queue.get_nowait())\n            except queue.Empty:\n                break\n\n        if batch:\n            self.log_audit_batch(batch)\n\n    def log_audit(self, action_type: str, entity_uid: str, details: str):\n        \"\"\"Records an action in the audit log (Async).\"\"\"\n        # Push to queue instead of writing directly\n        self.audit_queue.put((action_type, entity_uid, details))\n\n    def get_audit_summary(self) -&gt; Dict[str, int]:\n        \"\"\"\n        Returns an aggregated summary of actions from the audit log.\n        Stops and restarts the background audit worker to ensure consistency.\n        Returns:\n            Dict[str, int]: e.g., {'ANONYMIZE': 500, 'EXPORT': 500}\n        \"\"\"\n        # Stop worker to ensure all in-flight batches are written\n        # This joins the thread and flushes the queue.\n        self.stop()\n\n        try:\n            with self._get_connection() as conn:\n                cursor = conn.cursor()\n                try:\n                    cursor.execute(\n                        \"SELECT action_type, COUNT(*) FROM audit_log GROUP BY action_type\")\n                    rows = cursor.fetchall()\n                    return {row[0]: row[1] for row in rows}\n                except sqlite3.OperationalError:\n                    return {}\n        finally:\n            # Restart the worker\n            self._stop_event.clear()\n            self._audit_thread = threading.Thread(\n                target=self._audit_worker, daemon=True, name=\"AuditWorker\")\n            self._audit_thread.start()\n\n    def get_audit_errors(self) -&gt; List[tuple]:\n        \"\"\"\n        Retrieves all audit logs with type ERROR or WARNING.\n        Returns:\n            List[tuple]: (timestamp, action_type, details)\n        \"\"\"\n        self.flush_audit_queue()\n        try:\n            with self._get_connection() as conn:\n                cursor = conn.cursor()\n                cursor.execute(\"\"\"\n                    SELECT timestamp, action_type, details\n                    FROM audit_log\n                    WHERE action_type IN ('ERROR', 'WARNING')\n                    ORDER BY timestamp ASC\n                \"\"\")\n                return cursor.fetchall()\n        except sqlite3.OperationalError:\n            return []\n\n    def check_unsafe_attributes(self) -&gt; List[tuple]:\n        \"\"\"\n        Scans for instances with potentially unsafe attributes (e.g., BurnedInAnnotation=\"YES\").\n        Returns:\n            List[tuple]: (sop_instance_uid, file_path, details)\n        \"\"\"\n        unsafe = []\n        try:\n            with self._get_connection() as conn:\n                cursor = conn.cursor()\n                # Naive text search in JSON.\n                # matches \"0028,0301\": \"YES\"\n                # We need to be careful about spacing in JSON serialization, but standard json.dumps usually does \": \"\n                # A safer broad check is %0028,0301%YES%\n                cursor.execute(\"\"\"\n                    SELECT sop_instance_uid, file_path\n                    FROM instances\n                    WHERE attributes_json LIKE '%\"0028,0301\": \"YES\"%'\n                \"\"\")\n                rows = cursor.fetchall()\n                for r in rows:\n                    unsafe.append((r[0], r[1], \"BurnedInAnnotation FLAGGED as YES\"))\n        except sqlite3.OperationalError:\n            pass\n        return unsafe\n\n    def log_audit_batch(self, entries: List[tuple]):\n        \"\"\"\n        Batch inserts audit logs.\n        entries: List of (action_type, entity_uid, details)\n        \"\"\"\n        if not entries:\n            return\n\n        timestamp = datetime.now().isoformat()\n        # Prepare data with timestamp: (timestamp, action, uid, details)\n        data = [(timestamp, e[0], e[1], e[2]) for e in entries]\n\n        try:\n            with self._get_connection() as conn:\n                conn.executemany(\n                    \"INSERT INTO audit_log (timestamp, action_type, entity_uid, details) VALUES (?, ?, ?, ?)\", data)\n                conn.commit()\n        except sqlite3.Error as e:\n            self.logger.error(f\"Failed to batch log audit: {e}\")\n\n    def load_all(self) -&gt; List[Patient]:\n        \"\"\"\n        Reconstructs the entire object graph from the database.\n\n        Fetches all patients, studies, series, and instances, and reassembles them\n        into the proper object hierarchy.\n\n        Returns:\n            List[Patient]: A list of all root Patient objects.\n        \"\"\"\n        patients = []\n        if self.db_path != \":memory:\" and not os.path.exists(self.db_path):\n            return patients\n\n        try:\n            with self._get_connection() as conn:\n                # conn.row_factory = sqlite3.Row  &lt;-- Handled by _get_connection\n                cur = conn.cursor()\n\n                # Optimized: We could do joins, but for clarity/mapping let's do hierarchical fetch.\n                # Or fetch all and Stitch. Stitching in memory is faster for SQLite than\n                # N+1 queries.\n\n                # 1. Fetch AlL\n                p_rows = cur.execute(\"SELECT * FROM patients\").fetchall()\n                st_rows = cur.execute(\"SELECT * FROM studies\").fetchall()\n                se_rows = cur.execute(\"SELECT * FROM series\").fetchall()\n                i_rows = cur.execute(\"SELECT * FROM instances\").fetchall()\n\n                # 2. Build Maps\n                p_map = {}\n                for r in p_rows:\n                    p = Patient(r['patient_id'], r['patient_name'])\n                    p_map[r['id']] = p\n                    patients.append(p)\n\n                st_map = {}\n                for r in st_rows:\n                    st = Study(r['study_instance_uid'], r['study_date'])\n                    st_map[r['id']] = st\n                    if r['patient_id_fk'] in p_map:\n                        p_map[r['patient_id_fk']].studies.append(st)\n\n                se_map = {}\n                for r in se_rows:\n                    se = Series(r['series_instance_uid'], r['modality'], r['series_number'])\n                    if r['manufacturer'] or r['model_name']:\n                        se.equipment = Equipment(\n                            r['manufacturer'], r['model_name'], r['device_serial_number'])\n                    se_map[r['id']] = se\n                    if r['study_id_fk'] in st_map:\n                        st_map[r['study_id_fk']].series.append(se)\n\n                for r in i_rows:\n                    inst = Instance(\n                        r['sop_instance_uid'],\n                        r['sop_class_uid'],\n                        r['instance_number'],\n                        file_path=r['file_path']\n                    )\n\n                    # Restore extra attributes\n                    if r['attributes_json']:\n                        try:\n                            attrs = json.loads(\n                                r['attributes_json'], object_hook=gantry_json_object_hook)\n                            self._deserialize_into(inst, attrs)\n                        except BaseException:\n                            pass  # JSON error\n\n                    # Wire up Sidecar Loader if present\n                    if r['pixel_offset'] is not None and r['pixel_length'] is not None:\n                        # Capture closure vars\n                        offset = r['pixel_offset']\n                        length = r['pixel_length']\n                        alg = r['compress_alg']\n\n                        # We need to reshape after loading. The dimensions are in attributes.\n                        # We can do this inside the lambda wrapper or a helper method.\n                        # But Instance.attributes aren't populated yet!\n                        # Wait, we populate attributes right after this.\n                        # So the lambda calls self.instance methods? No, lambda binds early.\n\n                        inst._pixel_loader = self._create_pixel_loader(\n                            r['pixel_offset'], r['pixel_length'], r['compress_alg'], inst)\n\n                    if r['series_id_fk'] in se_map:\n                        se_map[r['series_id_fk']].instances.append(inst)\n\n            self.logger.info(f\"Loaded {len(patients)} patients from {self.db_path}\")\n            # Mark all loaded data as clean so we don't save it back immediately\n            for p in patients:\n                p.mark_clean()\n            return patients\n\n        except sqlite3.Error as e:\n            # print(f\"DEBUG: Failed to load from DB: {e}\")\n            self.logger.error(f\"Failed to load PDF from DB: {e}\")\n            traceback.print_exc()\n            return []\n\n    def load_patient(self, patient_uid: str) -&gt; Optional[Patient]:\n        \"\"\"\n        Loads a single patient and their graph from the DB by PatientID.\n\n        Args:\n            patient_uid (str): The PatientID to search for.\n\n        Returns:\n            Optional[Patient]: The Patient object if found, else None.\n        \"\"\"\n        if self.db_path != \":memory:\" and not os.path.exists(self.db_path):\n            return None\n\n        try:\n            with self._get_connection() as conn:\n                # conn.row_factory = sqlite3.Row\n                cur = conn.cursor()\n\n                # Fetch Patient\n                p_row = cur.execute(\n                    \"SELECT * FROM patients WHERE patient_id = ?\", (patient_uid,)).fetchone()\n                if not p_row:\n                    return None\n\n                p = Patient(p_row['patient_id'], p_row['patient_name'])\n                p_pk = p_row['id']\n\n                # Fetch Studies\n                st_rows = cur.execute(\n                    \"SELECT * FROM studies WHERE patient_id_fk = ?\", (p_pk,)).fetchall()\n                for st_r in st_rows:\n                    st = Study(st_r['study_instance_uid'], st_r['study_date'])\n                    st_pk = st_r['id']\n\n                    # Fetch Series\n                    se_rows = cur.execute(\n                        \"SELECT * FROM series WHERE study_id_fk = ?\", (st_pk,)).fetchall()\n                    for se_r in se_rows:\n                        se = Series(\n                            se_r['series_instance_uid'],\n                            se_r['modality'],\n                            se_r['series_number'])\n                        if se_r['manufacturer'] or se_r['model_name']:\n                            se.equipment = Equipment(\n                                se_r['manufacturer'], se_r['model_name'], se_r['device_serial_number'])\n                        se_pk = se_r['id']\n\n                        # Fetch Instances\n                        i_rows = cur.execute(\n                            \"SELECT * FROM instances WHERE series_id_fk = ?\", (se_pk,)).fetchall()\n                        for r in i_rows:\n                            inst = Instance(\n                                r['sop_instance_uid'],\n                                r['sop_class_uid'],\n                                r['instance_number'],\n                                file_path=r['file_path']\n                            )\n                            # Wire up Sidecar (Copy-Paste logic from load_all, keep generic?)\n                            if r['attributes_json']:\n                                try:\n                                    attrs = json.loads(\n                                        r['attributes_json'], object_hook=gantry_json_object_hook)\n                                    self._deserialize_into(inst, attrs)\n                                except BaseException:\n                                    pass\n\n                            # Wire up Sidecar (Copy-Paste logic from load_all, keep generic?)\n                            if r['pixel_offset'] is not None and r['pixel_length'] is not None:\n                                offset, length, alg = r['pixel_offset'], r['pixel_length'], r['compress_alg']\n                                inst._pixel_loader = self._create_pixel_loader(\n                                    r['pixel_offset'], r['pixel_length'], r['compress_alg'], inst)\n\n                            se.instances.append(inst)\n\n                        st.series.append(se)\n                    p.studies.append(st)\n\n                p.mark_clean()\n                return p\n        except sqlite3.Error as e:\n            self.logger.error(f\"Failed to load patient: {e}\")\n            return None\n\n    def _serialize_item(self, item: Instance) -&gt; Dict[str, Any]:\n        \"\"\"\n        Serializes a DicomItem (or Instance) to a dictionary, including attributes and sequences.\n        \"\"\"\n        data = item.attributes.copy()\n        if item.sequences:\n            seq_data = {}\n            for tag, seq in item.sequences.items():\n                items_list = []\n                for seq_item in seq.items:\n                    # Recursive call for sequence items (which are DicomItems)\n                    # We can reuse logic but need to handle DicomItem vs Instance\n                    # Instance specific fields are handled by caller for the root,\n                    # but for seq items they are just DicomItems.\n                    items_list.append(self._serialize_dicom_item(seq_item))\n                seq_data[tag] = items_list\n            data['__sequences__'] = seq_data\n        return data\n\n    def _serialize_dicom_item(self, item) -&gt; Dict[str, Any]:\n        \"\"\"Helper for recursive serialization of generic DicomItems.\"\"\"\n        data = item.attributes.copy()\n        if item.sequences:\n            seq_data = {}\n            for tag, seq in item.sequences.items():\n                items_list = [self._serialize_dicom_item(i) for i in seq.items]\n                seq_data[tag] = items_list\n            data['__sequences__'] = seq_data\n        return data\n\n    def _deserialize_into(self, target_item, data: Dict[str, Any]):\n        \"\"\"\n        Populates target_item with attributes and sequences from data dict.\n        \"\"\"\n        sequences_data = data.pop('__sequences__', None)\n\n        # 1. Attributes\n        target_item.attributes.update(data)\n\n        # 2. Sequences\n        if sequences_data:\n            from .entities import DicomItem\n            for tag, items_list in sequences_data.items():\n                for item_data in items_list:\n                    new_item = DicomItem()\n                    self._deserialize_into(new_item, item_data)\n                    target_item.add_sequence_item(tag, new_item)\n\n    def save_vertical_attributes(\n            self, instance_uid: str, attributes: Dict[Tuple[str, str], Any], conn: sqlite3.Connection = None):\n        \"\"\"\n        Persists extended attributes to the vertical `instance_attributes` table.\n\n        This handles private tags and attributes that don't fit in the core JSON.\n        Uses UPSERT semantics (Delete-Insert logic currently).\n\n        Args:\n            instance_uid (str): The SOP Instance UID.\n            attributes (Dict[Tuple[str, str], Any]): Mapping of (Group, Element) hex strings to values.\n            conn (sqlite3.Connection, optional): An existing database connection to use for the transaction.\n        \"\"\"\n        if not attributes:\n            return\n\n        data_rows = []\n        for (grp, elem), val in attributes.items():\n            vr = \"UN\"  # Todo: Pass VR from caller\n            # Check for VM &gt; 1\n            if isinstance(val, list):\n                for idx, atom in enumerate(val):\n                    data_rows.append((instance_uid, grp, elem, idx, vr, str(atom)))\n            else:\n                data_rows.append((instance_uid, grp, elem, 0, vr, str(val)))\n\n        if not data_rows:\n            return\n\n        try:\n\n            # If conn is passed, use it (and don't close it/commit it here, leave to caller).\n            # If not, create new context (which commits/closes).\n            ctx = self._get_connection() if conn is None else nullcontext(conn)\n\n            with ctx as db:\n                # 1. OPTIMIZATION: Delete existing for these keys first?\n                # Or UPSERT.\n                # \"test_vertical_update_serialization\" requires correctness.\n                # UPSERT based on unique index (uid, grp, elem, atom) works.\n                # But if list shrinks (VM 3 -&gt; VM 1), UPSERT leaves atoms 2,3.\n                # So we MUST DELETE by (uid, grp, elem) before inserting new set for that tag.\n\n                # We can do this in transaction.\n                keys_to_clear = list(attributes.keys())\n                # Batch delete?\n                # \"DELETE FROM instance_attributes WHERE instance_uid=? AND group_id=? AND element_id=?\\\"\n                del_params = [(instance_uid, k[0], k[1]) for k in keys_to_clear]\n                db.executemany(\n                    \"DELETE FROM instance_attributes WHERE instance_uid=? AND group_id=? AND element_id=?\",\n                    del_params)\n\n                db.executemany(\"\"\"\n                    INSERT INTO instance_attributes (instance_uid, group_id, element_id, atom_index, value_rep, value_text)\n                    VALUES (?, ?, ?, ?, ?, ?)\n                \"\"\", data_rows)\n\n        except sqlite3.Error as e:\n            self.logger.error(f\"Failed to save vertical attributes for {instance_uid}: {e}\")\n            raise e\n\n    def load_vertical_attributes(self, instance_uid: str) -&gt; Dict[Tuple[str, str], Any]:\n        \"\"\"\n        Loads extended attributes from vertical table.\n\n        Args:\n            instance_uid (str): The SOP Instance UID.\n\n        Returns:\n            Dict[Tuple[str, str], Any]: Dictionary mapping (group, element) tuples to values.\n        \"\"\"\n        results = {}\n        try:\n            with self._get_connection() as conn:\n                rows = conn.execute(\"\"\"\n                    SELECT group_id, element_id, atom_index, value_text\n                    FROM instance_attributes\n                    WHERE instance_uid=?\n                    ORDER BY group_id, element_id, atom_index\n                \"\"\", (instance_uid,)).fetchall()\n\n                if not rows:\n                    return {}\n\n                # Reassemble\n                curr_key = None\n                collect = []\n\n                for r in rows:\n                    key = (r['group_id'], r['element_id'])\n                    val = r['value_text']  # Type conversion? Strings for now.\n\n                    if key != curr_key:\n                        # Flush previous\n                        if curr_key:\n                            results[curr_key] = collect if len(collect) &gt; 1 else collect[0]\n                        curr_key = key\n                        collect = [val]\n                    else:\n                        collect.append(val)\n\n                # Flush last\n                if curr_key:\n                    results[curr_key] = collect if len(collect) &gt; 1 else collect[0]\n\n            return results\n        except sqlite3.Error as e:\n            self.logger.error(f\"Failed to load vertical attributes for {instance_uid}: {e}\")\n            return {}\n\n    def persist_pixel_data(self, instance: Instance):\n        \"\"\"\n        Immediately persists pixel data to the sidecar to allow memory offloading.\n\n        This writes the `pixel_array` to the sidecar file and updates the instance's\n        `_pixel_loader` and `_pixel_hash`. It does NOT update the full instance record\n        in the main DB, only the pixel linkage in memory (marked dirty).\n\n        Args:\n            instance (Instance): The instance containing the pixel data to persist.\n        \"\"\"\n        if instance.pixel_array is None:\n            return\n\n        try:\n            # 1. Write to Sidecar\n            # Pass array directly to avoid .tobytes() Memory spike (Zero-Copy 500MB save)\n            b_data = instance.pixel_array\n\n            # Hash Update (CRITICAL for Integrity Checks)\n            # Calculate Hash BEFORE writing/compression to ensure we capture the state\n            # exactly as it goes into the pipe.\n            import hashlib\n            # Ensure we are hashing the contiguous bytes\n            if hasattr(b_data, 'tobytes'):\n                p_hash = hashlib.sha256(b_data.tobytes()).hexdigest()\n            else:\n                p_hash = hashlib.sha256(b_data).hexdigest()\n\n            instance._pixel_hash = p_hash\n\n            # Determine suitable compression? Defaulting to zlib for swap.\n            # Ideally we respect original or config, but for swap zlib is safe/fast enough.\n            c_alg = 'zlib'\n\n            offset, length = self.sidecar.write_frame(b_data, c_alg)\n\n            # 2. Update Instance Loader\n            # This allows instance.unload_pixel_data() to work safely\n            # Note: instance attributes ARE populated here (it's a live object), so\n            # passing instance=instance works.\n            instance._pixel_loader = self._create_pixel_loader(\n                offset, length, c_alg, instance, pixel_hash=p_hash)\n\n            # 3. Optional: Persist the linkage to DB immediately?\n            # It's safer if we do, so if we crash, we know where the pixels are.\n            # However, if we don't save the attributes/UID changes, the DB is out of sync anyway.\n            # But the primary goal here is MEMORY MANAGEMENT.\n            # So updating the object state in memory (step 2) is sufficient for unload_pixel_data() to return True.\n            # The final session.save() will record the new offset/length into the DB\n            # instances table.\n\n            # CRITICAL: Mark instance as dirty so save_all() knows to update the DB with the new loader/hash!\n            # If we don't do this, save_all might skip this instance if it was otherwise clean,\n            # leaving the DB pointing to old/original data while memory points to new sidecar data.\n            instance._mod_count += 1\n\n        except Exception as e:\n            self.logger.error(f\"Failed to persist pixel swap for {instance.sop_instance_uid}: {e}\")\n            raise e\n\n    def save_all(self, patients: List[Patient]):\n        \"\"\"\n        Incrementally persists the provided patients and their graph to the database.\n\n        Uses UPSERT logic to update existing records and Insert new ones.\n        Only processes entities marked as `_dirty`.\n\n        Args:\n            patients (List[Patient]): The list of patient objects to save.\n        \"\"\"\n        self.logger.info(f\"Saving {len(patients)} patients to {self.db_path} (Incremental)...\")\n\n        pixel_bytes_written = 0\n        pixel_frames_written = 0\n        sidecar_manager = self.sidecar\n\n        try:\n            with self._get_connection() as conn:\n                cur = conn.cursor()\n\n                # Check for schema compatibility (simple check)\n                try:\n                    # We rely on UNIQUE constraints for UPSERT.\n                    # If older DB without constraints, we might fail or duplicate.\n                    pass\n                except BaseException:\n                    pass\n\n                # Counts for reporting\n                saved_p, saved_st, saved_se, saved_i = 0, 0, 0, 0\n\n                for p in patients:\n                    # Patient Level (Always Check Dirty)\n                    if getattr(p, '_dirty', True):\n                        cur.execute(\"\"\"\n                            INSERT INTO patients (patient_id, patient_name) VALUES (?, ?)\n                            ON CONFLICT(patient_id) DO UPDATE SET patient_name=excluded.patient_name\n                        \"\"\", (p.patient_id, p.patient_name))\n                        saved_p += 1\n\n                    # We need the PK for children\n                    # Since we might have just updated or it might exist, we select it.\n                    # Optimization: Cache PKs? For now, fetch is safe.\n                    p_pk_row = cur.execute(\n                        \"SELECT id FROM patients WHERE patient_id=?\", (p.patient_id,)).fetchone()\n                    if not p_pk_row:\n                        continue  # Should not happen after Insert\n                    p_pk = p_pk_row[0]\n\n                    for st in p.studies:\n                        if getattr(st, '_dirty', True):\n                            # FIX: Convert date objects to string to avoid Python 3.12+\n                            # DeprecationWarning for default adapter\n                            s_date = st.study_date\n                            if hasattr(s_date, \"isoformat\"):\n                                s_date = s_date.isoformat()\n                            elif s_date is not None:\n                                s_date = str(s_date)\n\n                            cur.execute(\"\"\"\n                                INSERT INTO studies (patient_id_fk, study_instance_uid, study_date) VALUES (?, ?, ?)\n                                ON CONFLICT(study_instance_uid) DO UPDATE SET\n                                    study_date=excluded.study_date,\n                                    patient_id_fk=excluded.patient_id_fk\n                            \"\"\", (p_pk, st.study_instance_uid, s_date))\n                            saved_st += 1\n\n                        st_pk_row = cur.execute(\n                            \"SELECT id FROM studies WHERE study_instance_uid=?\", (st.study_instance_uid,)).fetchone()\n                        if not st_pk_row:\n                            continue\n                        st_pk = st_pk_row[0]\n\n                        for se in st.series:\n                            if getattr(se, '_dirty', True):\n                                man = se.equipment.manufacturer if se.equipment else \"\"\n                                mod = se.equipment.model_name if se.equipment else \"\"\n                                sn = se.equipment.device_serial_number if se.equipment else \"\"\n\n                                cur.execute(\"\"\"\n                                    INSERT INTO series (study_id_fk, series_instance_uid, modality, series_number, manufacturer, model_name, device_serial_number)\n                                    VALUES (?, ?, ?, ?, ?, ?, ?)\n                                    ON CONFLICT(series_instance_uid) DO UPDATE SET\n                                        modality=excluded.modality,\n                                        series_number=excluded.series_number,\n                                        manufacturer=excluded.manufacturer,\n                                        model_name=excluded.model_name,\n                                        device_serial_number=excluded.device_serial_number,\n                                        study_id_fk=excluded.study_id_fk\n                                \"\"\", (st_pk, se.series_instance_uid, se.modality, se.series_number, man, mod, sn))\n                                saved_se += 1\n\n                            se_pk_row = cur.execute(\n                                \"SELECT id FROM series WHERE series_instance_uid=?\", (se.series_instance_uid,)).fetchone()\n                            if not se_pk_row:\n                                continue\n                            se_pk = se_pk_row[0]\n\n                            # --- Deletion Handling (Diff DB vs Memory) ---\n                            # Only perform if we suspect deletions or periodically?\n                            # Plan says: Implement Diff Logic.\n                            # Optimization: If series is NOT dirty, can we assume no deletions?\n                            # Not necessarily. Removing an item doesn't always mark Series dirty unless we hook \"remove\".\n                            # But DicomItem doesn't track removals from list automatically.\n                            # So we must check.\n\n                            db_uids_rows = cur.execute(\n                                \"SELECT sop_instance_uid FROM instances WHERE series_id_fk=?\", (se_pk,)).fetchall()\n                            db_uids = {r[0] for r in db_uids_rows}\n                            mem_uids = {i.sop_instance_uid for i in se.instances}\n\n                            to_delete = db_uids - mem_uids\n                            if to_delete:\n                                cur.executemany(\n                                    \"DELETE FROM instances WHERE sop_instance_uid=?\", [\n                                        (u,) for u in to_delete])\n                                saved_i += 0  # Or count negative?\n                                # self.logger.debug(f\"Deleted {len(to_delete)} instances from Series {se.series_instance_uid}\")\n\n                            # --- Upsert Dirty ---\n                            dirty_items = []\n                            for i in se.instances:\n                                if getattr(i, '_dirty', True):\n                                    # Capture version if available (robustness against race)\n                                    ver = getattr(i, '_mod_count', 0)\n                                    dirty_items.append((i, ver))\n\n                            if dirty_items:\n                                i_batch = []\n                                vert_updates = []  # Defer vertical updates to satisfy foreign key\n                                for inst, ver in dirty_items:\n                                    full_data = self._serialize_item(inst)\n\n                                    # Split Core vs Vertical (Private Tags -&gt; Vertical Table)\n                                    core_data = {}\n                                    vert_data = {}\n\n                                    for key, val in full_data.items():\n                                        if key == \"__sequences__\":\n                                            # Keep sequences in Core JSON for now\n                                            core_data[key] = val\n                                            continue\n\n                                        # key is \"GGGG,EEEE\" hex string\n                                        try:\n                                            group = int(key.split(',')[0], 16)\n                                            # Odd Group = Private Tag (usually)\n                                            # Skip Vertical for BYTES (cant be stored as TEXT\n                                            # easily, keep in JSON)\n                                            is_private = (\n                                                group %\n                                                2 != 0) and not isinstance(\n                                                val, bytes)\n\n                                            if is_private:\n                                                # Tuple key for vertical method: (grp, elem)\n                                                k_tuple = tuple(key.split(','))\n                                                vert_data[k_tuple] = val\n                                            else:\n                                                core_data[key] = val\n                                        except BaseException:\n                                            core_data[key] = val\n\n                                    # Queue Vertical (Saved after Instance Insert)\n                                    if vert_data:\n                                        vert_updates.append((inst.sop_instance_uid, vert_data))\n\n                                    # Serialize Core\n                                    attrs_json = json.dumps(core_data, cls=GantryJSONEncoder)\n\n                                    p_offset, p_length, p_alg, p_hash = None, None, None, None\n\n                                    if inst.pixel_array is not None:\n                                        b_data = inst.pixel_array.tobytes()\n                                        c_alg = 'zlib'\n                                        # Compute Hash\n                                        # Compute Hash\n                                        # Compute Hash\n                                        p_hash = hashlib.sha256(b_data).hexdigest()\n\n                                        # Deduplication: If already persisted with same hash, skip\n                                        # write\n                                        if getattr(\n                                                inst, '_pixel_hash', None) == p_hash and isinstance(\n                                                inst._pixel_loader, SidecarPixelLoader):\n                                            p_offset = inst._pixel_loader.offset\n                                            p_length = inst._pixel_loader.length\n                                            p_alg = inst._pixel_loader.alg\n                                        else:\n                                            off, leng = sidecar_manager.write_frame(b_data, c_alg)\n                                            p_offset, p_length, p_alg = off, leng, c_alg\n                                            pixel_bytes_written += leng\n                                            pixel_frames_written += 1\n\n                                            # Update loader so we can unload safely later\n                                            inst._pixel_loader = self._create_pixel_loader(\n                                                off, leng, c_alg, inst)\n\n                                        inst._pixel_hash = p_hash  # Cache on instance\n\n                                    elif isinstance(inst._pixel_loader, SidecarPixelLoader):\n                                        # Already persisted (swapped), preserve metadata\n                                        p_offset = inst._pixel_loader.offset\n                                        p_length = inst._pixel_loader.length\n                                        p_alg = inst._pixel_loader.alg\n                                        p_hash = getattr(inst, '_pixel_hash', None)\n                                    else:\n                                        pass\n\n                                    i_batch.append((\n                                        se_pk,\n                                        inst.sop_instance_uid,\n                                        inst.sop_class_uid,\n                                        inst.instance_number,\n                                        inst.file_path,\n                                        p_offset,\n                                        p_length,\n                                        p_hash,\n                                        p_alg,\n                                        attrs_json\n                                    ))\n\n                                cur.executemany(\"\"\"\n                                    INSERT INTO instances (series_id_fk, sop_instance_uid, sop_class_uid, instance_number, file_path,\n                                                           pixel_offset, pixel_length, pixel_hash, compress_alg, attributes_json)\n                                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n                                    ON CONFLICT(sop_instance_uid) DO UPDATE SET\n                                        series_id_fk=excluded.series_id_fk,\n                                        sop_class_uid=excluded.sop_class_uid,\n                                        instance_number=excluded.instance_number,\n                                        file_path=excluded.file_path,\n                                        attributes_json=excluded.attributes_json,\n                                        pixel_offset=COALESCE(excluded.pixel_offset, instances.pixel_offset),\n                                        pixel_length=COALESCE(excluded.pixel_length, instances.pixel_length),\n                                        pixel_hash=COALESCE(excluded.pixel_hash, instances.pixel_hash),\n                                        compress_alg=COALESCE(excluded.compress_alg, instances.compress_alg)\n                                \"\"\", i_batch)\n\n                                # Process Deferred Vertical Updates (Now that Instances exist)\n                                if vert_updates:\n                                    # self.logger.debug(f\"Saving vertical attributes for {len(vert_updates)} instances\")\n                                    for uid, v_data in vert_updates:\n                                        self.save_vertical_attributes(uid, v_data, conn=conn)\n\n                                saved_i += len(dirty_items)\n\n                                # Mark saved with version (deferred until commit success?\n                                # No, we can attach to list and do it post-commit)\n                                # But we're inside loops.\n                                # Creating a cleanup list:\n                                # (We can store dirty_items in a larger list to clean up post-commit)\n                                # For now, let's mark clean *assuming* commit will succeed.\n                                # If commit fails, we rollback, but objects remain \"clean\" in memory?\n                                # That is a risk. We should do it post-commit.\n                                # But scope is tricky.\n                                # Let's mark clean here but using version.\n                                # If transaction rolls back, DB is old, but memory has _saved_mod_count advanced?\n                                # That means next save won't save it. BAD.\n                                # We must hold off.\n\n                                # Since we commit once at the end:\n                                # We need to collect ALL dirty items and their versions.\n                                # That is expensive memory-wise for massive sets.\n                                # But necessary for correctness.\n                                # Compromise: we iterate again.\n                                # Wait, \"Iterate again\" in 'mark clean' loop below.\n                                # We can't know \"ver\" then.\n\n                                # Let's just update them here. If commit fails, the Exception propagates.\n                                # Use a try/except block around the whole `save_all`? Yes.\n                                # But `_saved_mod_count` is in memory.\n                                # If we update it, and `save_all` crashes, we can't easily undo it.\n                                # BUT `save_all` crashing usually kills the process or stops persistence.\n                                # So `eventual consistency` implies retrying.\n                                # If we marked it saved but it didn't save, we have data loss.\n\n                                # Correct way: List of callbacks?\n                                # Or just:\n                                for inst, ver in dirty_items:\n                                    if hasattr(inst, 'mark_saved'):\n                                        inst.mark_saved(ver)\n                                    else:\n                                        inst._dirty = False\n\n                conn.commit()\n\n                # Post-Commit:\n                # We already marked items as saved/clean incrementally using naive-commit assumption.\n                # If transaction failed, those items are marked clean in memory but not in DB -&gt; Inconsistency.\n                # However, re-implementing rollback for memory objects is out of scope.\n                # The versioning fixes the \"Overwrite valid change\" race, which is the user's issue.\n                pass\n\n                # Restore Logging Logic\n                if saved_p + saved_i &gt; 0:\n                    msg = f\"Save (Inc) complete. P:{saved_p} St:{saved_st} Se:{saved_se} I:{saved_i}.\"\n                    if pixel_frames_written &gt; 0:\n                        mb = pixel_bytes_written / (1024 * 1024)\n                        msg += f\" Sidecar: {pixel_frames_written} frames ({mb:.2f} MB).\"\n                    self.logger.info(msg)\n\n        except Exception as e:\n            self.logger.error(f\"Save failed: {e}\")\n            if hasattr(conn, \"rollback\"):\n                conn.rollback()\n            raise\n\n    def get_total_instances(self) -&gt; int:\n        \"\"\"\n        Returns the total number of instances currently persisted.\n\n        Returns:\n            int: The count of rows in the instances table.\n        \"\"\"\n        try:\n            with self._get_connection() as conn:\n                cur = conn.cursor()\n                row = cur.execute(\"SELECT COUNT(*) FROM instances\").fetchone()\n                return row[0] if row else 0\n        except sqlite3.Error as e:\n            self.logger.error(f\"Failed to count instances: {e}\")\n            return 0\n\n    def get_flattened_instances(self,\n                                patient_ids: List[str] = None,\n                                instance_uids: List[str] = None):\n        \"\"\"\n        Yields a flat dictionary for every instance in the DB.\n\n        Useful for streaming exports or analysis without loading the entire graph into RAM.\n\n        Args:\n            patient_ids (List[str], optional): Filter by list of Patient IDs.\n            instance_uids (List[str], optional): Filter by list of SOP Instance UIDs.\n\n        Yields:\n            dict: Flattend dictionary representing row data (patient, study, series, instance paths).\n        \"\"\"\n        # We use a managed connection that stays open during iteration\n        with self._get_connection() as conn:\n            # conn.row_factory = sqlite3.Row\n            cur = conn.cursor()\n\n            query = \"\"\"\n                SELECT\n                    p.patient_id, p.patient_name,\n                    st.study_instance_uid, st.study_date,\n                    s.series_instance_uid, s.modality, s.series_number, s.manufacturer, s.model_name, s.device_serial_number,\n                    i.sop_instance_uid, i.sop_class_uid, i.instance_number, i.file_path,\n                    i.pixel_offset, i.pixel_length, i.compress_alg, i.attributes_json\n                FROM instances i\n                JOIN series s ON i.series_id_fk = s.id\n                JOIN studies st ON s.study_id_fk = st.id\n                JOIN patients p ON st.patient_id_fk = p.id\n            \"\"\"\n\n            conditions = []\n            params = []\n\n            if patient_ids:\n                placeholders = \",\".join(\"?\" for _ in patient_ids)\n                conditions.append(f\"p.patient_id IN ({placeholders})\")\n                params.extend(patient_ids)\n\n            if instance_uids:\n                placeholders = \",\".join(\"?\" for _ in instance_uids)\n                conditions.append(f\"i.sop_instance_uid IN ({placeholders})\")\n                params.extend(instance_uids)\n\n            if conditions:\n                query += \" WHERE \" + \" AND \".join(conditions)\n\n            # Execute generator\n            cursor = cur.execute(query, params)\n\n            # We can map columns to names\n            cols = [desc[0] for desc in cursor.description]\n\n            for row in cursor:\n                yield dict(zip(cols, row))\n\n    def update_attributes(self, instances: List[Patient]):\n        \"\"\"\n        Efficiently updates the attributes_json for a list of instances.\n\n        Used when only attributes have changed (e.g., after locking identities)\n        to avoid full graph traversal.\n\n        Args:\n            instances (List[Instance]): The list of instances to update.\n        \"\"\"\n        if not instances:\n            return\n\n        self.logger.info(f\"Updating attributes for {len(instances)} instances...\")\n        try:\n            with self._get_connection() as conn:\n                cur = conn.cursor()\n\n                # Pre-calculate data for executemany\n                data = []\n                for inst in instances:\n                    # Serialize attributes AND sequences\n                    full_data = self._serialize_item(inst)\n                    attrs_json = json.dumps(full_data, cls=GantryJSONEncoder)\n                    data.append((attrs_json, inst.sop_instance_uid))\n\n                cur.executemany(\"\"\"\n                    UPDATE instances\n                    SET attributes_json = ?\n                    WHERE sop_instance_uid = ?\n                \"\"\", data)\n\n                conn.commit()\n                self.logger.info(\"Update complete.\")\n\n        except sqlite3.Error as e:\n            self.logger.error(f\"Failed to update attributes: {e}\")\n\n    def save_findings(self, findings: List[PhiFinding]):\n        \"\"\"\n        Persists PHI findings to the database.\n\n        Args:\n            findings (List[PhiFinding]): List of finding objects to insert.\n        \"\"\"\n        timestamp = datetime.now().isoformat()\n\n        if not findings:\n            return\n\n        self.logger.info(f\"Saving {len(findings)} PHI findings...\")\n\n        try:\n            with self._get_connection() as conn:\n                cur = conn.cursor()\n\n                # Prepare Data Generator for Batch Insert (Memory Efficient)\n                def findings_generator():\n                    for f in findings:\n                        rem_action = None\n                        rem_value = None\n                        if f.remediation_proposal:\n                            rem_action = f.remediation_proposal.action_type\n                            rem_value = str(f.remediation_proposal.new_value)\n\n                        yield (\n                            timestamp,\n                            f.entity_uid,\n                            f.entity_type,\n                            f.field_name,\n                            str(f.value),\n                            f.reason,\n                            f.patient_id,\n                            rem_action,\n                            rem_value,\n                            \"{}\"\n                        )\n\n                cur.executemany(\"\"\"\n                    INSERT INTO phi_findings\n                    (timestamp, entity_uid, entity_type, field_name, value, reason, patient_id, remediation_action, remediation_value, details_json)\n                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n                \"\"\", findings_generator())\n\n                conn.commit()\n                self.logger.info(\"Findings saved.\")\n\n        except sqlite3.Error as e:\n            self.logger.error(f\"Failed to save findings: {e}\")\n\n    def load_findings(self) -&gt; List[PhiFinding]:\n        \"\"\"\n        Loads all findings from the database.\n\n        Returns:\n            List[PhiFinding]: All persisted PHI findings.\n        \"\"\"\n        findings = []\n        if self.db_path != \":memory:\" and not os.path.exists(self.db_path):\n            return findings\n\n        try:\n            with self._get_connection() as conn:\n                # conn.row_factory = sqlite3.Row\n                cur = conn.cursor()\n                # Check if table exists (backward compatibility for old DBs if init didnt run on them)\n                # But _init_db runs on __init__, so schema should be there.\n\n                rows = cur.execute(\"SELECT * FROM phi_findings ORDER BY id\").fetchall()\n\n                for r in rows:\n                    if r['remediation_action']:\n                        prop = PhiRemediation(\n                            r['remediation_action'],\n                            r['field_name'],\n                            r['remediation_value'],\n                            None)\n                    else:\n                        prop = None\n\n                    f = PhiFinding(\n                        entity_uid=r['entity_uid'],\n                        entity_type=r['entity_type'],\n                        field_name=r['field_name'],\n                        value=r['value'],\n                        reason=r['reason'],\n                        patient_id=r['patient_id'],\n                        remediation_proposal=prop\n                    )\n                    findings.append(f)\n\n        except sqlite3.Error as e:\n            self.logger.error(f\"Failed to load findings: {e}\")\n\n        return findings\n\n    def compact_sidecar(self) -&gt; Dict[str, Tuple[int, int]]:\n        \"\"\"\n        Reclaims disk space by rewriting the sidecar file.\n\n        Removes unreferenced (orphaned) pixel data that might exist due to deletions\n        or updates. Updates the database pointers efficiently.\n\n        Returns:\n            Dict[str, Tuple[int, int]]: A map of SOP Instance UIDs to their new (offset, length).\n        \"\"\"\n        self.logger.info(\"Starting Sidecar Compaction...\")\n        start_time = time.time()\n\n        # 1. Get Live Index (Sorted)\n        # We only care about instances that actully point to the sidecar (pixel_offset IS NOT NULL)\n        try:\n            with self._get_connection() as conn:\n                cur = conn.cursor()\n                rows = cur.execute(\"\"\"\n                    SELECT id, sop_instance_uid, pixel_offset, pixel_length\n                    FROM instances\n                    WHERE pixel_offset IS NOT NULL\n                    ORDER BY pixel_offset ASC\n                \"\"\").fetchall()\n        except sqlite3.Error as e:\n            self.logger.error(f\"Compaction Failed (Query): {e}\")\n            raise e\n\n        if not rows:\n            self.logger.info(\"No live pixels found in sidecar. Compaction skipped.\")\n            return {}\n\n\n        temp_path = self.sidecar_path + \".compact.tmp\"\n        updates = []\n        uid_map = {}  # sop_instance_uid -&gt; (offset, length)\n        original_size = os.path.getsize(self.sidecar_path)\n        written_bytes = 0\n\n        try:\n            # 2. Rewrite\n            with open(self.sidecar_path, \"rb\") as f_in, open(temp_path, \"wb\") as f_out:\n                current_out_pos = 0\n\n                for r in rows:\n                    if r['pixel_length'] &lt;= 0:\n                        continue\n\n                    # Read\n                    f_in.seek(r['pixel_offset'])\n                    data = f_in.read(r['pixel_length'])\n\n                    if len(data) != r['pixel_length']:\n                        self.logger.warning(\n                            f\"Compaction Warning: Unexpected EOF for instance ID {\n                                r['id']}\")\n\n                    # Write\n                    f_out.write(data)\n                    length = len(data)\n\n                    # Record change\n                    # (new_offset, instance_id)\n                    updates.append((current_out_pos, r['id']))\n                    uid_map[r['sop_instance_uid']] = (current_out_pos, length)\n\n                    current_out_pos += length\n\n                written_bytes = current_out_pos\n\n            # 3. Update DB (Transaction)\n            with self._get_connection() as conn:\n                conn.executemany(\"UPDATE instances SET pixel_offset=? WHERE id=?\", updates)\n\n            # 4. Swap Files\n            shutil.move(temp_path, self.sidecar_path)\n\n            # 5. Reset Manager\n            self.sidecar = SidecarManager(self.sidecar_path)\n\n            duration = time.time() - start_time\n            saved_space = original_size - written_bytes\n            self.logger.info(\n                f\"Compaction Complete in {\n                    duration:.2f}s. Size: {original_size} -&gt; {written_bytes} bytes. Reclaimed: {saved_space} bytes.\")\n            print(\n                f\"Compaction Complete. Size: {\n                    original_size /\n                    1024 /\n                    1024:.2f}MB -&gt; {\n                    written_bytes /\n                    1024 /\n                    1024:.2f}MB. Reclaimed: {\n                    saved_space /\n                    1024 /\n                    1024:.2f}MB.\")\n\n            return uid_map\n\n        except Exception as e:\n            self.logger.error(f\"Compaction Failed: {e}\")\n            if os.path.exists(temp_path):\n                try:\n                    os.remove(temp_path)\n                except BaseException:\n                    pass\n            raise e\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Exclude threading primitives from pickling.</p> Source code in <code>gantry/persistence.py</code> <pre><code>def __getstate__(self):\n    \"\"\"Exclude threading primitives from pickling.\"\"\"\n    state = self.__dict__.copy()\n    keys_to_remove = [\n        '_memory_lock',\n        '_memory_conn',\n        'audit_queue',\n        '_stop_event',\n        '_audit_thread']\n    for k in keys_to_remove:\n        state.pop(k, None)\n    return state\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.__init__","title":"<code>__init__(db_path)</code>","text":"<p>Initialize the SQLite store.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>Path to the SQLite DB file. Use \":memory:\" for transient storage.</p> required Source code in <code>gantry/persistence.py</code> <pre><code>def __init__(self, db_path: str):\n    \"\"\"\n    Initialize the SQLite store.\n\n    Args:\n        db_path (str): Path to the SQLite DB file. Use \":memory:\" for transient storage.\n    \"\"\"\n    self.db_path = db_path\n    self.logger = get_logger()\n    if db_path == \":memory:\":\n        # Use a temporary file for sidecar if DB is in-memory\n        # SidecarManager currently requires a file path (append-only logic)\n        # Create a temp file that persists until process exit (or manual cleanup)\n        # We use NamedTemporaryFile but close it so SidecarManager can open/lock it.\n        tf = tempfile.NamedTemporaryFile(suffix=\"_pixels.bin\", delete=False)\n        self.sidecar_path = tf.name\n        tf.close()\n        # Shared memory connection for :memory: database to persist across transactions\n        self._memory_conn = sqlite3.connect(\":memory:\", check_same_thread=False)\n        self._memory_conn.row_factory = sqlite3.Row\n        self._memory_lock = threading.Lock()\n    else:\n        self.sidecar_path = os.path.splitext(db_path)[0] + \"_pixels.bin\"\n        self._memory_conn = None\n        self._memory_lock = None\n\n    self.sidecar = SidecarManager(self.sidecar_path)\n    self._init_db()\n\n    # Async Audit Queue\n    self.audit_queue = queue.Queue()\n    self._stop_event = threading.Event()\n    self._audit_thread = threading.Thread(\n        target=self._audit_worker, daemon=True, name=\"AuditWorker\")\n    self._audit_thread.start()\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.__setstate__","title":"<code>__setstate__(state)</code>","text":"<p>Recreate threading primitives on unpickling.</p> Source code in <code>gantry/persistence.py</code> <pre><code>def __setstate__(self, state):\n    \"\"\"Recreate threading primitives on unpickling.\"\"\"\n    self.__dict__.update(state)\n\n    # Restore non-pickleable attributes\n    if self.db_path == \":memory:\":\n        self._memory_lock = threading.Lock()\n        self._memory_conn = None  # Connection lost on pickle transfer\n    else:\n        self._memory_lock = None\n        self._memory_conn = None\n\n    self.audit_queue = queue.Queue()\n    self._stop_event = threading.Event()\n    self._audit_thread = threading.Thread(\n        target=self._audit_worker, daemon=True, name=\"AuditWorker\")\n    self._audit_thread.start()\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.check_unsafe_attributes","title":"<code>check_unsafe_attributes()</code>","text":"<p>Scans for instances with potentially unsafe attributes (e.g., BurnedInAnnotation=\"YES\"). Returns:     List[tuple]: (sop_instance_uid, file_path, details)</p> Source code in <code>gantry/persistence.py</code> <pre><code>def check_unsafe_attributes(self) -&gt; List[tuple]:\n    \"\"\"\n    Scans for instances with potentially unsafe attributes (e.g., BurnedInAnnotation=\"YES\").\n    Returns:\n        List[tuple]: (sop_instance_uid, file_path, details)\n    \"\"\"\n    unsafe = []\n    try:\n        with self._get_connection() as conn:\n            cursor = conn.cursor()\n            # Naive text search in JSON.\n            # matches \"0028,0301\": \"YES\"\n            # We need to be careful about spacing in JSON serialization, but standard json.dumps usually does \": \"\n            # A safer broad check is %0028,0301%YES%\n            cursor.execute(\"\"\"\n                SELECT sop_instance_uid, file_path\n                FROM instances\n                WHERE attributes_json LIKE '%\"0028,0301\": \"YES\"%'\n            \"\"\")\n            rows = cursor.fetchall()\n            for r in rows:\n                unsafe.append((r[0], r[1], \"BurnedInAnnotation FLAGGED as YES\"))\n    except sqlite3.OperationalError:\n        pass\n    return unsafe\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.compact_sidecar","title":"<code>compact_sidecar()</code>","text":"<p>Reclaims disk space by rewriting the sidecar file.</p> <p>Removes unreferenced (orphaned) pixel data that might exist due to deletions or updates. Updates the database pointers efficiently.</p> <p>Returns:</p> Type Description <code>Dict[str, Tuple[int, int]]</code> <p>Dict[str, Tuple[int, int]]: A map of SOP Instance UIDs to their new (offset, length).</p> Source code in <code>gantry/persistence.py</code> <pre><code>def compact_sidecar(self) -&gt; Dict[str, Tuple[int, int]]:\n    \"\"\"\n    Reclaims disk space by rewriting the sidecar file.\n\n    Removes unreferenced (orphaned) pixel data that might exist due to deletions\n    or updates. Updates the database pointers efficiently.\n\n    Returns:\n        Dict[str, Tuple[int, int]]: A map of SOP Instance UIDs to their new (offset, length).\n    \"\"\"\n    self.logger.info(\"Starting Sidecar Compaction...\")\n    start_time = time.time()\n\n    # 1. Get Live Index (Sorted)\n    # We only care about instances that actully point to the sidecar (pixel_offset IS NOT NULL)\n    try:\n        with self._get_connection() as conn:\n            cur = conn.cursor()\n            rows = cur.execute(\"\"\"\n                SELECT id, sop_instance_uid, pixel_offset, pixel_length\n                FROM instances\n                WHERE pixel_offset IS NOT NULL\n                ORDER BY pixel_offset ASC\n            \"\"\").fetchall()\n    except sqlite3.Error as e:\n        self.logger.error(f\"Compaction Failed (Query): {e}\")\n        raise e\n\n    if not rows:\n        self.logger.info(\"No live pixels found in sidecar. Compaction skipped.\")\n        return {}\n\n\n    temp_path = self.sidecar_path + \".compact.tmp\"\n    updates = []\n    uid_map = {}  # sop_instance_uid -&gt; (offset, length)\n    original_size = os.path.getsize(self.sidecar_path)\n    written_bytes = 0\n\n    try:\n        # 2. Rewrite\n        with open(self.sidecar_path, \"rb\") as f_in, open(temp_path, \"wb\") as f_out:\n            current_out_pos = 0\n\n            for r in rows:\n                if r['pixel_length'] &lt;= 0:\n                    continue\n\n                # Read\n                f_in.seek(r['pixel_offset'])\n                data = f_in.read(r['pixel_length'])\n\n                if len(data) != r['pixel_length']:\n                    self.logger.warning(\n                        f\"Compaction Warning: Unexpected EOF for instance ID {\n                            r['id']}\")\n\n                # Write\n                f_out.write(data)\n                length = len(data)\n\n                # Record change\n                # (new_offset, instance_id)\n                updates.append((current_out_pos, r['id']))\n                uid_map[r['sop_instance_uid']] = (current_out_pos, length)\n\n                current_out_pos += length\n\n            written_bytes = current_out_pos\n\n        # 3. Update DB (Transaction)\n        with self._get_connection() as conn:\n            conn.executemany(\"UPDATE instances SET pixel_offset=? WHERE id=?\", updates)\n\n        # 4. Swap Files\n        shutil.move(temp_path, self.sidecar_path)\n\n        # 5. Reset Manager\n        self.sidecar = SidecarManager(self.sidecar_path)\n\n        duration = time.time() - start_time\n        saved_space = original_size - written_bytes\n        self.logger.info(\n            f\"Compaction Complete in {\n                duration:.2f}s. Size: {original_size} -&gt; {written_bytes} bytes. Reclaimed: {saved_space} bytes.\")\n        print(\n            f\"Compaction Complete. Size: {\n                original_size /\n                1024 /\n                1024:.2f}MB -&gt; {\n                written_bytes /\n                1024 /\n                1024:.2f}MB. Reclaimed: {\n                saved_space /\n                1024 /\n                1024:.2f}MB.\")\n\n        return uid_map\n\n    except Exception as e:\n        self.logger.error(f\"Compaction Failed: {e}\")\n        if os.path.exists(temp_path):\n            try:\n                os.remove(temp_path)\n            except BaseException:\n                pass\n        raise e\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.flush_audit_queue","title":"<code>flush_audit_queue()</code>","text":"<p>Manually processes all pending items in the audit queue.</p> Source code in <code>gantry/persistence.py</code> <pre><code>def flush_audit_queue(self):\n    \"\"\"Manually processes all pending items in the audit queue.\"\"\"\n    batch = []\n    while not self.audit_queue.empty():\n        try:\n            batch.append(self.audit_queue.get_nowait())\n        except queue.Empty:\n            break\n\n    if batch:\n        self.log_audit_batch(batch)\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.get_audit_errors","title":"<code>get_audit_errors()</code>","text":"<p>Retrieves all audit logs with type ERROR or WARNING. Returns:     List[tuple]: (timestamp, action_type, details)</p> Source code in <code>gantry/persistence.py</code> <pre><code>def get_audit_errors(self) -&gt; List[tuple]:\n    \"\"\"\n    Retrieves all audit logs with type ERROR or WARNING.\n    Returns:\n        List[tuple]: (timestamp, action_type, details)\n    \"\"\"\n    self.flush_audit_queue()\n    try:\n        with self._get_connection() as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"\"\"\n                SELECT timestamp, action_type, details\n                FROM audit_log\n                WHERE action_type IN ('ERROR', 'WARNING')\n                ORDER BY timestamp ASC\n            \"\"\")\n            return cursor.fetchall()\n    except sqlite3.OperationalError:\n        return []\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.get_audit_summary","title":"<code>get_audit_summary()</code>","text":"<p>Returns an aggregated summary of actions from the audit log. Stops and restarts the background audit worker to ensure consistency. Returns:     Dict[str, int]: e.g., {'ANONYMIZE': 500, 'EXPORT': 500}</p> Source code in <code>gantry/persistence.py</code> <pre><code>def get_audit_summary(self) -&gt; Dict[str, int]:\n    \"\"\"\n    Returns an aggregated summary of actions from the audit log.\n    Stops and restarts the background audit worker to ensure consistency.\n    Returns:\n        Dict[str, int]: e.g., {'ANONYMIZE': 500, 'EXPORT': 500}\n    \"\"\"\n    # Stop worker to ensure all in-flight batches are written\n    # This joins the thread and flushes the queue.\n    self.stop()\n\n    try:\n        with self._get_connection() as conn:\n            cursor = conn.cursor()\n            try:\n                cursor.execute(\n                    \"SELECT action_type, COUNT(*) FROM audit_log GROUP BY action_type\")\n                rows = cursor.fetchall()\n                return {row[0]: row[1] for row in rows}\n            except sqlite3.OperationalError:\n                return {}\n    finally:\n        # Restart the worker\n        self._stop_event.clear()\n        self._audit_thread = threading.Thread(\n            target=self._audit_worker, daemon=True, name=\"AuditWorker\")\n        self._audit_thread.start()\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.get_flattened_instances","title":"<code>get_flattened_instances(patient_ids=None, instance_uids=None)</code>","text":"<p>Yields a flat dictionary for every instance in the DB.</p> <p>Useful for streaming exports or analysis without loading the entire graph into RAM.</p> <p>Parameters:</p> Name Type Description Default <code>patient_ids</code> <code>List[str]</code> <p>Filter by list of Patient IDs.</p> <code>None</code> <code>instance_uids</code> <code>List[str]</code> <p>Filter by list of SOP Instance UIDs.</p> <code>None</code> <p>Yields:</p> Name Type Description <code>dict</code> <p>Flattend dictionary representing row data (patient, study, series, instance paths).</p> Source code in <code>gantry/persistence.py</code> <pre><code>def get_flattened_instances(self,\n                            patient_ids: List[str] = None,\n                            instance_uids: List[str] = None):\n    \"\"\"\n    Yields a flat dictionary for every instance in the DB.\n\n    Useful for streaming exports or analysis without loading the entire graph into RAM.\n\n    Args:\n        patient_ids (List[str], optional): Filter by list of Patient IDs.\n        instance_uids (List[str], optional): Filter by list of SOP Instance UIDs.\n\n    Yields:\n        dict: Flattend dictionary representing row data (patient, study, series, instance paths).\n    \"\"\"\n    # We use a managed connection that stays open during iteration\n    with self._get_connection() as conn:\n        # conn.row_factory = sqlite3.Row\n        cur = conn.cursor()\n\n        query = \"\"\"\n            SELECT\n                p.patient_id, p.patient_name,\n                st.study_instance_uid, st.study_date,\n                s.series_instance_uid, s.modality, s.series_number, s.manufacturer, s.model_name, s.device_serial_number,\n                i.sop_instance_uid, i.sop_class_uid, i.instance_number, i.file_path,\n                i.pixel_offset, i.pixel_length, i.compress_alg, i.attributes_json\n            FROM instances i\n            JOIN series s ON i.series_id_fk = s.id\n            JOIN studies st ON s.study_id_fk = st.id\n            JOIN patients p ON st.patient_id_fk = p.id\n        \"\"\"\n\n        conditions = []\n        params = []\n\n        if patient_ids:\n            placeholders = \",\".join(\"?\" for _ in patient_ids)\n            conditions.append(f\"p.patient_id IN ({placeholders})\")\n            params.extend(patient_ids)\n\n        if instance_uids:\n            placeholders = \",\".join(\"?\" for _ in instance_uids)\n            conditions.append(f\"i.sop_instance_uid IN ({placeholders})\")\n            params.extend(instance_uids)\n\n        if conditions:\n            query += \" WHERE \" + \" AND \".join(conditions)\n\n        # Execute generator\n        cursor = cur.execute(query, params)\n\n        # We can map columns to names\n        cols = [desc[0] for desc in cursor.description]\n\n        for row in cursor:\n            yield dict(zip(cols, row))\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.get_total_instances","title":"<code>get_total_instances()</code>","text":"<p>Returns the total number of instances currently persisted.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The count of rows in the instances table.</p> Source code in <code>gantry/persistence.py</code> <pre><code>def get_total_instances(self) -&gt; int:\n    \"\"\"\n    Returns the total number of instances currently persisted.\n\n    Returns:\n        int: The count of rows in the instances table.\n    \"\"\"\n    try:\n        with self._get_connection() as conn:\n            cur = conn.cursor()\n            row = cur.execute(\"SELECT COUNT(*) FROM instances\").fetchone()\n            return row[0] if row else 0\n    except sqlite3.Error as e:\n        self.logger.error(f\"Failed to count instances: {e}\")\n        return 0\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.load_all","title":"<code>load_all()</code>","text":"<p>Reconstructs the entire object graph from the database.</p> <p>Fetches all patients, studies, series, and instances, and reassembles them into the proper object hierarchy.</p> <p>Returns:</p> Type Description <code>List[Patient]</code> <p>List[Patient]: A list of all root Patient objects.</p> Source code in <code>gantry/persistence.py</code> <pre><code>def load_all(self) -&gt; List[Patient]:\n    \"\"\"\n    Reconstructs the entire object graph from the database.\n\n    Fetches all patients, studies, series, and instances, and reassembles them\n    into the proper object hierarchy.\n\n    Returns:\n        List[Patient]: A list of all root Patient objects.\n    \"\"\"\n    patients = []\n    if self.db_path != \":memory:\" and not os.path.exists(self.db_path):\n        return patients\n\n    try:\n        with self._get_connection() as conn:\n            # conn.row_factory = sqlite3.Row  &lt;-- Handled by _get_connection\n            cur = conn.cursor()\n\n            # Optimized: We could do joins, but for clarity/mapping let's do hierarchical fetch.\n            # Or fetch all and Stitch. Stitching in memory is faster for SQLite than\n            # N+1 queries.\n\n            # 1. Fetch AlL\n            p_rows = cur.execute(\"SELECT * FROM patients\").fetchall()\n            st_rows = cur.execute(\"SELECT * FROM studies\").fetchall()\n            se_rows = cur.execute(\"SELECT * FROM series\").fetchall()\n            i_rows = cur.execute(\"SELECT * FROM instances\").fetchall()\n\n            # 2. Build Maps\n            p_map = {}\n            for r in p_rows:\n                p = Patient(r['patient_id'], r['patient_name'])\n                p_map[r['id']] = p\n                patients.append(p)\n\n            st_map = {}\n            for r in st_rows:\n                st = Study(r['study_instance_uid'], r['study_date'])\n                st_map[r['id']] = st\n                if r['patient_id_fk'] in p_map:\n                    p_map[r['patient_id_fk']].studies.append(st)\n\n            se_map = {}\n            for r in se_rows:\n                se = Series(r['series_instance_uid'], r['modality'], r['series_number'])\n                if r['manufacturer'] or r['model_name']:\n                    se.equipment = Equipment(\n                        r['manufacturer'], r['model_name'], r['device_serial_number'])\n                se_map[r['id']] = se\n                if r['study_id_fk'] in st_map:\n                    st_map[r['study_id_fk']].series.append(se)\n\n            for r in i_rows:\n                inst = Instance(\n                    r['sop_instance_uid'],\n                    r['sop_class_uid'],\n                    r['instance_number'],\n                    file_path=r['file_path']\n                )\n\n                # Restore extra attributes\n                if r['attributes_json']:\n                    try:\n                        attrs = json.loads(\n                            r['attributes_json'], object_hook=gantry_json_object_hook)\n                        self._deserialize_into(inst, attrs)\n                    except BaseException:\n                        pass  # JSON error\n\n                # Wire up Sidecar Loader if present\n                if r['pixel_offset'] is not None and r['pixel_length'] is not None:\n                    # Capture closure vars\n                    offset = r['pixel_offset']\n                    length = r['pixel_length']\n                    alg = r['compress_alg']\n\n                    # We need to reshape after loading. The dimensions are in attributes.\n                    # We can do this inside the lambda wrapper or a helper method.\n                    # But Instance.attributes aren't populated yet!\n                    # Wait, we populate attributes right after this.\n                    # So the lambda calls self.instance methods? No, lambda binds early.\n\n                    inst._pixel_loader = self._create_pixel_loader(\n                        r['pixel_offset'], r['pixel_length'], r['compress_alg'], inst)\n\n                if r['series_id_fk'] in se_map:\n                    se_map[r['series_id_fk']].instances.append(inst)\n\n        self.logger.info(f\"Loaded {len(patients)} patients from {self.db_path}\")\n        # Mark all loaded data as clean so we don't save it back immediately\n        for p in patients:\n            p.mark_clean()\n        return patients\n\n    except sqlite3.Error as e:\n        # print(f\"DEBUG: Failed to load from DB: {e}\")\n        self.logger.error(f\"Failed to load PDF from DB: {e}\")\n        traceback.print_exc()\n        return []\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.load_findings","title":"<code>load_findings()</code>","text":"<p>Loads all findings from the database.</p> <p>Returns:</p> Type Description <code>List[PhiFinding]</code> <p>List[PhiFinding]: All persisted PHI findings.</p> Source code in <code>gantry/persistence.py</code> <pre><code>def load_findings(self) -&gt; List[PhiFinding]:\n    \"\"\"\n    Loads all findings from the database.\n\n    Returns:\n        List[PhiFinding]: All persisted PHI findings.\n    \"\"\"\n    findings = []\n    if self.db_path != \":memory:\" and not os.path.exists(self.db_path):\n        return findings\n\n    try:\n        with self._get_connection() as conn:\n            # conn.row_factory = sqlite3.Row\n            cur = conn.cursor()\n            # Check if table exists (backward compatibility for old DBs if init didnt run on them)\n            # But _init_db runs on __init__, so schema should be there.\n\n            rows = cur.execute(\"SELECT * FROM phi_findings ORDER BY id\").fetchall()\n\n            for r in rows:\n                if r['remediation_action']:\n                    prop = PhiRemediation(\n                        r['remediation_action'],\n                        r['field_name'],\n                        r['remediation_value'],\n                        None)\n                else:\n                    prop = None\n\n                f = PhiFinding(\n                    entity_uid=r['entity_uid'],\n                    entity_type=r['entity_type'],\n                    field_name=r['field_name'],\n                    value=r['value'],\n                    reason=r['reason'],\n                    patient_id=r['patient_id'],\n                    remediation_proposal=prop\n                )\n                findings.append(f)\n\n    except sqlite3.Error as e:\n        self.logger.error(f\"Failed to load findings: {e}\")\n\n    return findings\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.load_patient","title":"<code>load_patient(patient_uid)</code>","text":"<p>Loads a single patient and their graph from the DB by PatientID.</p> <p>Parameters:</p> Name Type Description Default <code>patient_uid</code> <code>str</code> <p>The PatientID to search for.</p> required <p>Returns:</p> Type Description <code>Optional[Patient]</code> <p>Optional[Patient]: The Patient object if found, else None.</p> Source code in <code>gantry/persistence.py</code> <pre><code>def load_patient(self, patient_uid: str) -&gt; Optional[Patient]:\n    \"\"\"\n    Loads a single patient and their graph from the DB by PatientID.\n\n    Args:\n        patient_uid (str): The PatientID to search for.\n\n    Returns:\n        Optional[Patient]: The Patient object if found, else None.\n    \"\"\"\n    if self.db_path != \":memory:\" and not os.path.exists(self.db_path):\n        return None\n\n    try:\n        with self._get_connection() as conn:\n            # conn.row_factory = sqlite3.Row\n            cur = conn.cursor()\n\n            # Fetch Patient\n            p_row = cur.execute(\n                \"SELECT * FROM patients WHERE patient_id = ?\", (patient_uid,)).fetchone()\n            if not p_row:\n                return None\n\n            p = Patient(p_row['patient_id'], p_row['patient_name'])\n            p_pk = p_row['id']\n\n            # Fetch Studies\n            st_rows = cur.execute(\n                \"SELECT * FROM studies WHERE patient_id_fk = ?\", (p_pk,)).fetchall()\n            for st_r in st_rows:\n                st = Study(st_r['study_instance_uid'], st_r['study_date'])\n                st_pk = st_r['id']\n\n                # Fetch Series\n                se_rows = cur.execute(\n                    \"SELECT * FROM series WHERE study_id_fk = ?\", (st_pk,)).fetchall()\n                for se_r in se_rows:\n                    se = Series(\n                        se_r['series_instance_uid'],\n                        se_r['modality'],\n                        se_r['series_number'])\n                    if se_r['manufacturer'] or se_r['model_name']:\n                        se.equipment = Equipment(\n                            se_r['manufacturer'], se_r['model_name'], se_r['device_serial_number'])\n                    se_pk = se_r['id']\n\n                    # Fetch Instances\n                    i_rows = cur.execute(\n                        \"SELECT * FROM instances WHERE series_id_fk = ?\", (se_pk,)).fetchall()\n                    for r in i_rows:\n                        inst = Instance(\n                            r['sop_instance_uid'],\n                            r['sop_class_uid'],\n                            r['instance_number'],\n                            file_path=r['file_path']\n                        )\n                        # Wire up Sidecar (Copy-Paste logic from load_all, keep generic?)\n                        if r['attributes_json']:\n                            try:\n                                attrs = json.loads(\n                                    r['attributes_json'], object_hook=gantry_json_object_hook)\n                                self._deserialize_into(inst, attrs)\n                            except BaseException:\n                                pass\n\n                        # Wire up Sidecar (Copy-Paste logic from load_all, keep generic?)\n                        if r['pixel_offset'] is not None and r['pixel_length'] is not None:\n                            offset, length, alg = r['pixel_offset'], r['pixel_length'], r['compress_alg']\n                            inst._pixel_loader = self._create_pixel_loader(\n                                r['pixel_offset'], r['pixel_length'], r['compress_alg'], inst)\n\n                        se.instances.append(inst)\n\n                    st.series.append(se)\n                p.studies.append(st)\n\n            p.mark_clean()\n            return p\n    except sqlite3.Error as e:\n        self.logger.error(f\"Failed to load patient: {e}\")\n        return None\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.load_vertical_attributes","title":"<code>load_vertical_attributes(instance_uid)</code>","text":"<p>Loads extended attributes from vertical table.</p> <p>Parameters:</p> Name Type Description Default <code>instance_uid</code> <code>str</code> <p>The SOP Instance UID.</p> required <p>Returns:</p> Type Description <code>Dict[Tuple[str, str], Any]</code> <p>Dict[Tuple[str, str], Any]: Dictionary mapping (group, element) tuples to values.</p> Source code in <code>gantry/persistence.py</code> <pre><code>def load_vertical_attributes(self, instance_uid: str) -&gt; Dict[Tuple[str, str], Any]:\n    \"\"\"\n    Loads extended attributes from vertical table.\n\n    Args:\n        instance_uid (str): The SOP Instance UID.\n\n    Returns:\n        Dict[Tuple[str, str], Any]: Dictionary mapping (group, element) tuples to values.\n    \"\"\"\n    results = {}\n    try:\n        with self._get_connection() as conn:\n            rows = conn.execute(\"\"\"\n                SELECT group_id, element_id, atom_index, value_text\n                FROM instance_attributes\n                WHERE instance_uid=?\n                ORDER BY group_id, element_id, atom_index\n            \"\"\", (instance_uid,)).fetchall()\n\n            if not rows:\n                return {}\n\n            # Reassemble\n            curr_key = None\n            collect = []\n\n            for r in rows:\n                key = (r['group_id'], r['element_id'])\n                val = r['value_text']  # Type conversion? Strings for now.\n\n                if key != curr_key:\n                    # Flush previous\n                    if curr_key:\n                        results[curr_key] = collect if len(collect) &gt; 1 else collect[0]\n                    curr_key = key\n                    collect = [val]\n                else:\n                    collect.append(val)\n\n            # Flush last\n            if curr_key:\n                results[curr_key] = collect if len(collect) &gt; 1 else collect[0]\n\n        return results\n    except sqlite3.Error as e:\n        self.logger.error(f\"Failed to load vertical attributes for {instance_uid}: {e}\")\n        return {}\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.log_audit","title":"<code>log_audit(action_type, entity_uid, details)</code>","text":"<p>Records an action in the audit log (Async).</p> Source code in <code>gantry/persistence.py</code> <pre><code>def log_audit(self, action_type: str, entity_uid: str, details: str):\n    \"\"\"Records an action in the audit log (Async).\"\"\"\n    # Push to queue instead of writing directly\n    self.audit_queue.put((action_type, entity_uid, details))\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.log_audit_batch","title":"<code>log_audit_batch(entries)</code>","text":"<p>Batch inserts audit logs. entries: List of (action_type, entity_uid, details)</p> Source code in <code>gantry/persistence.py</code> <pre><code>def log_audit_batch(self, entries: List[tuple]):\n    \"\"\"\n    Batch inserts audit logs.\n    entries: List of (action_type, entity_uid, details)\n    \"\"\"\n    if not entries:\n        return\n\n    timestamp = datetime.now().isoformat()\n    # Prepare data with timestamp: (timestamp, action, uid, details)\n    data = [(timestamp, e[0], e[1], e[2]) for e in entries]\n\n    try:\n        with self._get_connection() as conn:\n            conn.executemany(\n                \"INSERT INTO audit_log (timestamp, action_type, entity_uid, details) VALUES (?, ?, ?, ?)\", data)\n            conn.commit()\n    except sqlite3.Error as e:\n        self.logger.error(f\"Failed to batch log audit: {e}\")\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.persist_pixel_data","title":"<code>persist_pixel_data(instance)</code>","text":"<p>Immediately persists pixel data to the sidecar to allow memory offloading.</p> <p>This writes the <code>pixel_array</code> to the sidecar file and updates the instance's <code>_pixel_loader</code> and <code>_pixel_hash</code>. It does NOT update the full instance record in the main DB, only the pixel linkage in memory (marked dirty).</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>Instance</code> <p>The instance containing the pixel data to persist.</p> required Source code in <code>gantry/persistence.py</code> <pre><code>def persist_pixel_data(self, instance: Instance):\n    \"\"\"\n    Immediately persists pixel data to the sidecar to allow memory offloading.\n\n    This writes the `pixel_array` to the sidecar file and updates the instance's\n    `_pixel_loader` and `_pixel_hash`. It does NOT update the full instance record\n    in the main DB, only the pixel linkage in memory (marked dirty).\n\n    Args:\n        instance (Instance): The instance containing the pixel data to persist.\n    \"\"\"\n    if instance.pixel_array is None:\n        return\n\n    try:\n        # 1. Write to Sidecar\n        # Pass array directly to avoid .tobytes() Memory spike (Zero-Copy 500MB save)\n        b_data = instance.pixel_array\n\n        # Hash Update (CRITICAL for Integrity Checks)\n        # Calculate Hash BEFORE writing/compression to ensure we capture the state\n        # exactly as it goes into the pipe.\n        import hashlib\n        # Ensure we are hashing the contiguous bytes\n        if hasattr(b_data, 'tobytes'):\n            p_hash = hashlib.sha256(b_data.tobytes()).hexdigest()\n        else:\n            p_hash = hashlib.sha256(b_data).hexdigest()\n\n        instance._pixel_hash = p_hash\n\n        # Determine suitable compression? Defaulting to zlib for swap.\n        # Ideally we respect original or config, but for swap zlib is safe/fast enough.\n        c_alg = 'zlib'\n\n        offset, length = self.sidecar.write_frame(b_data, c_alg)\n\n        # 2. Update Instance Loader\n        # This allows instance.unload_pixel_data() to work safely\n        # Note: instance attributes ARE populated here (it's a live object), so\n        # passing instance=instance works.\n        instance._pixel_loader = self._create_pixel_loader(\n            offset, length, c_alg, instance, pixel_hash=p_hash)\n\n        # 3. Optional: Persist the linkage to DB immediately?\n        # It's safer if we do, so if we crash, we know where the pixels are.\n        # However, if we don't save the attributes/UID changes, the DB is out of sync anyway.\n        # But the primary goal here is MEMORY MANAGEMENT.\n        # So updating the object state in memory (step 2) is sufficient for unload_pixel_data() to return True.\n        # The final session.save() will record the new offset/length into the DB\n        # instances table.\n\n        # CRITICAL: Mark instance as dirty so save_all() knows to update the DB with the new loader/hash!\n        # If we don't do this, save_all might skip this instance if it was otherwise clean,\n        # leaving the DB pointing to old/original data while memory points to new sidecar data.\n        instance._mod_count += 1\n\n    except Exception as e:\n        self.logger.error(f\"Failed to persist pixel swap for {instance.sop_instance_uid}: {e}\")\n        raise e\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.save_all","title":"<code>save_all(patients)</code>","text":"<p>Incrementally persists the provided patients and their graph to the database.</p> <p>Uses UPSERT logic to update existing records and Insert new ones. Only processes entities marked as <code>_dirty</code>.</p> <p>Parameters:</p> Name Type Description Default <code>patients</code> <code>List[Patient]</code> <p>The list of patient objects to save.</p> required Source code in <code>gantry/persistence.py</code> <pre><code>def save_all(self, patients: List[Patient]):\n    \"\"\"\n    Incrementally persists the provided patients and their graph to the database.\n\n    Uses UPSERT logic to update existing records and Insert new ones.\n    Only processes entities marked as `_dirty`.\n\n    Args:\n        patients (List[Patient]): The list of patient objects to save.\n    \"\"\"\n    self.logger.info(f\"Saving {len(patients)} patients to {self.db_path} (Incremental)...\")\n\n    pixel_bytes_written = 0\n    pixel_frames_written = 0\n    sidecar_manager = self.sidecar\n\n    try:\n        with self._get_connection() as conn:\n            cur = conn.cursor()\n\n            # Check for schema compatibility (simple check)\n            try:\n                # We rely on UNIQUE constraints for UPSERT.\n                # If older DB without constraints, we might fail or duplicate.\n                pass\n            except BaseException:\n                pass\n\n            # Counts for reporting\n            saved_p, saved_st, saved_se, saved_i = 0, 0, 0, 0\n\n            for p in patients:\n                # Patient Level (Always Check Dirty)\n                if getattr(p, '_dirty', True):\n                    cur.execute(\"\"\"\n                        INSERT INTO patients (patient_id, patient_name) VALUES (?, ?)\n                        ON CONFLICT(patient_id) DO UPDATE SET patient_name=excluded.patient_name\n                    \"\"\", (p.patient_id, p.patient_name))\n                    saved_p += 1\n\n                # We need the PK for children\n                # Since we might have just updated or it might exist, we select it.\n                # Optimization: Cache PKs? For now, fetch is safe.\n                p_pk_row = cur.execute(\n                    \"SELECT id FROM patients WHERE patient_id=?\", (p.patient_id,)).fetchone()\n                if not p_pk_row:\n                    continue  # Should not happen after Insert\n                p_pk = p_pk_row[0]\n\n                for st in p.studies:\n                    if getattr(st, '_dirty', True):\n                        # FIX: Convert date objects to string to avoid Python 3.12+\n                        # DeprecationWarning for default adapter\n                        s_date = st.study_date\n                        if hasattr(s_date, \"isoformat\"):\n                            s_date = s_date.isoformat()\n                        elif s_date is not None:\n                            s_date = str(s_date)\n\n                        cur.execute(\"\"\"\n                            INSERT INTO studies (patient_id_fk, study_instance_uid, study_date) VALUES (?, ?, ?)\n                            ON CONFLICT(study_instance_uid) DO UPDATE SET\n                                study_date=excluded.study_date,\n                                patient_id_fk=excluded.patient_id_fk\n                        \"\"\", (p_pk, st.study_instance_uid, s_date))\n                        saved_st += 1\n\n                    st_pk_row = cur.execute(\n                        \"SELECT id FROM studies WHERE study_instance_uid=?\", (st.study_instance_uid,)).fetchone()\n                    if not st_pk_row:\n                        continue\n                    st_pk = st_pk_row[0]\n\n                    for se in st.series:\n                        if getattr(se, '_dirty', True):\n                            man = se.equipment.manufacturer if se.equipment else \"\"\n                            mod = se.equipment.model_name if se.equipment else \"\"\n                            sn = se.equipment.device_serial_number if se.equipment else \"\"\n\n                            cur.execute(\"\"\"\n                                INSERT INTO series (study_id_fk, series_instance_uid, modality, series_number, manufacturer, model_name, device_serial_number)\n                                VALUES (?, ?, ?, ?, ?, ?, ?)\n                                ON CONFLICT(series_instance_uid) DO UPDATE SET\n                                    modality=excluded.modality,\n                                    series_number=excluded.series_number,\n                                    manufacturer=excluded.manufacturer,\n                                    model_name=excluded.model_name,\n                                    device_serial_number=excluded.device_serial_number,\n                                    study_id_fk=excluded.study_id_fk\n                            \"\"\", (st_pk, se.series_instance_uid, se.modality, se.series_number, man, mod, sn))\n                            saved_se += 1\n\n                        se_pk_row = cur.execute(\n                            \"SELECT id FROM series WHERE series_instance_uid=?\", (se.series_instance_uid,)).fetchone()\n                        if not se_pk_row:\n                            continue\n                        se_pk = se_pk_row[0]\n\n                        # --- Deletion Handling (Diff DB vs Memory) ---\n                        # Only perform if we suspect deletions or periodically?\n                        # Plan says: Implement Diff Logic.\n                        # Optimization: If series is NOT dirty, can we assume no deletions?\n                        # Not necessarily. Removing an item doesn't always mark Series dirty unless we hook \"remove\".\n                        # But DicomItem doesn't track removals from list automatically.\n                        # So we must check.\n\n                        db_uids_rows = cur.execute(\n                            \"SELECT sop_instance_uid FROM instances WHERE series_id_fk=?\", (se_pk,)).fetchall()\n                        db_uids = {r[0] for r in db_uids_rows}\n                        mem_uids = {i.sop_instance_uid for i in se.instances}\n\n                        to_delete = db_uids - mem_uids\n                        if to_delete:\n                            cur.executemany(\n                                \"DELETE FROM instances WHERE sop_instance_uid=?\", [\n                                    (u,) for u in to_delete])\n                            saved_i += 0  # Or count negative?\n                            # self.logger.debug(f\"Deleted {len(to_delete)} instances from Series {se.series_instance_uid}\")\n\n                        # --- Upsert Dirty ---\n                        dirty_items = []\n                        for i in se.instances:\n                            if getattr(i, '_dirty', True):\n                                # Capture version if available (robustness against race)\n                                ver = getattr(i, '_mod_count', 0)\n                                dirty_items.append((i, ver))\n\n                        if dirty_items:\n                            i_batch = []\n                            vert_updates = []  # Defer vertical updates to satisfy foreign key\n                            for inst, ver in dirty_items:\n                                full_data = self._serialize_item(inst)\n\n                                # Split Core vs Vertical (Private Tags -&gt; Vertical Table)\n                                core_data = {}\n                                vert_data = {}\n\n                                for key, val in full_data.items():\n                                    if key == \"__sequences__\":\n                                        # Keep sequences in Core JSON for now\n                                        core_data[key] = val\n                                        continue\n\n                                    # key is \"GGGG,EEEE\" hex string\n                                    try:\n                                        group = int(key.split(',')[0], 16)\n                                        # Odd Group = Private Tag (usually)\n                                        # Skip Vertical for BYTES (cant be stored as TEXT\n                                        # easily, keep in JSON)\n                                        is_private = (\n                                            group %\n                                            2 != 0) and not isinstance(\n                                            val, bytes)\n\n                                        if is_private:\n                                            # Tuple key for vertical method: (grp, elem)\n                                            k_tuple = tuple(key.split(','))\n                                            vert_data[k_tuple] = val\n                                        else:\n                                            core_data[key] = val\n                                    except BaseException:\n                                        core_data[key] = val\n\n                                # Queue Vertical (Saved after Instance Insert)\n                                if vert_data:\n                                    vert_updates.append((inst.sop_instance_uid, vert_data))\n\n                                # Serialize Core\n                                attrs_json = json.dumps(core_data, cls=GantryJSONEncoder)\n\n                                p_offset, p_length, p_alg, p_hash = None, None, None, None\n\n                                if inst.pixel_array is not None:\n                                    b_data = inst.pixel_array.tobytes()\n                                    c_alg = 'zlib'\n                                    # Compute Hash\n                                    # Compute Hash\n                                    # Compute Hash\n                                    p_hash = hashlib.sha256(b_data).hexdigest()\n\n                                    # Deduplication: If already persisted with same hash, skip\n                                    # write\n                                    if getattr(\n                                            inst, '_pixel_hash', None) == p_hash and isinstance(\n                                            inst._pixel_loader, SidecarPixelLoader):\n                                        p_offset = inst._pixel_loader.offset\n                                        p_length = inst._pixel_loader.length\n                                        p_alg = inst._pixel_loader.alg\n                                    else:\n                                        off, leng = sidecar_manager.write_frame(b_data, c_alg)\n                                        p_offset, p_length, p_alg = off, leng, c_alg\n                                        pixel_bytes_written += leng\n                                        pixel_frames_written += 1\n\n                                        # Update loader so we can unload safely later\n                                        inst._pixel_loader = self._create_pixel_loader(\n                                            off, leng, c_alg, inst)\n\n                                    inst._pixel_hash = p_hash  # Cache on instance\n\n                                elif isinstance(inst._pixel_loader, SidecarPixelLoader):\n                                    # Already persisted (swapped), preserve metadata\n                                    p_offset = inst._pixel_loader.offset\n                                    p_length = inst._pixel_loader.length\n                                    p_alg = inst._pixel_loader.alg\n                                    p_hash = getattr(inst, '_pixel_hash', None)\n                                else:\n                                    pass\n\n                                i_batch.append((\n                                    se_pk,\n                                    inst.sop_instance_uid,\n                                    inst.sop_class_uid,\n                                    inst.instance_number,\n                                    inst.file_path,\n                                    p_offset,\n                                    p_length,\n                                    p_hash,\n                                    p_alg,\n                                    attrs_json\n                                ))\n\n                            cur.executemany(\"\"\"\n                                INSERT INTO instances (series_id_fk, sop_instance_uid, sop_class_uid, instance_number, file_path,\n                                                       pixel_offset, pixel_length, pixel_hash, compress_alg, attributes_json)\n                                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n                                ON CONFLICT(sop_instance_uid) DO UPDATE SET\n                                    series_id_fk=excluded.series_id_fk,\n                                    sop_class_uid=excluded.sop_class_uid,\n                                    instance_number=excluded.instance_number,\n                                    file_path=excluded.file_path,\n                                    attributes_json=excluded.attributes_json,\n                                    pixel_offset=COALESCE(excluded.pixel_offset, instances.pixel_offset),\n                                    pixel_length=COALESCE(excluded.pixel_length, instances.pixel_length),\n                                    pixel_hash=COALESCE(excluded.pixel_hash, instances.pixel_hash),\n                                    compress_alg=COALESCE(excluded.compress_alg, instances.compress_alg)\n                            \"\"\", i_batch)\n\n                            # Process Deferred Vertical Updates (Now that Instances exist)\n                            if vert_updates:\n                                # self.logger.debug(f\"Saving vertical attributes for {len(vert_updates)} instances\")\n                                for uid, v_data in vert_updates:\n                                    self.save_vertical_attributes(uid, v_data, conn=conn)\n\n                            saved_i += len(dirty_items)\n\n                            # Mark saved with version (deferred until commit success?\n                            # No, we can attach to list and do it post-commit)\n                            # But we're inside loops.\n                            # Creating a cleanup list:\n                            # (We can store dirty_items in a larger list to clean up post-commit)\n                            # For now, let's mark clean *assuming* commit will succeed.\n                            # If commit fails, we rollback, but objects remain \"clean\" in memory?\n                            # That is a risk. We should do it post-commit.\n                            # But scope is tricky.\n                            # Let's mark clean here but using version.\n                            # If transaction rolls back, DB is old, but memory has _saved_mod_count advanced?\n                            # That means next save won't save it. BAD.\n                            # We must hold off.\n\n                            # Since we commit once at the end:\n                            # We need to collect ALL dirty items and their versions.\n                            # That is expensive memory-wise for massive sets.\n                            # But necessary for correctness.\n                            # Compromise: we iterate again.\n                            # Wait, \"Iterate again\" in 'mark clean' loop below.\n                            # We can't know \"ver\" then.\n\n                            # Let's just update them here. If commit fails, the Exception propagates.\n                            # Use a try/except block around the whole `save_all`? Yes.\n                            # But `_saved_mod_count` is in memory.\n                            # If we update it, and `save_all` crashes, we can't easily undo it.\n                            # BUT `save_all` crashing usually kills the process or stops persistence.\n                            # So `eventual consistency` implies retrying.\n                            # If we marked it saved but it didn't save, we have data loss.\n\n                            # Correct way: List of callbacks?\n                            # Or just:\n                            for inst, ver in dirty_items:\n                                if hasattr(inst, 'mark_saved'):\n                                    inst.mark_saved(ver)\n                                else:\n                                    inst._dirty = False\n\n            conn.commit()\n\n            # Post-Commit:\n            # We already marked items as saved/clean incrementally using naive-commit assumption.\n            # If transaction failed, those items are marked clean in memory but not in DB -&gt; Inconsistency.\n            # However, re-implementing rollback for memory objects is out of scope.\n            # The versioning fixes the \"Overwrite valid change\" race, which is the user's issue.\n            pass\n\n            # Restore Logging Logic\n            if saved_p + saved_i &gt; 0:\n                msg = f\"Save (Inc) complete. P:{saved_p} St:{saved_st} Se:{saved_se} I:{saved_i}.\"\n                if pixel_frames_written &gt; 0:\n                    mb = pixel_bytes_written / (1024 * 1024)\n                    msg += f\" Sidecar: {pixel_frames_written} frames ({mb:.2f} MB).\"\n                self.logger.info(msg)\n\n    except Exception as e:\n        self.logger.error(f\"Save failed: {e}\")\n        if hasattr(conn, \"rollback\"):\n            conn.rollback()\n        raise\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.save_findings","title":"<code>save_findings(findings)</code>","text":"<p>Persists PHI findings to the database.</p> <p>Parameters:</p> Name Type Description Default <code>findings</code> <code>List[PhiFinding]</code> <p>List of finding objects to insert.</p> required Source code in <code>gantry/persistence.py</code> <pre><code>def save_findings(self, findings: List[PhiFinding]):\n    \"\"\"\n    Persists PHI findings to the database.\n\n    Args:\n        findings (List[PhiFinding]): List of finding objects to insert.\n    \"\"\"\n    timestamp = datetime.now().isoformat()\n\n    if not findings:\n        return\n\n    self.logger.info(f\"Saving {len(findings)} PHI findings...\")\n\n    try:\n        with self._get_connection() as conn:\n            cur = conn.cursor()\n\n            # Prepare Data Generator for Batch Insert (Memory Efficient)\n            def findings_generator():\n                for f in findings:\n                    rem_action = None\n                    rem_value = None\n                    if f.remediation_proposal:\n                        rem_action = f.remediation_proposal.action_type\n                        rem_value = str(f.remediation_proposal.new_value)\n\n                    yield (\n                        timestamp,\n                        f.entity_uid,\n                        f.entity_type,\n                        f.field_name,\n                        str(f.value),\n                        f.reason,\n                        f.patient_id,\n                        rem_action,\n                        rem_value,\n                        \"{}\"\n                    )\n\n            cur.executemany(\"\"\"\n                INSERT INTO phi_findings\n                (timestamp, entity_uid, entity_type, field_name, value, reason, patient_id, remediation_action, remediation_value, details_json)\n                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n            \"\"\", findings_generator())\n\n            conn.commit()\n            self.logger.info(\"Findings saved.\")\n\n    except sqlite3.Error as e:\n        self.logger.error(f\"Failed to save findings: {e}\")\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.save_vertical_attributes","title":"<code>save_vertical_attributes(instance_uid, attributes, conn=None)</code>","text":"<p>Persists extended attributes to the vertical <code>instance_attributes</code> table.</p> <p>This handles private tags and attributes that don't fit in the core JSON. Uses UPSERT semantics (Delete-Insert logic currently).</p> <p>Parameters:</p> Name Type Description Default <code>instance_uid</code> <code>str</code> <p>The SOP Instance UID.</p> required <code>attributes</code> <code>Dict[Tuple[str, str], Any]</code> <p>Mapping of (Group, Element) hex strings to values.</p> required <code>conn</code> <code>Connection</code> <p>An existing database connection to use for the transaction.</p> <code>None</code> Source code in <code>gantry/persistence.py</code> <pre><code>def save_vertical_attributes(\n        self, instance_uid: str, attributes: Dict[Tuple[str, str], Any], conn: sqlite3.Connection = None):\n    \"\"\"\n    Persists extended attributes to the vertical `instance_attributes` table.\n\n    This handles private tags and attributes that don't fit in the core JSON.\n    Uses UPSERT semantics (Delete-Insert logic currently).\n\n    Args:\n        instance_uid (str): The SOP Instance UID.\n        attributes (Dict[Tuple[str, str], Any]): Mapping of (Group, Element) hex strings to values.\n        conn (sqlite3.Connection, optional): An existing database connection to use for the transaction.\n    \"\"\"\n    if not attributes:\n        return\n\n    data_rows = []\n    for (grp, elem), val in attributes.items():\n        vr = \"UN\"  # Todo: Pass VR from caller\n        # Check for VM &gt; 1\n        if isinstance(val, list):\n            for idx, atom in enumerate(val):\n                data_rows.append((instance_uid, grp, elem, idx, vr, str(atom)))\n        else:\n            data_rows.append((instance_uid, grp, elem, 0, vr, str(val)))\n\n    if not data_rows:\n        return\n\n    try:\n\n        # If conn is passed, use it (and don't close it/commit it here, leave to caller).\n        # If not, create new context (which commits/closes).\n        ctx = self._get_connection() if conn is None else nullcontext(conn)\n\n        with ctx as db:\n            # 1. OPTIMIZATION: Delete existing for these keys first?\n            # Or UPSERT.\n            # \"test_vertical_update_serialization\" requires correctness.\n            # UPSERT based on unique index (uid, grp, elem, atom) works.\n            # But if list shrinks (VM 3 -&gt; VM 1), UPSERT leaves atoms 2,3.\n            # So we MUST DELETE by (uid, grp, elem) before inserting new set for that tag.\n\n            # We can do this in transaction.\n            keys_to_clear = list(attributes.keys())\n            # Batch delete?\n            # \"DELETE FROM instance_attributes WHERE instance_uid=? AND group_id=? AND element_id=?\\\"\n            del_params = [(instance_uid, k[0], k[1]) for k in keys_to_clear]\n            db.executemany(\n                \"DELETE FROM instance_attributes WHERE instance_uid=? AND group_id=? AND element_id=?\",\n                del_params)\n\n            db.executemany(\"\"\"\n                INSERT INTO instance_attributes (instance_uid, group_id, element_id, atom_index, value_rep, value_text)\n                VALUES (?, ?, ?, ?, ?, ?)\n            \"\"\", data_rows)\n\n    except sqlite3.Error as e:\n        self.logger.error(f\"Failed to save vertical attributes for {instance_uid}: {e}\")\n        raise e\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.stop","title":"<code>stop()</code>","text":"<p>Stops the audit worker and flushes queue.</p> Source code in <code>gantry/persistence.py</code> <pre><code>def stop(self):\n    \"\"\"Stops the audit worker and flushes queue.\"\"\"\n    self._stop_event.set()\n    if self._audit_thread.is_alive():\n        self._audit_thread.join(timeout=2.0)\n    self.flush_audit_queue()\n</code></pre>"},{"location":"api/persistence/#gantry.persistence.SqliteStore.update_attributes","title":"<code>update_attributes(instances)</code>","text":"<p>Efficiently updates the attributes_json for a list of instances.</p> <p>Used when only attributes have changed (e.g., after locking identities) to avoid full graph traversal.</p> <p>Parameters:</p> Name Type Description Default <code>instances</code> <code>List[Instance]</code> <p>The list of instances to update.</p> required Source code in <code>gantry/persistence.py</code> <pre><code>def update_attributes(self, instances: List[Patient]):\n    \"\"\"\n    Efficiently updates the attributes_json for a list of instances.\n\n    Used when only attributes have changed (e.g., after locking identities)\n    to avoid full graph traversal.\n\n    Args:\n        instances (List[Instance]): The list of instances to update.\n    \"\"\"\n    if not instances:\n        return\n\n    self.logger.info(f\"Updating attributes for {len(instances)} instances...\")\n    try:\n        with self._get_connection() as conn:\n            cur = conn.cursor()\n\n            # Pre-calculate data for executemany\n            data = []\n            for inst in instances:\n                # Serialize attributes AND sequences\n                full_data = self._serialize_item(inst)\n                attrs_json = json.dumps(full_data, cls=GantryJSONEncoder)\n                data.append((attrs_json, inst.sop_instance_uid))\n\n            cur.executemany(\"\"\"\n                UPDATE instances\n                SET attributes_json = ?\n                WHERE sop_instance_uid = ?\n            \"\"\", data)\n\n            conn.commit()\n            self.logger.info(\"Update complete.\")\n\n    except sqlite3.Error as e:\n        self.logger.error(f\"Failed to update attributes: {e}\")\n</code></pre>"},{"location":"api/session/","title":"Session API","text":""},{"location":"api/session/#gantry.session.DicomSession","title":"<code>gantry.session.DicomSession</code>","text":"<p>The Main Facade for the Gantry library.</p> <p>Manages the lifecycle of the DicomStore including: - Loading/Saving session state from SQLite. - Ingesting DICOM files. - Managing Configuration and Rules. - Auditing for PHI. - Redaction and Anonymization. - Exporting cleaned data.</p> Source code in <code>gantry/session.py</code> <pre><code>class DicomSession:\n    \"\"\"\n    The Main Facade for the Gantry library.\n\n    Manages the lifecycle of the DicomStore including:\n    - Loading/Saving session state from SQLite.\n    - Ingesting DICOM files.\n    - Managing Configuration and Rules.\n    - Auditing for PHI.\n    - Redaction and Anonymization.\n    - Exporting cleaned data.\n    \"\"\"\n\n    # =========================================================================\n    # LIFECYCLE\n    # =========================================================================\n\n    def __init__(self, persistence_file=None):\n        \"\"\"\n        Initialize the DicomSession.\n\n        Args:\n            persistence_file (str): Path to the SQLite database file for session persistence.\n                                    Defaults to \"gantry.db\".\n        \"\"\"\n        configure_logger()\n        self.persistence_file = persistence_file or os.getenv(\"GANTRY_DB_PATH\", \"gantry.db\")\n\n        # Check existence before SqliteStore potentially creates it\n        db_exists = os.path.exists(self.persistence_file)\n\n        self.store_backend = SqliteStore(self.persistence_file)\n        self.persistence_manager = PersistenceManager(self.store_backend)\n\n        # Hydrate memory from DB\n        self.store = DicomStore()\n\n        if db_exists:\n            print(f\"Loading session from {self.persistence_file}...\")\n        else:\n            print(f\"Initializing new session at {self.persistence_file}...\")\n\n        self.store.patients = self.store_backend.load_all()\n\n        # Initialize Configuration Object\n        self.configuration = GantryConfiguration()\n\n        # Reversibility\n        self.key_manager = None\n        self.reversibility_service = None\n\n        if os.path.exists(\"gantry.key\"):\n            self.enable_reversible_anonymization(\"gantry.key\")\n\n        # Shared Global Executor for Process Consistency\n        self._executor = concurrent.futures.ProcessPoolExecutor(\n            max_workers=None)  # Default: CPU * 1.5\n\n        if db_exists:\n            print(f\"Loaded session from {self.persistence_file}\")\n\n        get_logger().info(f\"Session started. {len(self.store.patients)} patients loaded.\")\n\n    def close(self):\n        \"\"\"\n        Cleanly shuts down the session, stopping background threads and flushing queues.\n        \"\"\"\n        print(\"Closing session persistence...\")\n        if hasattr(self, 'persistence_manager'):\n            self.persistence_manager.shutdown()\n        if hasattr(self, 'store_backend'):\n            self.store_backend.stop()  # Stops audit thread\n\n        if hasattr(self, '_executor'):\n            print(\"Shutting down process pool...\")\n            self._executor.shutdown(wait=True)\n\n    def save(self, sync: bool = False):\n        \"\"\"\n        Persists the current session state to the database.\n        :param sync: If True, blocks until save is complete.\n        \"\"\"\n        if sync and hasattr(self, 'store_backend'):\n            get_logger().info(\"Saving session (Synchronous)...\")\n            self.store_backend.save_all(self.store.patients)\n        elif hasattr(self, 'persistence_manager'):\n            self.persistence_manager.save_async(self.store.patients)\n\n    def _restart_executor(self, max_workers=None):\n        \"\"\"\n        Restarts the internal process pool executor, potentially with fewer workers.\n        Useful for recovering from BrokenProcessPool errors (OOM).\n        \"\"\"\n        get_logger().warning(f\"Restarting ProcessPoolExecutor (max_workers={max_workers})...\")\n        if self._executor:\n            try:\n                # Force kill old processes if they are stuck/broken\n                self._executor.shutdown(wait=False, cancel_futures=True)\n            except BaseException:\n                pass\n\n        # Re-init\n        self._executor = concurrent.futures.ProcessPoolExecutor(max_workers=max_workers)\n\n    def release_memory(self):\n        \"\"\"\n        Attempts to release memory by unloading pixel data from all instances.\n        Safe to call: only unloads data that is safely persisted (on disk or sidecar).\n        Useful after running extensive redaction or export operations.\n        \"\"\"\n        get_logger().info(\"Releasing memory (RAM cleanup)...\")\n        count = 0\n        freed = 0\n\n        # Count total instances first for progress bar\n        total_instances = sum(len(se.instances)\n                              for p in self.store.patients for st in p.studies for se in st.series)\n\n        if total_instances == 0:\n            return\n\n        with tqdm(total=total_instances, desc=\"Releasing Memory\", unit=\"img\") as pbar:\n            for p in self.store.patients:\n                for st in p.studies:\n                    for se in st.series:\n                        for inst in se.instances:\n                            count += 1\n                            if inst.unload_pixel_data():\n                                freed += 1\n                            pbar.update(1)\n\n        get_logger().info(\n            f\"Memory release complete. Unloaded pixels for {freed}/{count} instances.\")\n        if freed &gt; 0:\n            print(f\"Memory Cleanup: Released {freed} images from RAM.\")\n\n    def compact(self):\n        \"\"\"\n        Manually triggers Sidecar Compaction to reclaim disk space.\n        Rewrites the _pixels.bin file, removing orphaned data from deleted or redacted instances.\n        WARNING: This is an expensive I/O operation.\n        \"\"\"\n        if hasattr(self, 'store_backend'):\n            print(\"Beginning Sidecar Compaction (this may take a while)...\")\n\n            # 1. Sync DB so compaction knows true state\n            self.save(sync=True)\n\n            # 2. Compact and get updates\n            # Returns Dict[sop_instance_uid, (new_offset, new_length)]\n            updates = self.store_backend.compact_sidecar()\n\n            if not updates:\n                print(\"Compaction finished (no changes or empty).\")\n                return\n\n            # 3. Patch In-Memory Instances (Preserve References)\n            print(f\"Updating {len(updates)} in-memory instances...\")\n            count = 0\n\n            # Optimization: Pre-check if we have SidecarPixelLoader imported\n\n\n            # We must traverse the whole graph.\n            # DicomStore doesn't index by UID (yet).\n            for p in self.store.patients:\n                for st in p.studies:\n                    for se in st.series:\n                        for inst in se.instances:\n                            if inst.sop_instance_uid in updates:\n                                new_off, new_len = updates[inst.sop_instance_uid]\n\n                                # Update Loader\n                                if inst._pixel_loader and isinstance(\n                                        inst._pixel_loader, SidecarPixelLoader):\n                                    inst._pixel_loader.offset = new_off\n                                    inst._pixel_loader.length = new_len\n                                    count += 1\n\n                                # Note: If inst._pixel_loader is None (e.g. loaded from original DICOM file),\n                                # it doesn't use sidecar, so no update needed.\n                                # If it has pixel_array loaded (RAM), it's fine.\n                                # If we unload() later, we need correct loader.\n                                # BUT if it has pixel_array, does it have a loader?\n                                # persist_pixel_data ensures loader is created.\n                                # So if it was persisted, it has a loader.\n\n            print(f\"Patched {count} active objects.\")\n\n        else:\n            print(\"Persistence backend does not support compaction.\")\n\n    def examine(self):\n        \"\"\"Prints a summary of the session contents and equipment.\"\"\"\n        get_logger().info(\"Generating inventory report.\")\n\n        # 1. Object Counts\n        n_p = len(self.store.patients)\n        n_st = sum(len(p.studies) for p in self.store.patients)\n        n_se = sum(len(st.series) for p in self.store.patients for st in p.studies)\n        n_i = sum(len(se.instances)\n                  for p in self.store.patients for st in p.studies for se in st.series)\n\n        # 2. Equipment Grouping\n        eq_counts = {}  # (man, model) -&gt; count\n\n        for p in self.store.patients:\n            for st in p.studies:\n                for se in st.series:\n                    for inst in se.instances:\n                        if se.equipment:\n                            key = (se.equipment.manufacturer, se.equipment.model_name)\n                            eq_counts[key] = eq_counts.get(key, 0) + 1\n\n        print(f\"\\nInventory Summary:\")\n        print(f\" Patients:  {n_p}\")\n        print(f\" Studies:   {n_st}\")\n        print(f\" Series:    {n_se}\")\n        print(f\" Instances: {n_i}\")\n\n        print(f\"\\nEquipment Inventory:\")\n        if not eq_counts:\n            print(\" No equipment metadata found.\")\n        else:\n            for (man, mod), count in sorted(eq_counts.items()):\n                print(f\" - {man} - {mod} (Count: {count})\")\n\n    # =========================================================================\n    # INGESTION\n    # =========================================================================\n\n    def ingest(self, directory: str):\n        \"\"\"\n        Ingests DICOM files from a directory into the session store.\n\n        Recursively scans the provided directory for valid DICOM files.\n        Files are parsed and organized into the Patient -&gt; Study -&gt; Series -&gt; Instance hierarchy.\n        This operation automatically saves the session state upon completion.\n\n        Args:\n            directory (str): The path to the directory containing DICOM files.\n        \"\"\"\n        print(f\"Ingesting from '{directory}'...\")\n        # Pass Sidecar Manager for eager pixel writing\n        DicomImporter.import_files(\n            [directory],\n            self.store,\n            executor=self._executor,\n            sidecar_manager=self.store_backend.sidecar)\n\n        self.save(sync=True)\n\n        # Calculate stats\n        n_p = len(self.store.patients)\n        n_st = sum(len(p.studies) for p in self.store.patients)\n        n_se = sum(len(st.series) for p in self.store.patients for st in p.studies)\n        n_i = sum(len(se.instances)\n                  for p in self.store.patients for st in p.studies for se in st.series)\n\n        print(f\"Ingestion complete. Saved session state.\")\n        print(\"Summary:\")\n        print(f\"  - {n_p} Patients\")\n        print(f\"  - {n_st} Studies\")\n        print(f\"  - {n_se} Series\")\n        print(f\"  - {n_i} Instances\")\n\n    # =========================================================================\n    # CONFIGURATION\n    # =========================================================================\n\n    def load_config(self, config_file: str):\n        \"\"\"\n        Loads a configuration file into memory without applying it.\n\n        This allows the user to validate the configuration or run a preview using\n        `preview_config()` before performing any destructive actions.\n\n        Args:\n            config_file (str): Path to the YAML or JSON configuration file.\n        \"\"\"\n        try:\n            get_logger().info(f\"Loading configuration from {config_file}...\")\n            print(f\"Loading configuration from {config_file}...\")\n\n            # UNIFIED LOAD (v2) - Now loading into GantryConfiguration object\n            tags, rules, jitter, remove_private = ConfigLoader.load_unified_config(config_file)\n\n            # Update the configuration object\n            self.configuration.phi_tags = tags\n            self.configuration.rules = rules\n            self.configuration.date_jitter = jitter\n            self.configuration.remove_private_tags = remove_private\n            self.configuration.config_path = config_file\n\n            get_logger().info(\n                f\"Loaded {len(self.configuration.rules)} machine rules and {len(self.configuration.phi_tags)} PHI tags.\")\n            print(\n                f\"Configuration Loaded:\\n - {len(self.configuration.rules)} Machine Redaction Rules\\n - {len(self.configuration.phi_tags)} PHI Tags\")\n            print(\n                f\" - Date Jitter: {\n                    self.configuration.date_jitter['min_days']} to {\n                    self.configuration.date_jitter['max_days']} days\")\n            print(f\" - Remove Private Tags: {self.configuration.remove_private_tags}\")\n            print(\"Tip: Run .audit() to check PHI, or .redact_pixels() to apply redaction.\")\n        except Exception as e:\n            import traceback\n            get_logger().error(f\"Load failed: {e}\")\n            print(f\"Load failed: {e}\")\n            print(traceback.format_exc())\n            # Reset on failure? OR keep previous?\n            # Original behavior was reset.\n            self.configuration.rules = []\n            self.configuration.phi_tags = {}\n\n    def preview_config(self):\n        \"\"\"\n        Performs a dry-run of the currently loaded configuration.\n\n        Checks the active redaction rules against the current session inventory and\n        prints a summary of which instances would be affected (matched) by the rules.\n        Does not modify any data.\n        \"\"\"\n        if not self.configuration.rules:\n            get_logger().warning(\"No configuration loaded. Use .load_config() first.\")\n            print(\"No configuration loaded. Use .load_config() first.\")\n            return\n\n        print(\"\\n--- Dry Run / Configuration Preview ---\")\n\n        # We need the index to check matches\n        # We instantiate the service just to query the index, not to modify\n        service = RedactionService(self.store, self.store_backend)\n\n        match_count = 0\n\n        for rule in self.configuration.rules:\n            serial = rule.get(\"serial_number\", \"UNKNOWN\")\n            model = rule.get(\"model_name\", \"Unknown Model\")\n            zones = rule.get(\"redaction_zones\", [])\n\n            # check matches in store\n            targets = service.index.get_by_machine(serial)\n\n            if targets:\n                count = len(targets)\n                match_count += count\n                print(f\"MATCH: '{serial}' ({model})\")\n                print(f\"    - Found {count} images in current session.\")\n                print(f\"    - Actions: Will apply {len(zones)} redaction zones.\")\n            else:\n                print(f\"NO MATCH: '{serial}'. Rule loaded, but no images found.\")\n\n        print(f\"\\nSummary: Execution will modify approximately {match_count} images.\")\n        print(\"---------------------------------------\")\n\n    def create_config(self, output_path: str):\n        \"\"\"\n        Generates a unified configuration file (scaffold) in YAML format.\n\n        This method analyzes the current session inventory (Equipment, Manufacturers)\n        and attempts to auto-generate redaction rules based on internal knowledge bases\n        (e.g., CTP rules). It also includes a default set of PHI tags.\n\n        Args:\n            output_path (str): The file path where the generated YAML configuration should be saved.\n        \"\"\"\n\n\n        # Helper for Flow-Style Lists (Bracketed)\n        class FlowList(list):\n            pass\n\n        def flow_list_representer(dumper, data):\n            return dumper.represent_sequence('tag:yaml.org,2002:seq', data, flow_style=True)\n\n        yaml.add_representer(FlowList, flow_list_representer)\n\n        if not (output_path.endswith(\".yaml\") or output_path.endswith(\".yml\")):\n            output_path += \".yaml\"\n            print(f\"Note: Appending .yaml extension -&gt; {output_path}\")\n\n        # 1. Identify what we have\n        all_equipment = self.store.get_unique_equipment()\n\n        # Instantiate service to query pixel/tag data efficiently\n        service = RedactionService(self.store)\n\n        # 2. Identify what is already configured (Pixel Rules)\n        configured_serials = {rule.get(\"serial_number\") for rule in self.configuration.rules}\n\n        # Load Knowledge Base for Machines\n        kb_path = os.path.join(\n            os.path.dirname(\n                os.path.abspath(__file__)),\n            \"resources\",\n            \"redaction_rules.json\")\n        kb_machines = []\n        if os.path.exists(kb_path):\n            try:\n                with open(kb_path, 'r') as f:\n                    kb_data = json.load(f)\n                    kb_machines = kb_data.get(\"machines\", [])\n            except BaseException:\n                pass\n\n        # 3. Find missing machines and try to pre-fill\n        missing_configs = []\n        for eq in all_equipment:\n            if eq.device_serial_number and eq.device_serial_number not in configured_serials:\n\n                # Check KB\n                matched_rule = None\n                # Primary: Serial Match\n                for rule in kb_machines:\n                    if rule.get(\"serial_number\") == eq.device_serial_number:\n                        matched_rule = rule\n                        break\n\n                # Check CTP Rules (Knowledge Base 2)\n                ctp_path = os.path.join(\n                    os.path.dirname(\n                        os.path.abspath(__file__)),\n                    \"resources\",\n                    \"ctp_rules.yaml\")\n                if not os.path.exists(ctp_path):\n                    # Fallback to JSON if YAML doesn't exist\n                    ctp_path = os.path.join(\n                        os.path.dirname(\n                            os.path.abspath(__file__)),\n                        \"resources\",\n                        \"ctp_rules.json\")\n\n                if not matched_rule and os.path.exists(ctp_path):\n                    try:\n                        if ctp_path.endswith('.yaml'):\n                            with open(ctp_path, 'r') as f:\n                                ctp_data = yaml.safe_load(f)\n                        else:\n                            import json\n                            with open(ctp_path, 'r') as f:\n                                ctp_data = json.load(f)\n\n                        ctp_rules = ctp_data.get(\"rules\", [])\n\n                        for rule in ctp_rules:\n                            # Fuzzy matching on Manufacturer and Model\n                            # CTP rules usually have \"manufacturer\" and \"model_name\"\n                            r_man = rule.get(\"manufacturer\", \"\").lower()\n                            r_mod = rule.get(\"model_name\", \"\").lower()\n\n                            eq_man = (eq.manufacturer or \"\").lower()\n                            eq_mod = (eq.model_name or \"\").lower()\n\n                            # Simple containment check as per CTP style\n                            if r_man and r_man in eq_man and r_mod and r_mod in eq_mod:\n                                matched_rule = rule.copy()\n                                matched_rule[\"serial_number\"] = eq.device_serial_number\n\n                                # Move _ctp_condition to comment if present\n                                cond = matched_rule.pop(\"_ctp_condition\", None)\n                                if cond:\n                                    matched_rule[\"comment\"] = f\"Auto-matched from CTP. Condition: {cond}\"\n                                else:\n                                    matched_rule[\"comment\"] = f\"Auto-matched from CTP Knowledge Base ({\n                                        rule.get('manufacturer')} {\n                                        rule.get('model_name')})\"\n\n                                break\n\n                    except Exception as e:\n                        get_logger().warning(f\"Failed to load CTP rules: {e}\")\n\n                # Secondary: Model Match (Internal KB)\n                if not matched_rule:\n                    for rule in kb_machines:\n                        if rule.get(\"model_name\") == eq.model_name:\n                            # It's a model match, so we should probably copy the zones\n                            matches_man = not rule.get(\"manufacturer\") or (\n                                rule.get(\"manufacturer\") == eq.manufacturer)\n                            if matches_man:\n                                matched_rule = rule.copy()\n                                matched_rule[\"serial_number\"] = eq.device_serial_number\n                                matched_rule[\"comment\"] = f\"Auto-matched from Model Knowledge Base ({\n                                    eq.model_name})\"\n                                break\n\n                # 3.b Check for Burned In Annotations (Safety Check)\n                # query index for this machine\n                instances = service.index.get_by_machine(eq.device_serial_number)\n                burned_in_count = 0\n                for inst in instances:\n                    val = inst.attributes.get(\"0028,0301\", \"NO\")\n                    if isinstance(val, str) and \"YES\" in val.upper():\n                        burned_in_count += 1\n\n                safety_comment = \"\"\n                if burned_in_count &gt; 0:\n                    safety_comment = f\"WARNING: {burned_in_count} images have 'Burned In Annotation' flag. Verify pixel redaction.\"\n\n                if matched_rule:\n                    # Use the template\n                    rule_copy = matched_rule.copy()  # Ensure we don't mutate KB\n                    if safety_comment:\n                        existing = rule_copy.get(\"comment\", \"\")\n                        rule_copy[\"comment\"] = f\"{existing} {safety_comment}\".strip()\n                    missing_configs.append(rule_copy)\n                else:\n                    # Create empty scaffold\n                    new_rule = {\n                        \"manufacturer\": eq.manufacturer or \"Unknown\",\n                        \"model_name\": eq.model_name or \"Unknown\",\n                        \"serial_number\": eq.device_serial_number,\n                        \"redaction_zones\": []\n                    }\n                    if safety_comment:\n                        new_rule[\"comment\"] = safety_comment\n                    missing_configs.append(new_rule)\n\n        # 4. Load PHI Tags Default (if not loaded)\n        phi_tags = self.configuration.phi_tags\n        if not phi_tags:\n            # Load default config for scaffold\n            try:\n                phi_tags = ConfigLoader.load_phi_config()\n            except Exception as e:\n                get_logger().warning(f\"Failed to load research tags: {e}\")\n\n        # 4b. Enhance PHI Tags (Transform to structured defaults)\n        structured_tags = {}\n\n        # Ensure critical tags are present\n        if \"0008,0020\" not in phi_tags:\n            phi_tags[\"0008,0020\"] = \"Study Date\"\n        if \"0010,0040\" not in phi_tags:\n            phi_tags[\"0010,0040\"] = \"Patient Sex\"\n        if \"0010,1010\" not in phi_tags:\n            phi_tags[\"0010,1010\"] = \"Patient Age\"  # Helper\n\n        for tag, val in phi_tags.items():\n            name = val if isinstance(val, str) else val.get(\"name\", \"Unknown\")\n            action = \"REMOVE\"  # Default safety\n\n            # Apply Research-Friendly Smart Defaults\n            if tag == \"0008,0020\":  # Study Date\n                action = \"JITTER\"\n            elif tag == \"0010,0040\":  # Sex\n                action = \"KEEP\"\n            elif tag == \"0010,1010\":  # Age\n                action = \"KEEP\"\n            elif \"Date\" in name or \"Time\" in name:\n                action = \"REMOVE\"  # Times are sensitive\n            elif \"ID\" in name:\n                action = \"REMOVE\"  # IDs are sensitive\n\n            # Preserve existing structure if it was already structured\n            if isinstance(val, dict):\n                structured_tags[tag] = val\n            else:\n                # Minimal Scaffold: Skip tags that are simply REMOVED (covered by Basic profile)\n                # Unless explicitly requested to show all? For now, match tests.\n                if action == \"REMOVE\":\n                    continue\n\n                structured_tags[tag] = {\n                    \"name\": name,\n                    \"action\": action\n                }\n\n        # 5. Construct Unified Data\n        data = {\n            \"version\": \"2.0\",\n            \"privacy_profile\": \"basic\",\n            # No _instructions dict anymore, we use comments!\n            \"phi_tags\": structured_tags,\n            \"date_jitter\": self.configuration.date_jitter,\n            \"remove_private_tags\": self.configuration.remove_private_tags,\n            \"machines\": missing_configs + self.configuration.rules\n        }\n\n        if not missing_configs and not self.configuration.rules:\n            print(\"No machines detected to scaffold.\")\n\n        # Pre-process data to ensure comments are single-line strings\n        # And ensure redaction_zones use FlowList for bracketed style\n        for m in data.get(\"machines\", []):\n            if \"comment\" in m and isinstance(m[\"comment\"], str):\n                # Replace newlines with spaces/semicolons\n                m[\"comment\"] = m[\"comment\"].replace(\"\\n\", \" \").replace(\"\\r\", \"\")\n                # collapse multiple spaces\n                m[\"comment\"] = re.sub(r'\\s+', ' ', m[\"comment\"]).strip()\n\n            if \"redaction_zones\" in m and isinstance(m[\"redaction_zones\"], list):\n                # Wrap inner lists (zones) in FlowList\n                # And assume user wants [[...], [...]] so wrap outer too?\n\n                zones = m[\"redaction_zones\"]\n                new_zones = FlowList()\n                for z in zones:\n                    if isinstance(z, list):\n                        new_zones.append(FlowList(z))\n                    else:\n                        new_zones.append(z)\n                m[\"redaction_zones\"] = new_zones  # Assign flow list wrapper\n\n        try:\n            # Generate YAML string\n            # sort_keys=False ensures order is preserved (machines list)\n            # width=float(\"inf\") prevents line wrapping for long strings\n            yaml_content = yaml.dump(\n                data,\n                sort_keys=False,\n                default_flow_style=False,\n                width=float(\"inf\"))\n\n            # Post-process: Convert \"comment: ...\" into \"# ...\"\n            lines = yaml_content.splitlines()\n            new_lines = []\n            for line in lines:\n                # Simple match for key-value pair\n                match = re.search(r'^(\\s*)comment:\\s*(.*)$', line)\n                if match:\n                    indent = match.group(1)\n                    content = match.group(2).strip()\n\n                    # Check for surrounding quotes and strip them\n                    if content.startswith(\"'\") and content.endswith(\"'\"):\n                        content = content[1:-1]\n                        content = content.replace(\"''\", \"'\")\n                    elif content.startswith('\"') and content.endswith('\"'):\n                        content = content[1:-1]\n                        content = content.replace('\\\\\"', '\"')\n\n                    new_lines.append(f\"{indent}# {content}\")\n                else:\n                    if line.strip().startswith(\n                            \"- \") and len(new_lines) &gt; 0 and new_lines[-1].strip() != \"\":\n                        new_lines.append(\"\")\n\n                    new_lines.append(line)\n\n            # Prepend Header Comments\n            header = \"\"\"# Gantry Privacy Configuration (v2.0)\n# ==========================================\n#\n#\n# privacy_profile: \"basic\"\n#   - Standard profile handling common PHI (Name, ID, etc).\n#   - Set to \"none\" for manual control.\n#\n# phi_tags:\n#   - Define custom overrides here.\n#   - Actions: KEEP, REMOVE, EMPTY, REPLACE, JITTER (SHIFT)\n#\n# date_jitter:\n#   - Range of days to shift dates by (negative = into past).\n#\n# remove_private_tags:\n#   - If true, removes all odd-group tags except Gantry Metadata.\n#\n#\n\"\"\"\n            final_content = header + \"\\n\" + \"\\n\".join(new_lines) + \"\\n\"\n\n            with open(output_path, 'w') as f:\n                f.write(final_content)\n\n            get_logger().info(\n                f\"Scaffolded Unified Config to {output_path} ({\n                    len(missing_configs)} new machines)\")\n            print(f\"Scaffolded Unified Config to {output_path}\")\n        except Exception as e:\n            get_logger().error(f\"Failed to write scaffold: {e}\")\n\n    # =========================================================================\n    # AUDIT &amp; ANALYSIS\n    # =========================================================================\n\n    def audit(self, config_path: str = None) -&gt; \"PhiReport\":\n        \"\"\"\n        Scans all patients in the session for potential PHI.\n\n        If `config_path` is provided, it serves as the source of PHI definition tags.\n        Otherwise, the currently loaded configuration (`self.configuration.phi_tags`) is used.\n\n        The scan runs in parallel processes for performance.\n\n        Args:\n            config_path (str, optional): Path to a configuration file defining PHI tags.\n\n        Returns:\n            PhiReport: An object containing valid PHI findings, iterable and exportable.\n        \"\"\"\n\n\n        # Default to current config\n        tags_to_use = self.configuration.phi_tags\n\n        if config_path:\n            try:\n                t, r, dj, rpt = ConfigLoader.load_unified_config(config_path)\n                tags_to_use = t\n            except BaseException:\n                # Fallback to simple tags load\n                tags_to_use = ConfigLoader.load_phi_config(config_path)\n\n        # Uses GantryConfiguration derived tags\n        inspector = PhiInspector(config_tags=tags_to_use,\n                                 remove_private_tags=self.configuration.remove_private_tags)\n        if not inspector.phi_tags:\n            get_logger().warning(\"PHI Scan Warning: No PHI tags defined. Scan will find nothing. Check your config.\")\n\n        get_logger().info(\"Scanning for PHI (Parallel)...\")\n\n        # Hybrid Approach:\n        # Pass lightweight object CLONES to avoid \"Assert left &gt; 0\" IPC error\n        # AND to ensure we audit in-memory (unsaved) changes.\n        worker_args = []\n        for p in self.store.patients:\n            # Strip pixels to reduce size\n            light_p = self._make_lightweight_copy(p)\n            worker_args.append((light_p, tags_to_use, self.configuration.remove_private_tags))\n\n        results = run_parallel(scan_worker, worker_args, desc=\"Scanning PHI\")\n\n        all_findings = []\n        for findings in results:\n            all_findings.extend(findings)\n\n        # Rehydrate Entities!\n        self._rehydrate_findings(all_findings)\n\n        get_logger().info(f\"PHI Scan Complete. Found {len(all_findings)} issues.\")\n\n        return PhiReport(all_findings)\n\n    def scan_pixel_content(self, serial_number: str = None) -&gt; \"PhiReport\":\n        \"\"\"\n        Scans instances in the session for burned-in text using OCR.\n\n        Performs \"Intelligent Verification\":.\n        Only scans instances belonging to machines (Serial Numbers) that are present\n        in the current configuration. Unconfigured machines are skipped.\n\n        Args:\n            serial_number (str, optional): If provided, restricts the scan to ONLY\n                                           machines with this serial number.\n\n        Returns:\n            PhiReport: A report containing findings of filtered (uncovered) burned-in text.\n        \"\"\"\n        get_logger().info(\"Scanning pixel content for text (OCR)...\")\n        print(\"Scanning pixel content for text (OCR)...\")\n\n        # Gather all instances with their equipment context\n        current_rules = self.configuration.rules\n\n        # Build set of valid serials from config\n        configured_serials = {r.get(\"serial_number\") for r in current_rules if r.get(\"serial_number\")}\n\n        worker_items = []\n        skipped_count = 0\n\n        for p in self.store.patients:\n            for st in p.studies:\n                for se in st.series:\n                    equip = se.equipment\n                    if not equip or not equip.device_serial_number:\n                        skipped_count += len(se.instances)\n                        continue\n\n                    sn = equip.device_serial_number\n\n                    # Filter 1: Must be in Config\n                    # We check if we have a rule for this serial\n                    matched_rule = None\n                    for r in current_rules:\n                        if r.get(\"serial_number\") == sn:\n                            matched_rule = r\n                            break\n\n                    if not matched_rule:\n                        skipped_count += len(se.instances)\n                        continue\n\n                    # Rule Refinement: Skip if NO ZONES defined (Scaffolded state)\n                    # Unless user explicitly wants to scan? No, user req says skip.\n                    if not matched_rule.get(\"redaction_zones\"):\n                         # Log once per serial?\n                         # For now just skip\n                         skipped_count += len(se.instances)\n                         continue\n\n                    # Filter 2: Explicit User Filter\n                    if serial_number and sn != serial_number:\n                        continue\n\n                    for inst in se.instances:\n                        worker_items.append((inst, equip, current_rules))\n\n        if not worker_items:\n            msg = \"No matching configured instances found to scan.\"\n            if skipped_count &gt; 0:\n                msg += f\" (Skipped {skipped_count} unconfigured instances)\"\n            print(msg)\n            return PhiReport([])\n\n        results = run_parallel(_verify_worker, worker_items, desc=\"OCR Verification\")\n\n        all_findings = []\n        for r in results:\n            all_findings.extend(r)\n\n        print(f\"OCR Scan Complete. Found {len(all_findings)} suspicious regions (Uncovered).\")\n        return PhiReport(all_findings)\n\n    def auto_remediate_config(self, report: \"PhiReport\") -&gt; int:\n        \"\"\"\n        Analyzes the provided OCR report and automatically updates the session's\n        configuration to fix detected leaks (by expanding zones or adding new ones).\n\n        Args:\n            report (PhiReport): The findings from .scan_pixel_content()\n\n        Returns:\n            int: The number of rules updated.\n        \"\"\"\n        get_logger().info(\"Analyzing report for auto-remediation...\")\n\n        suggestions = ConfigAutomator.suggest_config_updates(report, self.configuration)\n\n        if not suggestions:\n            print(\"No configuration updates suggested.\")\n            return 0\n\n        print(f\"Generated {len(suggestions)} suggestions for config updates.\")\n\n        count = ConfigAutomator.apply_suggestions(self, suggestions)\n\n        if count &gt; 0:\n            print(f\"Applied {count} updates to in-memory configuration.\")\n            print(\"Tip: Run .scan_pixel_content() again to verify fix, then .configuration.save_config() to persist.\")\n\n        return count\n\n        return count\n\n    def discover_redaction_zones(self, serial_number: str, sample_size: int = 50) -&gt; List[List[int]]:\n        \"\"\"\n        Analyzes instances of a specific machine to discover potential redaction zones.\n\n        Args:\n            serial_number (str): The serial number of the machine to target.\n            sample_size (int): Max number of instances to analyze (for speed).\n\n        Returns:\n            List[List[int]]: A list of suggested zones [x, y, w, h].\n        \"\"\"\n        get_logger().info(f\"Discovering zones for {serial_number}...\")\n\n        # 1. Gather instances\n        target_instances = []\n        for p in self.store.patients:\n            for st in p.studies:\n                for se in st.series:\n                    if se.equipment and se.equipment.device_serial_number == serial_number:\n                        target_instances.extend(se.instances)\n\n        if not target_instances:\n            print(f\"No instances found for serial {serial_number}\")\n            return []\n\n        print(f\"Found {len(target_instances)} instances. Using sample of {min(len(target_instances), sample_size)}.\")\n\n        # 2. Sample\n        import random\n        if len(target_instances) &gt; sample_size:\n            sample = random.sample(target_instances, sample_size)\n        else:\n            sample = target_instances\n\n        # 3. Analyze (Parallel?)\n        # Discovery logic is currently serial inside discover_zones?\n        # Actually ZoneDiscoverer.discover_zones iterates list and calls analyze_pixels.\n        # We should parallelize this part if heavy.\n\n        # Let's re-use run_parallel logic? \n        # But ZoneDiscoverer expects list.\n        # Let's map analyze_pixels then pass results to merger.\n\n        raw_regions_lists = run_parallel(pixel_analysis.analyze_pixels, sample, desc=\"Discovery Scan\")\n\n        # Flatten\n        all_regions = []\n        for lst in raw_regions_lists:\n            all_regions.extend(lst)\n\n        # 4. Merge\n        # We need to construct a dummy instance list? No, we need regions.\n        # ZoneDiscoverer logic was: takes instances -&gt; analyzes -&gt; merges.\n        # We just did analysis.\n        # Let's modify discovery usage or extract merge logic.\n\n        # Access internal merge method or refactor ZoneDiscoverer to accept regions?\n        # Since I just wrote it, I know I can just call _merge_overlapping_boxes with box lists.\n        # Boxes needed as [x,y,w,h]\n\n        boxes = [list(r.box) for r in all_regions]\n\n        # We need to access the static method. ideally public.\n        # I'll use the private one for now as it's in same package context effectively.\n        merged = ZoneDiscoverer._merge_overlapping_boxes(boxes)\n\n        # Filter tiny\n        final_zones = [b for b in merged if b[2] &gt; 5 and b[3] &gt; 5]\n\n        print(f\"Discovery complete. Suggested {len(final_zones)} zones.\")\n        return final_zones\n\n    def get_cohort_report(self, expand_metadata: bool = False) -&gt; 'pd.DataFrame':\n        \"\"\"\n        Returns a Pandas DataFrame containing flattened metadata for the current cohort.\n        Useful for analysis and QA.\n        \"\"\"\n        import pandas as pd\n        rows = []\n        for p in self.store.patients:\n            for s in p.studies:\n                for se in s.series:\n                    manufacturer = se.equipment.manufacturer if se.equipment else \"\"\n                    model = se.equipment.model_name if se.equipment else \"\"\n                    device_serial = se.equipment.device_serial_number if se.equipment else \"\"\n\n                    for inst in se.instances:\n                        # Basic row info\n                        row = {\n                            \"PatientID\": p.patient_id,\n                            \"PatientName\": p.patient_name,\n                            \"StudyInstanceUID\": s.study_instance_uid,\n                            \"StudyDate\": s.study_date,\n                            \"SeriesInstanceUID\": se.series_instance_uid,\n                            \"Modality\": se.modality,\n                            \"SOPInstanceUID\": inst.sop_instance_uid,\n                            \"Manufacturer\": manufacturer,\n                            \"Model\": model,\n                            \"DeviceSerial\": device_serial\n                        }\n\n                        if expand_metadata and hasattr(inst, 'attributes') and inst.attributes:\n                            row.update(inst.attributes)\n\n                        rows.append(row)\n\n        return pd.DataFrame(rows)\n\n    def generate_report(self, output_path: str, format: str = \"markdown\") -&gt; None:\n        \"\"\"\n        Generates a formal Compliance Report for the current session.\n\n        The report includes:\n        - Session statistics (counts).\n        - Audit logs and exceptions.\n        - Check for unsafe attributes (e.g., Burned In Annotations).\n        - Privacy Profile information.\n\n        Args:\n            output_path (str): The file path where the report should be saved.\n            format (str): The output format ('markdown' or 'md'). Defaults to \"markdown\".\n        \"\"\"\n        get_logger().info(f\"Generating Compliance Report ({format}) to {output_path}...\")\n\n        # 1. Gather Statistics\n        n_p = len(self.store.patients)\n        n_st = sum(len(p.studies) for p in self.store.patients)\n        n_se = sum(len(st.series) for p in self.store.patients for st in p.studies)\n        n_i = sum(len(se.instances)\n                  for p in self.store.patients for st in p.studies for se in st.series)\n\n        # 2. Gather Audit Logs &amp; Exceptions\n        audit_summary = self.store_backend.get_audit_summary()\n        exceptions = self.store_backend.get_audit_errors()\n\n        # Check for unsafe attributes (BurnedInAnnotation)\n        unsafe_items = self.store_backend.check_unsafe_attributes()\n        if unsafe_items:\n            for uid, fpath, msg in unsafe_items:\n                exceptions.append(\n                    (datetime.datetime.now().isoformat(),\n                     \"COMPLIANCE_CHECK\",\n                     f\"{msg} - {uid}\"))\n\n        # 3. Determine Context\n        privacy_profile = \"See Config\"\n        try:\n            from importlib.metadata import version\n            ver = version(\"gantry\")\n        except BaseException:\n            ver = \"0.0.0\"\n\n        # 4. Build Report DTO\n        report = ComplianceReport(\n            gantry_version=ver,\n            project_name=os.path.basename(self.persistence_file),\n            privacy_profile=privacy_profile,\n            total_patients=n_p,\n            total_studies=n_st,\n            total_series=n_se,\n            total_instances=n_i,\n            audit_summary=audit_summary,\n            exceptions=exceptions,\n            validation_status=\"PASS\" if audit_summary and not exceptions else \"REVIEW_REQUIRED\"\n        )\n\n        renderer = get_renderer(format)\n        renderer.render(report, output_path)\n\n    def generate_manifest(self, output_path: str, format: str = \"html\") -&gt; None:\n        \"\"\"\n        Generates a visual (HTML) or machine-readable (JSON) manifest of all instances.\n\n        This manifest lists every SOP Instance currently tracked in the session,\n        along with its file path and key metadata (Modality, Manufacturer, etc.).\n\n        Args:\n            output_path (str): The file path where the manifest should be saved.\n            format (str): The output format ('html' or 'json'). Defaults to \"html\".\n        \"\"\"\n        get_logger().info(f\"Generating Manifest ({format}) to {output_path}...\")\n\n        items = []\n        for p in self.store.patients:\n            for st in p.studies:\n                for se in st.series:\n                    modality = se.modality\n                    manufacturer = se.equipment.manufacturer if se.equipment else \"\"\n                    model = se.equipment.model_name if se.equipment else \"\"\n\n                    for inst in se.instances:\n                        fpath = getattr(inst, 'file_path', \"N/A\")\n\n                        item = ManifestItem(\n                            patient_id=p.patient_id,\n                            study_instance_uid=st.study_instance_uid,\n                            series_instance_uid=se.series_instance_uid,\n                            sop_instance_uid=inst.sop_instance_uid,\n                            file_path=str(fpath),\n                            modality=modality,\n                            manufacturer=manufacturer,\n                            model_name=model\n                        )\n                        items.append(item)\n\n        manifest = Manifest(\n            generated_at=datetime.datetime.now().isoformat(),\n            items=items,\n            project_name=os.path.basename(self.persistence_file)\n        )\n\n        generate_manifest_file(manifest, output_path, format)\n\n    def save_analysis(self, report):\n        \"\"\"\n        Persists the results of a PHI analysis to the database.\n\n        Args:\n            report (Union[PhiReport, List[PhiFinding]]): The PHI report object or list of findings to save.\n        \"\"\"\n        findings = report\n        if hasattr(report, 'findings'):\n            findings = report.findings\n\n        self.store_backend.save_findings(findings)\n\n    # =========================================================================\n    # PRIVACY &amp; SECURITY\n    # =========================================================================\n\n    def lock_identities(self,\n                        patient_id: str,\n                        persist: bool = False,\n                        _patient_obj: \"Patient\" = None,\n                        verbose: bool = True,\n                        **kwargs) -&gt; Union[List[\"Instance\"],\n                                           LockingResult]:\n        \"\"\"\n        Securely embeds the original patient name/ID into a private DICOM tag.\n\n        This mechanism allows for \"Reversible Anonymization\". The original identity\n        is encrypted using a symmetric key and stored in a private attribute\n        before the visible public attributes are anonymized.\n\n        Must be called BEFORE anonymization/redaction if recovery is required.\n\n        Args:\n            patient_id (str): The ID of the patient to preserve (or a list/report for batch processing).\n            persist (bool): If True, writes changes to the database immediately.\n                            If False, returns modified instances (useful for batch buffering).\n            _patient_obj (Patient, optional): Optimization argument to avoid O(N) lookup.\n            verbose (bool): If True, logs debug information.\n            **kwargs: Additional arguments passed to `lock_identities_batch`.\n\n        Returns:\n            Union[List[Instance], LockingResult]: A list of modified instances.\n        \"\"\"\n        if not self.reversibility_service:\n            raise RuntimeError(\n                \"Reversible anonymization not enabled. Call enable_reversible_anonymization() first.\")\n\n        # Dispatch to batch method if a list is provided\n        if isinstance(patient_id, (list, tuple, set)) or hasattr(patient_id, 'findings'):\n            return self.lock_identities_batch(patient_id, **kwargs)\n\n        if verbose:\n            get_logger().debug(f\"Preserving identity for {patient_id}...\")\n\n        modified_instances = []\n\n        if _patient_obj:\n            patient = _patient_obj\n        else:\n            patient = next((p for p in self.store.patients if p.patient_id == patient_id), None)\n\n        if not patient:\n            get_logger().error(f\"Patient {patient_id} not found.\")\n            return LockingResult([])\n\n        # Determine Tags to Lock (Default + Custom)\n        default_tags = [\n            \"0010,0010\",  # PatientName\n            \"0010,0020\",  # PatientID\n            \"0010,0030\",  # PatientBirthDate\n            \"0010,0040\",  # PatientSex\n            \"0008,0050\"  # AccessionNumber\n        ]\n\n        tags_to_lock = kwargs.get(\"tags_to_lock\", default_tags)\n\n        # Capture Original Values from First Instance\n        original_attrs = {}\n        first_instance = None\n\n        # Locate first instance efficiently\n        for st in patient.studies:\n            for se in st.series:\n                if se.instances:\n                    first_instance = se.instances[0]\n                    break\n            if first_instance:\n                break\n\n        if first_instance:\n            for tag in tags_to_lock:\n                val = first_instance.attributes.get(tag)\n                if val is not None:\n                    original_attrs[tag] = val\n        else:\n            # Fallback to Patient object properties if no instances (unlikely)\n            if \"0010,0010\" in tags_to_lock:\n                original_attrs[\"0010,0010\"] = patient.patient_name\n            if \"0010,0020\" in tags_to_lock:\n                original_attrs[\"0010,0020\"] = patient.patient_id\n\n        cnt = 0\n\n        # Optimization: Encrypt once per patient\n        token = self.reversibility_service.generate_identity_token(\n            original_attributes=original_attrs)\n\n        # Iterate deep\n        for st in patient.studies:\n            for se in st.series:\n                for inst in se.instances:\n                    self.reversibility_service.embed_identity_token(inst, token)\n                    modified_instances.append(inst)\n                    cnt += 1\n\n        if persist and modified_instances:\n            self.store_backend.update_attributes(modified_instances)\n            get_logger().info(\n                f\"Secured identity (tags: {\n                    list(\n                        original_attrs.keys())}) in {cnt} instances for {patient_id}.\")\n\n        return LockingResult(modified_instances)\n\n    def lock_identities_batch(self,\n                              patient_ids: Union[List[str],\n                                                 \"PhiReport\",\n                                                 List[\"PhiFinding\"]],\n                              auto_persist_chunk_size: int = 0) -&gt; Union[List[\"Instance\"],\n                                                                         LockingResult]:\n        \"\"\"\n        Batch process multiple patients to lock identities.\n\n        Args:\n            patient_ids (Union[List[str], PhiReport]): List of PatientIDs to process.\n            auto_persist_chunk_size (int): If &gt; 0, persists changes and releases memory every N instances.\n                                           IMPORTANT: Returns an empty list if enabled to prevent OOM.\n\n        Returns:\n            Union[List[Instance], LockingResult]: List of all modified instances (if chunking is disabled).\n        \"\"\"\n        if not self.reversibility_service:\n            raise RuntimeError(\"Reversible anonymization not enabled.\")\n\n        # Normalize input to a set of strings\n        normalized_ids = set()\n\n        # Handle PhiReport or list containers\n        iterable_data = patient_ids\n        if hasattr(patient_ids, 'findings'):  # PhiReport\n            iterable_data = patient_ids.findings\n\n        for item in iterable_data:\n            if isinstance(item, str):\n                normalized_ids.add(item)\n            elif hasattr(item, 'patient_id') and item.patient_id:\n                normalized_ids.add(item.patient_id)\n\n        start_ids = list(normalized_ids)\n\n        modified_instances = []  # Only used if auto_persist_chunk_size == 0\n        current_chunk = []      # Used if auto_persist_chunk_size &gt; 0\n\n        count_patients = 0\n        count_instances_chunked = 0\n\n        from tqdm import tqdm\n\n        # Optimization: Create a lookup map for O(1) access\n        patient_map = {p.patient_id: p for p in self.store.patients}\n\n        with tqdm(start_ids, desc=\"Locking Identities\", unit=\"patient\") as pbar:\n            for pid in pbar:\n                p_obj = patient_map.get(pid)\n                if p_obj:\n                    # Use verbose=False to avoid log spam\n                    res = self.lock_identities(\n                        pid, persist=False, _patient_obj=p_obj, verbose=False)\n\n                    if auto_persist_chunk_size &gt; 0:\n                        current_chunk.extend(res)\n                        if len(current_chunk) &gt;= auto_persist_chunk_size:\n                            self.store_backend.update_attributes(current_chunk)\n                            count_instances_chunked += len(current_chunk)\n                            current_chunk = []  # Release memory\n                    else:\n                        modified_instances.extend(res)\n\n                    count_patients += 1\n                else:\n                    get_logger().error(f\"Patient {pid} not found (batch processing).\")\n\n        # Final cleanup\n        if auto_persist_chunk_size &gt; 0:\n            if current_chunk:\n                self.store_backend.update_attributes(current_chunk)\n                count_instances_chunked += len(current_chunk)\n\n            get_logger().info(\n                f\"Batch preserved identity for {count_patients} patients ({count_instances_chunked} instances). Persisted incrementally.\")\n            return LockingResult([])\n\n        if modified_instances:\n            msg = f\"Preserved identity for {len(modified_instances)} instances.\"\n            get_logger().info(msg)\n\n        get_logger().info(\n            f\"Batch preserved identity for {count_patients} patients ({\n                len(modified_instances)} instances).\")\n        return LockingResult(modified_instances)\n\n    def recover_patient_identity(self, patient_id: str, restore: bool = True):\n        \"\"\"\n        Attempts to recover original identity from the encrypted private token.\n\n        Decrypts the private tag stored by `lock_identities` and optionally\n        restores the original PatientName and PatientID public attributes.\n\n        Args:\n            patient_id (str): The PatientID to search for and recover.\n            restore (bool): If True, applies the recovered attributes back to ALL\n                            in-memory instances for this patient.\n        \"\"\"\n        if not self.reversibility_service:\n            raise RuntimeError(\"Reversibility not enabled.\")\n\n        p = next((x for x in self.store.patients if x.patient_id == patient_id), None)\n        if not p:\n            print(f\"Patient {patient_id} not found.\")\n            return\n\n        # Locate first instance to get the token\n        first_inst = None\n        for st in p.studies:\n            for se in st.series:\n                if se.instances:\n                    first_inst = se.instances[0]\n                    break\n\n        if not first_inst:\n            print(\"No instances found for patient.\")\n            return\n\n        original_attrs = self.reversibility_service.recover_original_data(first_inst)\n\n        if original_attrs:\n            if restore:\n                count = 0\n                for st in p.studies:\n                    for se in st.series:\n                        for inst in se.instances:\n                            for tag, val in original_attrs.items():\n                                inst.set_attr(tag, val)\n                            count += 1\n\n                # Update Patient Object top-level properties if Name/ID changed\n                if \"0010,0010\" in original_attrs:\n                    p.patient_name = original_attrs[\"0010,0010\"]\n                if \"0010,0020\" in original_attrs:\n                    p.patient_id = original_attrs[\"0010,0020\"]\n\n                get_logger().info(f\"Restored identity attributes to {count} instances.\")\n        else:\n            print(\"No encrypted identity token found or decryption failed.\")\n\n    def enable_reversible_anonymization(self, key_path: str = \"gantry.key\"):\n        \"\"\"\n        Initializes the encryption subsystem for Reversible Anonymization.\n\n        Loads or generates a symmetric key which is used to encrypt original identities.\n\n        Args:\n            key_path (str): Path to the key file.\n        \"\"\"\n        self.key_manager = KeyManager(key_path)\n        self.key_manager.load_or_generate_key()\n        self.reversibility_service = ReversibilityService(self.key_manager)\n        get_logger().info(f\"Reversible anonymization enabled. Key: {key_path}\")\n\n    # =========================================================================\n    # REDACTION &amp; REMEDIATION\n    # =========================================================================\n\n    def redact(self, show_progress=True):\n        \"\"\"\n        Applies pixel redaction rules to the current session.\n\n        Uses the currently loaded configuration (`self.configuration.rules`) to find and\n        redact sensitive regions in the pixel data. This operation modifies the\n        pixel data in-memory (and via Sidecar for persistence).\n\n        Args:\n            show_progress (bool): If True, displays a progress bar.\n        \"\"\"\n        if not self.configuration.rules:\n            get_logger().warning(\"No configuration loaded. Use .load_config() first.\")\n            print(\"No configuration loaded. Use .load_config() first.\")\n            return\n\n        service = RedactionService(self.store, self.store_backend)\n\n        try:\n            from concurrent.futures import ThreadPoolExecutor\n            import os\n\n            # Parallel Execution for Speed\n            # Threading works well here because pixel I/O and NumPy ops release GIL.\n            # Shared memory allows in-place modification of instances.\n            # OPTIMIZATION: Limited to 0.5x CPU or Max 8 to prevent OOM with large datasets\n            cpu_count = os.cpu_count() or 1\n            if os.environ.get(\"GANTRY_MAX_WORKERS\"):\n                max_workers = int(os.environ[\"GANTRY_MAX_WORKERS\"])\n            else:\n                max_workers = max(1, min(int(cpu_count * 0.5), 8))\n\n            # Generate granular tasks for better load balancing\n            all_tasks = []\n            get_logger().info(\"Analyzing workload...\")\n            for rule in self.configuration.rules:\n                tasks = service.prepare_redaction_tasks(rule)\n                all_tasks.extend(tasks)\n\n            if not all_tasks:\n                get_logger().warning(\"No matching images found for any loaded rules.\")\n                print(\"No matching images found for any loaded rules.\")\n                return\n\n            print(\n                f\"Queued {len(all_tasks)} redaction tasks across {len(self.configuration.rules)} rules.\")\n            print(f\"Executing using {max_workers} workers (Process Isolation)...\")\n            # 2. Parallel Redaction (Granular)\n            get_logger().info(\n                f\"Starting granular redaction ({\n                    len(all_tasks)} tasks, workers={max_workers})...\")\n\n            # Map for quick Result application (SOP -&gt; Instance)\n            instance_map = {t['instance'].sop_instance_uid: t['instance'] for t in all_tasks}\n\n            try:\n                # Use Process Isolation (Standard Pool) - Workers clean up via GC/Exit\n                # We consume generator to apply updates incrementally\n                results_gen = run_parallel(\n                    service.execute_redaction_task,\n                    all_tasks,\n                    desc=\"Redacting Pixels\",\n                    max_workers=max_workers,\n                    return_generator=True,\n                    chunksize=1,\n                    progress=show_progress)\n\n                for mutation in results_gen:\n                    if mutation:\n                        sop = mutation.get('original_sop_uid') or mutation.get('sop_uid')\n                        if sop in instance_map:\n                            inst = instance_map[sop]\n\n                            # 1. Apply Attributes &amp; Sequences\n                            if mutation.get('attributes'):\n                                inst.attributes.update(mutation['attributes'])\n                            if mutation.get('sequences'):\n                                inst.sequences.update(mutation['sequences'])\n\n                            # 2. Apply Pixel Loader (Critical)\n                            # The loader acts as our handle to the sidecar data\n                            loader = mutation.get('pixel_loader')\n                            if loader:\n                                # Fix Reference: Loader points to Worker's Instance copy.\n                                # Re-point it to the Main Process Instance.\n                                loader.instance = inst\n                                inst._pixel_loader = loader\n                                print(f\"DEBUG: Updated loader for {sop} -&gt; {loader.offset}\")\n\n                            if mutation.get('pixel_hash'):\n                                inst._pixel_hash = mutation['pixel_hash']\n\n                            inst._dirty = True\n                            print(f\"DEBUG: Instance {sop} updated in memory.\")\n                        else:\n                            print(\n                                f\"DEBUG: MISS! {sop} not in instance_map {\n                                    list(\n                                        instance_map.keys())[\n                                        :3]}...\")\n\n            finally:\n                pass\n\n            # Run Safety Checks\n            service.scan_burned_in_annotations()\n\n            print(\"Execution Complete. Remember to call .save() to persist.\")\n            print(\"Execution Complete. Session saved.\")\n\n        except Exception as e:\n            get_logger().error(f\"Execution interrupted: {e}\")\n            print(f\"Execution interrupted: {e}\")\n\n    def redact_by_machine(self, serial_number: str, roi: List[int]):\n        \"\"\"\n        Helper to run redaction for a single machine interactively.\n\n        Temporarily overrides the configuration to apply a single ROI to a specific device.\n\n        Args:\n            serial_number (str): The device serial number to target.\n            roi (List[int]): The Region of Interest as [y1, y2, x1, x2].\n        \"\"\"\n        # This Helper is tricky. It modifies the ACTIVE configuration temporarily?\n        # Or just runs temporary logic?\n        # Original logic modified active_rules. Let's keep that behavior on our config object.\n        original = list(self.configuration.rules)  # Shallow copy\n        try:\n            self.configuration.rules = [{\"serial_number\": serial_number, \"redaction_zones\": [roi]}]\n            self.redact()\n        finally:\n            self.configuration.rules = original\n\n    def anonymize(self, findings: List[PhiFinding] = None):\n        \"\"\"\n        Apply remediation Actions to PHI Findings (Tag Anonymization).\n\n        If `findings` is provided, only those specific findings are remediated.\n        If `findings` is None, a full audit is performed using the current configuration,\n        and all resulting findings are remediated (\"Blind Execute\").\n\n        Args:\n            findings (List[PhiFinding], optional): Specific findings to clean.\n        \"\"\"\n        from .remediation import RemediationService\n        # Pass date jitter config to constructor\n        # Use persistence_manager.store_backend (SqliteStore) for audit logging\n        remediator = RemediationService(\n            store_backend=self.persistence_manager.store_backend,\n            date_jitter_config=self.configuration.date_jitter\n        )\n\n        count = 0\n        if findings:\n            count = remediator.apply_remediation(findings)\n        else:\n            # Blind execution (apply all rules)\n            # We need to generate findings based on current config first?\n            # Or assume RemediationService can handle blind?\n            # Actually, standard flow assumes findings.\n            tqdm_desc = \"Blind Anonymize\"\n            # Logic for blind anonymization: scan then remediate\n            # Use audit() which uses self.configuration internally now\n            current_findings = self.audit()\n            count = remediator.apply_remediation(current_findings)\n\n        get_logger().info(f\"Anonymized {count} entities.\")\n        print(f\"Anonymized/Remediated {count} tags according to policy.\")\n\n    # =========================================================================\n    # EXPORT\n    # =========================================================================\n\n    def export(self, folder: str, version=None, use_compression=True,\n               check_burned_in=False, check_reversibility=True, patient_ids: List[str] = None, show_progress=True,\n               # Legacy/Test Support arguments\n               compression=None, safe=False, subset=None):\n        \"\"\"\n        Exports the current session to a directory, structured by Patient/Study/Series.\n\n        Args:\n            folder (str): The output directory path.\n            version (str, optional): Deprecated/Unused.\n            use_compression (bool): If True, compresses output images using JPEG2000 (Lossless).\n            check_burned_in (bool): If True, performs a safety scan for 'Burned In Annotation' flags before export.\n            check_reversibility (bool): If True, checks if reversibility is enabled (informational).\n            patient_ids (List[str], optional): Limit export to specific Patient IDs.\n            show_progress (bool): If True, shows progress bar.\n\n            # Legacy Arguments\n            compression (bool): Alias for `use_compression`.\n            safe (bool): Alias for `check_burned_in`.\n            subset (Union[str, list, pd.DataFrame]): Filter export using a query string, list of UIDs, or DataFrame.\n        \"\"\"\n        import os\n        from .io_handlers import DicomExporter\n\n        # 1. Validation Checks\n        if check_reversibility and self.reversibility_service:\n            # warn if we are exporting encrypted data without warning?\n            # Actually Gantry exports exactly what is in store (which might be encrypted).\n            pass\n\n        target_ids = patient_ids\n        if target_ids is None:\n            target_ids = [p.patient_id for p in self.store.patients]\n\n        # Legacy Argument Mapping\n        if compression is not None:\n            use_compression = compression\n        if safe:\n            check_burned_in = True\n\n        # SAFETY CHECK &amp; FEEDBACK LOOP\n        # If running in safe mode, run a full scan first to give aggregated feedback\n        if check_burned_in:\n            get_logger().info(\"Performing pre-export safety scan...\")\n            findings = self.scan_for_phi()\n            if findings:\n                print(\"\\nSafety Scan Found Issues\")\n                print(\"The following tags were flagged as dirty:\")\n                print(f\"{'Tag':&lt;15} {'Description':&lt;30} {'Count':&lt;10} {'Examples'}\")\n                print(\"-\" * 80)\n\n                from collections import Counter\n                counts = Counter()\n                examples = {}\n                descriptions = {}\n\n                for f in findings:\n                    tag = f.tag or f.field_name\n                    counts[tag] += 1\n                    if tag not in examples:\n                        examples[tag] = str(f.value)\n                    descriptions[tag] = f.reason\n\n                for tag, count in counts.items():\n                    ex = examples[tag][:30]\n                    desc = descriptions[tag][:28]\n                    print(f\"{tag:&lt;15} {desc:&lt;30} {count:&lt;10} {ex}\")\n\n                print(\"\\nSuggested Config Update:\")\n                print(\"Add the following rules to your config to resolve these:\")\n                print(\"{\")\n                print('    \"phi_tags\": {')\n                rows = []\n                for tag in counts:\n                    # Attempt to infer name\n                    name = \"patient_name\" if \"0010,0010\" in tag else \"unknown_tag\"\n                    if \"0010,0020\" in tag:\n                        name = \"patient_id\"\n                    if \"0008,0020\" in tag:\n                        name = \"study_date\"\n\n                    rows.append(\n                        f'        \"{tag}\": {{ \"name\": \"{name}\", \"action\": \"REMOVE\" }} , // Found {counts[tag]} times')\n                print(\",\\n\".join(rows))\n                print('    }')\n                print(\"}\")\n\n                print('    }')\n                print(\"}\")\n\n                get_logger().warning(\"Safe Export: PHI findings detected. Proceeding to export ONLY safe instances (Skipping dirty).\")\n                # Build Dirty Filter\n                dirty_uids = set()\n                for f in findings:\n                    if f.entity_uid:\n                        dirty_uids.add(f.entity_uid)\n\n            else:\n                dirty_uids = set()\n\n        # Subset resolution\n        allowed_uids = None\n        if subset is not None:\n            import pandas as pd\n            df = None\n            if isinstance(subset, str):\n                # Query string\n                full_df = self.get_cohort_report(expand_metadata=True)\n                try:\n                    df = full_df.query(subset)\n                except Exception as e:\n                    get_logger().error(f\"Failed to query subset '{subset}': {e}\")\n                    return\n            elif isinstance(subset, pd.DataFrame):\n                df = subset\n            elif isinstance(subset, list):\n                # Assume list of UIDs (Patient, Series, or Instance)\n                # We need to match against any level. simpler to scan.\n                # For now, let's assume if it matches PatientID, SeriesUID, or SOPUID we keep it.\n                subset_set = set(subset)\n                allowed_uids = subset_set  # We will pass this to filter\n\n            if df is not None:\n                # Extract all UIDs relevant\n                allowed_uids = set()\n                # PRECISION EXPORT:\n                # If we have SOPInstanceUID, we ONLY use that to ensure we match the exact rows returned by the query.\n                # Adding PatientID would re-include ALL instances for that patient\n                # (defeating granular filters like Modality='CT').\n                if \"SOPInstanceUID\" in df.columns:\n                    allowed_uids.update(df[\"SOPInstanceUID\"].tolist())\n                # Fallbacks if SOPInstanceUID is missing (e.g. custom dataframe)\n                elif \"SeriesInstanceUID\" in df.columns:\n                    allowed_uids.update(df[\"SeriesInstanceUID\"].tolist())\n                elif \"StudyInstanceUID\" in df.columns:\n                    allowed_uids.update(df[\"StudyInstanceUID\"].tolist())\n                elif \"PatientID\" in df.columns:\n                    allowed_uids.update(df[\"PatientID\"].tolist())\n\n        get_logger().info(f\"Exporting session to: {folder}\")\n        print(\"Preparing export plan...\")\n\n        # 2. Memory Management Check\n        # Before starting a massive export (which might load pixels), ensure we save pending changes\n        # and flush memory to avoid OOM if user did a lot of redaction.\n        print(\"Saving pending changes to free memory...\")\n        self.save()\n        self.release_memory()\n\n        # 3. Create Export Plan (Lightweight objects)\n        export_tasks = []\n        total_instances = 0\n\n        count_p = 0\n        count_i = 0\n\n        # We iterate our store to build tasks.\n        # But for parallelism, we want to pass file paths or DB IDs, not full objects.\n        # DicomExporter needs (Instance -&gt; OutputPath) mapping.\n\n        # Pre-calculate paths\n        # Structure: Folder / Patient / Study / Series / Instance\n\n        # Optimization: We can generate the plan using minimal metadata\n        from .io_handlers import ExportContext\n\n        for p in self.store.patients:\n            if p.patient_id not in target_ids:\n                continue\n\n            count_p += 1\n            p_clean = \"Subject_\" + ConfigLoader.clean_filename(p.patient_id or \"UnknownPatient\")\n            p_path = os.path.join(folder, p_clean)\n\n            pat_attrs = {\n                \"0010,0010\": p.patient_name,\n                \"0010,0020\": p.patient_id\n            }\n            if hasattr(p, 'birth_date') and p.birth_date:\n                pat_attrs[\"0010,0030\"] = p.birth_date\n            if hasattr(p, 'sex') and p.sex:\n                pat_attrs[\"0010,0040\"] = p.sex\n\n            for st in p.studies:\n                # Hybrid Naming: Study_YYYYMMDD_Description_UIDSuffix\n                st_desc = \"Study\"\n                # Peek at first series-&gt;instance for description\n                try:\n                    if st.series and st.series[0].instances:\n                        st_desc = st.series[0].instances[0].attributes.get(\"0008,1030\", \"Study\")\n                except BaseException:\n                    pass\n\n                st_date = str(st.study_date or \"NoDate\")\n                st_uid_suffix = (st.study_instance_uid or \"Unknown\")[-5:]\n\n                st_folder_name = f\"Study_{st_date}_{st_desc}_{st_uid_suffix}\"\n                st_clean = ConfigLoader.clean_filename(st_folder_name)\n                st_path = os.path.join(p_path, st_clean)\n\n                study_attrs = {\n                    \"0020,000D\": st.study_instance_uid,\n                    \"0008,0020\": st.study_date,\n                }\n                if hasattr(st, 'study_time') and st.study_time:\n                    study_attrs[\"0008,0030\"] = st.study_time\n                if hasattr(st, 'accession_number'):\n                    study_attrs[\"0008,0050\"] = st.accession_number\n\n                for se in st.series:\n                    # Hybrid Naming: Series_NUM_Modality_Description_UIDSuffix\n                    se_desc = \"Series\"\n                    try:\n                        if se.instances:\n                            se_desc = se.instances[0].attributes.get(\"0008,103e\", \"Series\")\n                    except BaseException:\n                        pass\n\n                    se_num = str(se.series_number)\n                    se_mod = se.modality or \"OT\"\n                    se_uid_suffix = (se.series_instance_uid or \"Unknown\")[-5:]\n\n                    se_folder_name = f\"Series_{se_num}_{se_mod}_{se_desc}_{se_uid_suffix}\"\n                    se_clean = ConfigLoader.clean_filename(se_folder_name)\n                    se_path = os.path.join(st_path, se_clean)\n\n                    series_attrs = {\n                        \"0020,000E\": se.series_instance_uid,\n                        \"0008,0060\": se.modality,\n                        \"0020,0011\": str(se.series_number)\n                    }\n                    if hasattr(se, 'series_description'):\n                        series_attrs[\"0008,103E\"] = se.series_description\n\n                    for inst in se.instances:\n                        # Debug\n                        # print(f\"Checking instance {inst.sop_instance_uid}...\")\n\n                        if check_burned_in:\n                            # HIERARCHICAL SAFETY CHECK\n                            # If parent (Patient, Study, Series) is dirty, skip instance.\n                            # Also check instance itself.\n                            is_dirty = False\n                            if p.patient_id in dirty_uids:\n                                is_dirty = True\n                            elif st.study_instance_uid in dirty_uids:\n                                is_dirty = True\n                            elif se.series_instance_uid in dirty_uids:\n                                is_dirty = True\n                            elif inst.sop_instance_uid in dirty_uids:\n                                is_dirty = True\n\n                            # Fallback: Per-instance check if not already flagged dirty but inspector failed?\n                            # No, Pre-Check covered everything.\n\n                            if is_dirty:\n                                get_logger().warning(\n                                    f\"Skipping unsafe instance {\n                                        inst.sop_instance_uid} (Entity or Parent is Dirty).\")\n                                continue\n\n                        # Legacy Subset Filtering\n                        if allowed_uids is not None:\n                            if (inst.sop_instance_uid not in allowed_uids and\n                                se.series_instance_uid not in allowed_uids and\n                                st.study_instance_uid not in allowed_uids and\n                                    p.patient_id not in allowed_uids):\n                                continue\n\n                        count_i += 1\n                        out_path = os.path.join(\n                            se_path, ConfigLoader.clean_filename(\n                                inst.sop_instance_uid)) + \".dcm\"\n\n                        ctx = ExportContext(\n                            instance=inst,\n                            output_path=out_path,\n                            patient_attributes=pat_attrs,\n                            study_attributes=study_attrs,\n                            series_attributes=series_attrs,\n                            compression='j2k' if use_compression else None\n                        )\n\n                        export_tasks.append(ctx)\n                        total_instances += 1\n\n        if not export_tasks:\n            get_logger().warning(\"No instances found to export.\")\n            return\n\n        print(f\"Exporting {total_instances} images from {count_p} patients...\")\n\n        # 4. Execute Export\n        # We use global run_parallel logic or specialized internal batcher?\n        # session.py line 1107 used DicomExporter.export_batch with maxtasksperchild=25\n\n        chunk_size = 500  # Report progress every N\n        show_progress = True\n\n        if total_instances &gt; 0:\n            # MEMORY LEAK MITIGATION:\n            # We use worker recycling (maxtasksperchild=100) via multiprocessing.Pool\n            # This forces workers to restart periodically, clearing any leaked memory (e.g. from C-libs).\n            # We do NOT use the shared self._executor for this, as ProcessPoolExecutor\n            # doesn't support recycling.\n            try:\n                # Optimized for stability: maxtasksperchild=25 clears memory frequently\n                # GC Optimization: Disable GC in workers\n                success_count = DicomExporter.export_batch(\n                    export_tasks,\n                    show_progress=show_progress,\n                    total=total_instances,\n                    maxtasksperchild=25,\n                    disable_gc=True)\n            except Exception as e:\n                get_logger().error(f\"Export Failed! Error: {e}\")\n                raise e\n            finally:\n                # Main process GC trigger\n                import gc\n                gc.collect()\n\n            get_logger().info(f\"Export complete.\")\n        else:\n            get_logger().warning(\"No instances queued for export.\")\n\n        print(\"Done.\")\n\n    def export_dataframe(\n            self,\n            output_path: str = \"export_metadata.csv\",\n            expand_metadata: bool = False):\n        \"\"\"\n        Exports flat validation metadata to CSV or Parquet.\n\n        Args:\n            output_path (str): The output file path (ends with .csv or .parquet).\n            expand_metadata (bool): If True, includes all DICOM attributes as columns.\n        \"\"\"\n        import pandas as pd\n        df = self.get_cohort_report(expand_metadata=expand_metadata)\n\n        if output_path.endswith(\".parquet\"):\n            try:\n                # Requires pyarrow and pandas\n                df.to_parquet(output_path, index=False)\n            except Exception as e:\n                get_logger().error(f\"Failed to export parquet: {e}\")\n                raise e\n        else:\n            df.to_csv(output_path, index=False)\n\n        print(f\"Exported metadata to {output_path}\")\n        return df\n\n    def export_to_parquet(self, output_path: str, patient_ids: List[str] = None):\n        \"\"\"\n        [EXPERIMENTAL] Exports flattened metadata to a Parquet file.\n        Requires 'pandas' and 'pyarrow' or 'fastparquet'.\n        \"\"\"\n        try:\n            import pandas as pd\n        except ImportError:\n            get_logger().error(\"export_to_parquet requires 'pandas' installed.\")\n            raise ImportError(\n                \"Please install pandas to use this feature: pip install pandas pyarrow\")\n\n        # 1. Sync DB state\n        get_logger().info(\"Saving state before Parquet export...\")\n        self.save()\n\n        # 2. Stream Data\n        get_logger().info(\"Streaming data from database...\")\n\n        target_ids = patient_ids\n        if target_ids is None:\n            target_ids = [p.patient_id for p in self.store.patients]\n\n        if not target_ids:\n            get_logger().warning(\"No patients to export.\")\n            return\n\n        generator = self.persistence_manager.store_backend.get_flattened_instances(target_ids)\n\n        rows = list(generator)\n\n        if not rows:\n            get_logger().warning(\"No instances found for these patients.\")\n            return\n\n        df = pd.DataFrame(rows)\n\n        # 3. Save\n        get_logger().info(f\"Writing {len(df)} rows to {output_path}...\")\n\n        # Ensure directory exists\n        os.makedirs(os.path.dirname(os.path.abspath(output_path)), exist_ok=True)\n\n        try:\n            df.to_parquet(output_path, index=False)\n            get_logger().info(\"Parquet export successful.\")\n        except ImportError as e:\n            get_logger().error(\"Parquet engine (pyarrow or fastparquet) missing.\")\n            raise e\n        except Exception as e:\n            get_logger().error(f\"Failed to write parquet: {e}\")\n            raise\n\n    # =========================================================================\n    # INTERNAL HELPERS\n    # =========================================================================\n\n    def _rehydrate_findings(self, findings):\n        \"\"\"\n        Updates findings in-place to point to live objects in self.store\n        instead of the unpickled copies from workers.\n        \"\"\"\n        patient_map = {p.patient_id: p for p in self.store.patients}\n        study_map = {}\n        instance_map = {}\n\n        for p in self.store.patients:\n            for s in p.studies:\n                study_map[s.study_instance_uid] = s\n                for se in s.series:\n                    for i in se.instances:\n                        instance_map[i.sop_instance_uid] = i\n\n        for f in findings:\n            if f.entity_type == \"Patient\":\n                if f.entity_uid in patient_map:\n                    f.entity = patient_map[f.entity_uid]\n            elif f.entity_type == \"Study\":\n                if f.entity_uid in study_map:\n                    f.entity = study_map[f.entity_uid]\n            elif f.entity_type == \"Instance\":\n                if f.entity_uid in instance_map:\n                    f.entity = instance_map[f.entity_uid]\n\n    def _make_lightweight_copy(self, patient: \"Patient\") -&gt; \"Patient\":\n        \"\"\"\n        Creates a lightweight clone of the Patient object (and children)\n        stripped of heavy pixel data, for efficient IPC transfer.\n        Also attaches 'file_path' to instances to ensure workers can reload pixels if needed.\n        \"\"\"\n        from .entities import Patient, Study, Series, Instance\n\n        # Clone Patient\n        p_new = Patient(\n            patient_name=patient.patient_name,\n            patient_id=patient.patient_id\n        )\n\n        for s in patient.studies:\n            s_new = Study(\n                study_instance_uid=s.study_instance_uid,\n                study_date=s.study_date\n            )\n            if hasattr(s, \"date_shifted\"):\n                s_new.date_shifted = s.date_shifted\n\n            p_new.studies.append(s_new)\n\n            for se in s.series:\n                se_new = Series(\n                    series_instance_uid=se.series_instance_uid,\n                    modality=se.modality,\n                    series_number=se.series_number\n                )\n                if se.equipment:\n                    se_new.equipment = se.equipment\n                s_new.series.append(se_new)\n\n                for i in se.instances:\n                    # Clone Instance\n                    i_new = Instance(\n                        sop_instance_uid=i.sop_instance_uid,\n                        instance_number=i.instance_number,\n                        sop_class_uid=i.sop_class_uid,\n                        file_path=i.file_path\n                    )\n                    # Key: Ensure attributes are copied so workers can scan tags\n                    if hasattr(i, 'attributes'):\n                        i_new.attributes = i.attributes.copy()\n\n                    if hasattr(i, \"date_shifted\"):\n                        i_new.date_shifted = i.date_shifted\n\n                    se_new.instances.append(i_new)\n\n        return p_new\n\n    # =========================================================================\n    # DEPRECATED\n    # =========================================================================\n\n    def scan_for_phi(self, config_path: str = None) -&gt; \"PhiReport\":\n        \"\"\"\n        Legacy alias for audit().\n        \"\"\"\n        return self.audit(config_path)\n</code></pre>"},{"location":"api/session/#gantry.session.DicomSession.ingest","title":"<code>ingest(directory)</code>","text":"<p>Ingests DICOM files from a directory into the session store.</p> <p>Recursively scans the provided directory for valid DICOM files. Files are parsed and organized into the Patient -&gt; Study -&gt; Series -&gt; Instance hierarchy. This operation automatically saves the session state upon completion.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>The path to the directory containing DICOM files.</p> required Source code in <code>gantry/session.py</code> <pre><code>def ingest(self, directory: str):\n    \"\"\"\n    Ingests DICOM files from a directory into the session store.\n\n    Recursively scans the provided directory for valid DICOM files.\n    Files are parsed and organized into the Patient -&gt; Study -&gt; Series -&gt; Instance hierarchy.\n    This operation automatically saves the session state upon completion.\n\n    Args:\n        directory (str): The path to the directory containing DICOM files.\n    \"\"\"\n    print(f\"Ingesting from '{directory}'...\")\n    # Pass Sidecar Manager for eager pixel writing\n    DicomImporter.import_files(\n        [directory],\n        self.store,\n        executor=self._executor,\n        sidecar_manager=self.store_backend.sidecar)\n\n    self.save(sync=True)\n\n    # Calculate stats\n    n_p = len(self.store.patients)\n    n_st = sum(len(p.studies) for p in self.store.patients)\n    n_se = sum(len(st.series) for p in self.store.patients for st in p.studies)\n    n_i = sum(len(se.instances)\n              for p in self.store.patients for st in p.studies for se in st.series)\n\n    print(f\"Ingestion complete. Saved session state.\")\n    print(\"Summary:\")\n    print(f\"  - {n_p} Patients\")\n    print(f\"  - {n_st} Studies\")\n    print(f\"  - {n_se} Series\")\n    print(f\"  - {n_i} Instances\")\n</code></pre>"},{"location":"api/session/#gantry.session.DicomSession.save","title":"<code>save(sync=False)</code>","text":"<p>Persists the current session state to the database. :param sync: If True, blocks until save is complete.</p> Source code in <code>gantry/session.py</code> <pre><code>def save(self, sync: bool = False):\n    \"\"\"\n    Persists the current session state to the database.\n    :param sync: If True, blocks until save is complete.\n    \"\"\"\n    if sync and hasattr(self, 'store_backend'):\n        get_logger().info(\"Saving session (Synchronous)...\")\n        self.store_backend.save_all(self.store.patients)\n    elif hasattr(self, 'persistence_manager'):\n        self.persistence_manager.save_async(self.store.patients)\n</code></pre>"},{"location":"api/session/#gantry.session.DicomSession.export","title":"<code>export(folder, version=None, use_compression=True, check_burned_in=False, check_reversibility=True, patient_ids=None, show_progress=True, compression=None, safe=False, subset=None)</code>","text":"<p>Exports the current session to a directory, structured by Patient/Study/Series.</p> <p>Parameters:</p> Name Type Description Default <code>folder</code> <code>str</code> <p>The output directory path.</p> required <code>version</code> <code>str</code> <p>Deprecated/Unused.</p> <code>None</code> <code>use_compression</code> <code>bool</code> <p>If True, compresses output images using JPEG2000 (Lossless).</p> <code>True</code> <code>check_burned_in</code> <code>bool</code> <p>If True, performs a safety scan for 'Burned In Annotation' flags before export.</p> <code>False</code> <code>check_reversibility</code> <code>bool</code> <p>If True, checks if reversibility is enabled (informational).</p> <code>True</code> <code>patient_ids</code> <code>List[str]</code> <p>Limit export to specific Patient IDs.</p> <code>None</code> <code>show_progress</code> <code>bool</code> <p>If True, shows progress bar.</p> <code>True</code> <code>compression</code> <code>bool</code> <p>Alias for <code>use_compression</code>.</p> <code>None</code> <code>safe</code> <code>bool</code> <p>Alias for <code>check_burned_in</code>.</p> <code>False</code> <code>subset</code> <code>Union[str, list, DataFrame]</code> <p>Filter export using a query string, list of UIDs, or DataFrame.</p> <code>None</code> Source code in <code>gantry/session.py</code> <pre><code>def export(self, folder: str, version=None, use_compression=True,\n           check_burned_in=False, check_reversibility=True, patient_ids: List[str] = None, show_progress=True,\n           # Legacy/Test Support arguments\n           compression=None, safe=False, subset=None):\n    \"\"\"\n    Exports the current session to a directory, structured by Patient/Study/Series.\n\n    Args:\n        folder (str): The output directory path.\n        version (str, optional): Deprecated/Unused.\n        use_compression (bool): If True, compresses output images using JPEG2000 (Lossless).\n        check_burned_in (bool): If True, performs a safety scan for 'Burned In Annotation' flags before export.\n        check_reversibility (bool): If True, checks if reversibility is enabled (informational).\n        patient_ids (List[str], optional): Limit export to specific Patient IDs.\n        show_progress (bool): If True, shows progress bar.\n\n        # Legacy Arguments\n        compression (bool): Alias for `use_compression`.\n        safe (bool): Alias for `check_burned_in`.\n        subset (Union[str, list, pd.DataFrame]): Filter export using a query string, list of UIDs, or DataFrame.\n    \"\"\"\n    import os\n    from .io_handlers import DicomExporter\n\n    # 1. Validation Checks\n    if check_reversibility and self.reversibility_service:\n        # warn if we are exporting encrypted data without warning?\n        # Actually Gantry exports exactly what is in store (which might be encrypted).\n        pass\n\n    target_ids = patient_ids\n    if target_ids is None:\n        target_ids = [p.patient_id for p in self.store.patients]\n\n    # Legacy Argument Mapping\n    if compression is not None:\n        use_compression = compression\n    if safe:\n        check_burned_in = True\n\n    # SAFETY CHECK &amp; FEEDBACK LOOP\n    # If running in safe mode, run a full scan first to give aggregated feedback\n    if check_burned_in:\n        get_logger().info(\"Performing pre-export safety scan...\")\n        findings = self.scan_for_phi()\n        if findings:\n            print(\"\\nSafety Scan Found Issues\")\n            print(\"The following tags were flagged as dirty:\")\n            print(f\"{'Tag':&lt;15} {'Description':&lt;30} {'Count':&lt;10} {'Examples'}\")\n            print(\"-\" * 80)\n\n            from collections import Counter\n            counts = Counter()\n            examples = {}\n            descriptions = {}\n\n            for f in findings:\n                tag = f.tag or f.field_name\n                counts[tag] += 1\n                if tag not in examples:\n                    examples[tag] = str(f.value)\n                descriptions[tag] = f.reason\n\n            for tag, count in counts.items():\n                ex = examples[tag][:30]\n                desc = descriptions[tag][:28]\n                print(f\"{tag:&lt;15} {desc:&lt;30} {count:&lt;10} {ex}\")\n\n            print(\"\\nSuggested Config Update:\")\n            print(\"Add the following rules to your config to resolve these:\")\n            print(\"{\")\n            print('    \"phi_tags\": {')\n            rows = []\n            for tag in counts:\n                # Attempt to infer name\n                name = \"patient_name\" if \"0010,0010\" in tag else \"unknown_tag\"\n                if \"0010,0020\" in tag:\n                    name = \"patient_id\"\n                if \"0008,0020\" in tag:\n                    name = \"study_date\"\n\n                rows.append(\n                    f'        \"{tag}\": {{ \"name\": \"{name}\", \"action\": \"REMOVE\" }} , // Found {counts[tag]} times')\n            print(\",\\n\".join(rows))\n            print('    }')\n            print(\"}\")\n\n            print('    }')\n            print(\"}\")\n\n            get_logger().warning(\"Safe Export: PHI findings detected. Proceeding to export ONLY safe instances (Skipping dirty).\")\n            # Build Dirty Filter\n            dirty_uids = set()\n            for f in findings:\n                if f.entity_uid:\n                    dirty_uids.add(f.entity_uid)\n\n        else:\n            dirty_uids = set()\n\n    # Subset resolution\n    allowed_uids = None\n    if subset is not None:\n        import pandas as pd\n        df = None\n        if isinstance(subset, str):\n            # Query string\n            full_df = self.get_cohort_report(expand_metadata=True)\n            try:\n                df = full_df.query(subset)\n            except Exception as e:\n                get_logger().error(f\"Failed to query subset '{subset}': {e}\")\n                return\n        elif isinstance(subset, pd.DataFrame):\n            df = subset\n        elif isinstance(subset, list):\n            # Assume list of UIDs (Patient, Series, or Instance)\n            # We need to match against any level. simpler to scan.\n            # For now, let's assume if it matches PatientID, SeriesUID, or SOPUID we keep it.\n            subset_set = set(subset)\n            allowed_uids = subset_set  # We will pass this to filter\n\n        if df is not None:\n            # Extract all UIDs relevant\n            allowed_uids = set()\n            # PRECISION EXPORT:\n            # If we have SOPInstanceUID, we ONLY use that to ensure we match the exact rows returned by the query.\n            # Adding PatientID would re-include ALL instances for that patient\n            # (defeating granular filters like Modality='CT').\n            if \"SOPInstanceUID\" in df.columns:\n                allowed_uids.update(df[\"SOPInstanceUID\"].tolist())\n            # Fallbacks if SOPInstanceUID is missing (e.g. custom dataframe)\n            elif \"SeriesInstanceUID\" in df.columns:\n                allowed_uids.update(df[\"SeriesInstanceUID\"].tolist())\n            elif \"StudyInstanceUID\" in df.columns:\n                allowed_uids.update(df[\"StudyInstanceUID\"].tolist())\n            elif \"PatientID\" in df.columns:\n                allowed_uids.update(df[\"PatientID\"].tolist())\n\n    get_logger().info(f\"Exporting session to: {folder}\")\n    print(\"Preparing export plan...\")\n\n    # 2. Memory Management Check\n    # Before starting a massive export (which might load pixels), ensure we save pending changes\n    # and flush memory to avoid OOM if user did a lot of redaction.\n    print(\"Saving pending changes to free memory...\")\n    self.save()\n    self.release_memory()\n\n    # 3. Create Export Plan (Lightweight objects)\n    export_tasks = []\n    total_instances = 0\n\n    count_p = 0\n    count_i = 0\n\n    # We iterate our store to build tasks.\n    # But for parallelism, we want to pass file paths or DB IDs, not full objects.\n    # DicomExporter needs (Instance -&gt; OutputPath) mapping.\n\n    # Pre-calculate paths\n    # Structure: Folder / Patient / Study / Series / Instance\n\n    # Optimization: We can generate the plan using minimal metadata\n    from .io_handlers import ExportContext\n\n    for p in self.store.patients:\n        if p.patient_id not in target_ids:\n            continue\n\n        count_p += 1\n        p_clean = \"Subject_\" + ConfigLoader.clean_filename(p.patient_id or \"UnknownPatient\")\n        p_path = os.path.join(folder, p_clean)\n\n        pat_attrs = {\n            \"0010,0010\": p.patient_name,\n            \"0010,0020\": p.patient_id\n        }\n        if hasattr(p, 'birth_date') and p.birth_date:\n            pat_attrs[\"0010,0030\"] = p.birth_date\n        if hasattr(p, 'sex') and p.sex:\n            pat_attrs[\"0010,0040\"] = p.sex\n\n        for st in p.studies:\n            # Hybrid Naming: Study_YYYYMMDD_Description_UIDSuffix\n            st_desc = \"Study\"\n            # Peek at first series-&gt;instance for description\n            try:\n                if st.series and st.series[0].instances:\n                    st_desc = st.series[0].instances[0].attributes.get(\"0008,1030\", \"Study\")\n            except BaseException:\n                pass\n\n            st_date = str(st.study_date or \"NoDate\")\n            st_uid_suffix = (st.study_instance_uid or \"Unknown\")[-5:]\n\n            st_folder_name = f\"Study_{st_date}_{st_desc}_{st_uid_suffix}\"\n            st_clean = ConfigLoader.clean_filename(st_folder_name)\n            st_path = os.path.join(p_path, st_clean)\n\n            study_attrs = {\n                \"0020,000D\": st.study_instance_uid,\n                \"0008,0020\": st.study_date,\n            }\n            if hasattr(st, 'study_time') and st.study_time:\n                study_attrs[\"0008,0030\"] = st.study_time\n            if hasattr(st, 'accession_number'):\n                study_attrs[\"0008,0050\"] = st.accession_number\n\n            for se in st.series:\n                # Hybrid Naming: Series_NUM_Modality_Description_UIDSuffix\n                se_desc = \"Series\"\n                try:\n                    if se.instances:\n                        se_desc = se.instances[0].attributes.get(\"0008,103e\", \"Series\")\n                except BaseException:\n                    pass\n\n                se_num = str(se.series_number)\n                se_mod = se.modality or \"OT\"\n                se_uid_suffix = (se.series_instance_uid or \"Unknown\")[-5:]\n\n                se_folder_name = f\"Series_{se_num}_{se_mod}_{se_desc}_{se_uid_suffix}\"\n                se_clean = ConfigLoader.clean_filename(se_folder_name)\n                se_path = os.path.join(st_path, se_clean)\n\n                series_attrs = {\n                    \"0020,000E\": se.series_instance_uid,\n                    \"0008,0060\": se.modality,\n                    \"0020,0011\": str(se.series_number)\n                }\n                if hasattr(se, 'series_description'):\n                    series_attrs[\"0008,103E\"] = se.series_description\n\n                for inst in se.instances:\n                    # Debug\n                    # print(f\"Checking instance {inst.sop_instance_uid}...\")\n\n                    if check_burned_in:\n                        # HIERARCHICAL SAFETY CHECK\n                        # If parent (Patient, Study, Series) is dirty, skip instance.\n                        # Also check instance itself.\n                        is_dirty = False\n                        if p.patient_id in dirty_uids:\n                            is_dirty = True\n                        elif st.study_instance_uid in dirty_uids:\n                            is_dirty = True\n                        elif se.series_instance_uid in dirty_uids:\n                            is_dirty = True\n                        elif inst.sop_instance_uid in dirty_uids:\n                            is_dirty = True\n\n                        # Fallback: Per-instance check if not already flagged dirty but inspector failed?\n                        # No, Pre-Check covered everything.\n\n                        if is_dirty:\n                            get_logger().warning(\n                                f\"Skipping unsafe instance {\n                                    inst.sop_instance_uid} (Entity or Parent is Dirty).\")\n                            continue\n\n                    # Legacy Subset Filtering\n                    if allowed_uids is not None:\n                        if (inst.sop_instance_uid not in allowed_uids and\n                            se.series_instance_uid not in allowed_uids and\n                            st.study_instance_uid not in allowed_uids and\n                                p.patient_id not in allowed_uids):\n                            continue\n\n                    count_i += 1\n                    out_path = os.path.join(\n                        se_path, ConfigLoader.clean_filename(\n                            inst.sop_instance_uid)) + \".dcm\"\n\n                    ctx = ExportContext(\n                        instance=inst,\n                        output_path=out_path,\n                        patient_attributes=pat_attrs,\n                        study_attributes=study_attrs,\n                        series_attributes=series_attrs,\n                        compression='j2k' if use_compression else None\n                    )\n\n                    export_tasks.append(ctx)\n                    total_instances += 1\n\n    if not export_tasks:\n        get_logger().warning(\"No instances found to export.\")\n        return\n\n    print(f\"Exporting {total_instances} images from {count_p} patients...\")\n\n    # 4. Execute Export\n    # We use global run_parallel logic or specialized internal batcher?\n    # session.py line 1107 used DicomExporter.export_batch with maxtasksperchild=25\n\n    chunk_size = 500  # Report progress every N\n    show_progress = True\n\n    if total_instances &gt; 0:\n        # MEMORY LEAK MITIGATION:\n        # We use worker recycling (maxtasksperchild=100) via multiprocessing.Pool\n        # This forces workers to restart periodically, clearing any leaked memory (e.g. from C-libs).\n        # We do NOT use the shared self._executor for this, as ProcessPoolExecutor\n        # doesn't support recycling.\n        try:\n            # Optimized for stability: maxtasksperchild=25 clears memory frequently\n            # GC Optimization: Disable GC in workers\n            success_count = DicomExporter.export_batch(\n                export_tasks,\n                show_progress=show_progress,\n                total=total_instances,\n                maxtasksperchild=25,\n                disable_gc=True)\n        except Exception as e:\n            get_logger().error(f\"Export Failed! Error: {e}\")\n            raise e\n        finally:\n            # Main process GC trigger\n            import gc\n            gc.collect()\n\n        get_logger().info(f\"Export complete.\")\n    else:\n        get_logger().warning(\"No instances queued for export.\")\n\n    print(\"Done.\")\n</code></pre>"},{"location":"api/session/#gantry.session.DicomSession.audit","title":"<code>audit(config_path=None)</code>","text":"<p>Scans all patients in the session for potential PHI.</p> <p>If <code>config_path</code> is provided, it serves as the source of PHI definition tags. Otherwise, the currently loaded configuration (<code>self.configuration.phi_tags</code>) is used.</p> <p>The scan runs in parallel processes for performance.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>Path to a configuration file defining PHI tags.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>PhiReport</code> <code>PhiReport</code> <p>An object containing valid PHI findings, iterable and exportable.</p> Source code in <code>gantry/session.py</code> <pre><code>def audit(self, config_path: str = None) -&gt; \"PhiReport\":\n    \"\"\"\n    Scans all patients in the session for potential PHI.\n\n    If `config_path` is provided, it serves as the source of PHI definition tags.\n    Otherwise, the currently loaded configuration (`self.configuration.phi_tags`) is used.\n\n    The scan runs in parallel processes for performance.\n\n    Args:\n        config_path (str, optional): Path to a configuration file defining PHI tags.\n\n    Returns:\n        PhiReport: An object containing valid PHI findings, iterable and exportable.\n    \"\"\"\n\n\n    # Default to current config\n    tags_to_use = self.configuration.phi_tags\n\n    if config_path:\n        try:\n            t, r, dj, rpt = ConfigLoader.load_unified_config(config_path)\n            tags_to_use = t\n        except BaseException:\n            # Fallback to simple tags load\n            tags_to_use = ConfigLoader.load_phi_config(config_path)\n\n    # Uses GantryConfiguration derived tags\n    inspector = PhiInspector(config_tags=tags_to_use,\n                             remove_private_tags=self.configuration.remove_private_tags)\n    if not inspector.phi_tags:\n        get_logger().warning(\"PHI Scan Warning: No PHI tags defined. Scan will find nothing. Check your config.\")\n\n    get_logger().info(\"Scanning for PHI (Parallel)...\")\n\n    # Hybrid Approach:\n    # Pass lightweight object CLONES to avoid \"Assert left &gt; 0\" IPC error\n    # AND to ensure we audit in-memory (unsaved) changes.\n    worker_args = []\n    for p in self.store.patients:\n        # Strip pixels to reduce size\n        light_p = self._make_lightweight_copy(p)\n        worker_args.append((light_p, tags_to_use, self.configuration.remove_private_tags))\n\n    results = run_parallel(scan_worker, worker_args, desc=\"Scanning PHI\")\n\n    all_findings = []\n    for findings in results:\n        all_findings.extend(findings)\n\n    # Rehydrate Entities!\n    self._rehydrate_findings(all_findings)\n\n    get_logger().info(f\"PHI Scan Complete. Found {len(all_findings)} issues.\")\n\n    return PhiReport(all_findings)\n</code></pre>"},{"location":"api/session/#gantry.session.DicomSession.redact","title":"<code>redact(show_progress=True)</code>","text":"<p>Applies pixel redaction rules to the current session.</p> <p>Uses the currently loaded configuration (<code>self.configuration.rules</code>) to find and redact sensitive regions in the pixel data. This operation modifies the pixel data in-memory (and via Sidecar for persistence).</p> <p>Parameters:</p> Name Type Description Default <code>show_progress</code> <code>bool</code> <p>If True, displays a progress bar.</p> <code>True</code> Source code in <code>gantry/session.py</code> <pre><code>def redact(self, show_progress=True):\n    \"\"\"\n    Applies pixel redaction rules to the current session.\n\n    Uses the currently loaded configuration (`self.configuration.rules`) to find and\n    redact sensitive regions in the pixel data. This operation modifies the\n    pixel data in-memory (and via Sidecar for persistence).\n\n    Args:\n        show_progress (bool): If True, displays a progress bar.\n    \"\"\"\n    if not self.configuration.rules:\n        get_logger().warning(\"No configuration loaded. Use .load_config() first.\")\n        print(\"No configuration loaded. Use .load_config() first.\")\n        return\n\n    service = RedactionService(self.store, self.store_backend)\n\n    try:\n        from concurrent.futures import ThreadPoolExecutor\n        import os\n\n        # Parallel Execution for Speed\n        # Threading works well here because pixel I/O and NumPy ops release GIL.\n        # Shared memory allows in-place modification of instances.\n        # OPTIMIZATION: Limited to 0.5x CPU or Max 8 to prevent OOM with large datasets\n        cpu_count = os.cpu_count() or 1\n        if os.environ.get(\"GANTRY_MAX_WORKERS\"):\n            max_workers = int(os.environ[\"GANTRY_MAX_WORKERS\"])\n        else:\n            max_workers = max(1, min(int(cpu_count * 0.5), 8))\n\n        # Generate granular tasks for better load balancing\n        all_tasks = []\n        get_logger().info(\"Analyzing workload...\")\n        for rule in self.configuration.rules:\n            tasks = service.prepare_redaction_tasks(rule)\n            all_tasks.extend(tasks)\n\n        if not all_tasks:\n            get_logger().warning(\"No matching images found for any loaded rules.\")\n            print(\"No matching images found for any loaded rules.\")\n            return\n\n        print(\n            f\"Queued {len(all_tasks)} redaction tasks across {len(self.configuration.rules)} rules.\")\n        print(f\"Executing using {max_workers} workers (Process Isolation)...\")\n        # 2. Parallel Redaction (Granular)\n        get_logger().info(\n            f\"Starting granular redaction ({\n                len(all_tasks)} tasks, workers={max_workers})...\")\n\n        # Map for quick Result application (SOP -&gt; Instance)\n        instance_map = {t['instance'].sop_instance_uid: t['instance'] for t in all_tasks}\n\n        try:\n            # Use Process Isolation (Standard Pool) - Workers clean up via GC/Exit\n            # We consume generator to apply updates incrementally\n            results_gen = run_parallel(\n                service.execute_redaction_task,\n                all_tasks,\n                desc=\"Redacting Pixels\",\n                max_workers=max_workers,\n                return_generator=True,\n                chunksize=1,\n                progress=show_progress)\n\n            for mutation in results_gen:\n                if mutation:\n                    sop = mutation.get('original_sop_uid') or mutation.get('sop_uid')\n                    if sop in instance_map:\n                        inst = instance_map[sop]\n\n                        # 1. Apply Attributes &amp; Sequences\n                        if mutation.get('attributes'):\n                            inst.attributes.update(mutation['attributes'])\n                        if mutation.get('sequences'):\n                            inst.sequences.update(mutation['sequences'])\n\n                        # 2. Apply Pixel Loader (Critical)\n                        # The loader acts as our handle to the sidecar data\n                        loader = mutation.get('pixel_loader')\n                        if loader:\n                            # Fix Reference: Loader points to Worker's Instance copy.\n                            # Re-point it to the Main Process Instance.\n                            loader.instance = inst\n                            inst._pixel_loader = loader\n                            print(f\"DEBUG: Updated loader for {sop} -&gt; {loader.offset}\")\n\n                        if mutation.get('pixel_hash'):\n                            inst._pixel_hash = mutation['pixel_hash']\n\n                        inst._dirty = True\n                        print(f\"DEBUG: Instance {sop} updated in memory.\")\n                    else:\n                        print(\n                            f\"DEBUG: MISS! {sop} not in instance_map {\n                                list(\n                                    instance_map.keys())[\n                                    :3]}...\")\n\n        finally:\n            pass\n\n        # Run Safety Checks\n        service.scan_burned_in_annotations()\n\n        print(\"Execution Complete. Remember to call .save() to persist.\")\n        print(\"Execution Complete. Session saved.\")\n\n    except Exception as e:\n        get_logger().error(f\"Execution interrupted: {e}\")\n        print(f\"Execution interrupted: {e}\")\n</code></pre>"},{"location":"api/session/#gantry.session.DicomSession.load_config","title":"<code>load_config(config_file)</code>","text":"<p>Loads a configuration file into memory without applying it.</p> <p>This allows the user to validate the configuration or run a preview using <code>preview_config()</code> before performing any destructive actions.</p> <p>Parameters:</p> Name Type Description Default <code>config_file</code> <code>str</code> <p>Path to the YAML or JSON configuration file.</p> required Source code in <code>gantry/session.py</code> <pre><code>def load_config(self, config_file: str):\n    \"\"\"\n    Loads a configuration file into memory without applying it.\n\n    This allows the user to validate the configuration or run a preview using\n    `preview_config()` before performing any destructive actions.\n\n    Args:\n        config_file (str): Path to the YAML or JSON configuration file.\n    \"\"\"\n    try:\n        get_logger().info(f\"Loading configuration from {config_file}...\")\n        print(f\"Loading configuration from {config_file}...\")\n\n        # UNIFIED LOAD (v2) - Now loading into GantryConfiguration object\n        tags, rules, jitter, remove_private = ConfigLoader.load_unified_config(config_file)\n\n        # Update the configuration object\n        self.configuration.phi_tags = tags\n        self.configuration.rules = rules\n        self.configuration.date_jitter = jitter\n        self.configuration.remove_private_tags = remove_private\n        self.configuration.config_path = config_file\n\n        get_logger().info(\n            f\"Loaded {len(self.configuration.rules)} machine rules and {len(self.configuration.phi_tags)} PHI tags.\")\n        print(\n            f\"Configuration Loaded:\\n - {len(self.configuration.rules)} Machine Redaction Rules\\n - {len(self.configuration.phi_tags)} PHI Tags\")\n        print(\n            f\" - Date Jitter: {\n                self.configuration.date_jitter['min_days']} to {\n                self.configuration.date_jitter['max_days']} days\")\n        print(f\" - Remove Private Tags: {self.configuration.remove_private_tags}\")\n        print(\"Tip: Run .audit() to check PHI, or .redact_pixels() to apply redaction.\")\n    except Exception as e:\n        import traceback\n        get_logger().error(f\"Load failed: {e}\")\n        print(f\"Load failed: {e}\")\n        print(traceback.format_exc())\n        # Reset on failure? OR keep previous?\n        # Original behavior was reset.\n        self.configuration.rules = []\n        self.configuration.phi_tags = {}\n</code></pre>"},{"location":"api/session/#gantry.session.DicomSession.create_config","title":"<code>create_config(output_path)</code>","text":"<p>Generates a unified configuration file (scaffold) in YAML format.</p> <p>This method analyzes the current session inventory (Equipment, Manufacturers) and attempts to auto-generate redaction rules based on internal knowledge bases (e.g., CTP rules). It also includes a default set of PHI tags.</p> <p>Parameters:</p> Name Type Description Default <code>output_path</code> <code>str</code> <p>The file path where the generated YAML configuration should be saved.</p> required Source code in <code>gantry/session.py</code> <pre><code>    def create_config(self, output_path: str):\n        \"\"\"\n        Generates a unified configuration file (scaffold) in YAML format.\n\n        This method analyzes the current session inventory (Equipment, Manufacturers)\n        and attempts to auto-generate redaction rules based on internal knowledge bases\n        (e.g., CTP rules). It also includes a default set of PHI tags.\n\n        Args:\n            output_path (str): The file path where the generated YAML configuration should be saved.\n        \"\"\"\n\n\n        # Helper for Flow-Style Lists (Bracketed)\n        class FlowList(list):\n            pass\n\n        def flow_list_representer(dumper, data):\n            return dumper.represent_sequence('tag:yaml.org,2002:seq', data, flow_style=True)\n\n        yaml.add_representer(FlowList, flow_list_representer)\n\n        if not (output_path.endswith(\".yaml\") or output_path.endswith(\".yml\")):\n            output_path += \".yaml\"\n            print(f\"Note: Appending .yaml extension -&gt; {output_path}\")\n\n        # 1. Identify what we have\n        all_equipment = self.store.get_unique_equipment()\n\n        # Instantiate service to query pixel/tag data efficiently\n        service = RedactionService(self.store)\n\n        # 2. Identify what is already configured (Pixel Rules)\n        configured_serials = {rule.get(\"serial_number\") for rule in self.configuration.rules}\n\n        # Load Knowledge Base for Machines\n        kb_path = os.path.join(\n            os.path.dirname(\n                os.path.abspath(__file__)),\n            \"resources\",\n            \"redaction_rules.json\")\n        kb_machines = []\n        if os.path.exists(kb_path):\n            try:\n                with open(kb_path, 'r') as f:\n                    kb_data = json.load(f)\n                    kb_machines = kb_data.get(\"machines\", [])\n            except BaseException:\n                pass\n\n        # 3. Find missing machines and try to pre-fill\n        missing_configs = []\n        for eq in all_equipment:\n            if eq.device_serial_number and eq.device_serial_number not in configured_serials:\n\n                # Check KB\n                matched_rule = None\n                # Primary: Serial Match\n                for rule in kb_machines:\n                    if rule.get(\"serial_number\") == eq.device_serial_number:\n                        matched_rule = rule\n                        break\n\n                # Check CTP Rules (Knowledge Base 2)\n                ctp_path = os.path.join(\n                    os.path.dirname(\n                        os.path.abspath(__file__)),\n                    \"resources\",\n                    \"ctp_rules.yaml\")\n                if not os.path.exists(ctp_path):\n                    # Fallback to JSON if YAML doesn't exist\n                    ctp_path = os.path.join(\n                        os.path.dirname(\n                            os.path.abspath(__file__)),\n                        \"resources\",\n                        \"ctp_rules.json\")\n\n                if not matched_rule and os.path.exists(ctp_path):\n                    try:\n                        if ctp_path.endswith('.yaml'):\n                            with open(ctp_path, 'r') as f:\n                                ctp_data = yaml.safe_load(f)\n                        else:\n                            import json\n                            with open(ctp_path, 'r') as f:\n                                ctp_data = json.load(f)\n\n                        ctp_rules = ctp_data.get(\"rules\", [])\n\n                        for rule in ctp_rules:\n                            # Fuzzy matching on Manufacturer and Model\n                            # CTP rules usually have \"manufacturer\" and \"model_name\"\n                            r_man = rule.get(\"manufacturer\", \"\").lower()\n                            r_mod = rule.get(\"model_name\", \"\").lower()\n\n                            eq_man = (eq.manufacturer or \"\").lower()\n                            eq_mod = (eq.model_name or \"\").lower()\n\n                            # Simple containment check as per CTP style\n                            if r_man and r_man in eq_man and r_mod and r_mod in eq_mod:\n                                matched_rule = rule.copy()\n                                matched_rule[\"serial_number\"] = eq.device_serial_number\n\n                                # Move _ctp_condition to comment if present\n                                cond = matched_rule.pop(\"_ctp_condition\", None)\n                                if cond:\n                                    matched_rule[\"comment\"] = f\"Auto-matched from CTP. Condition: {cond}\"\n                                else:\n                                    matched_rule[\"comment\"] = f\"Auto-matched from CTP Knowledge Base ({\n                                        rule.get('manufacturer')} {\n                                        rule.get('model_name')})\"\n\n                                break\n\n                    except Exception as e:\n                        get_logger().warning(f\"Failed to load CTP rules: {e}\")\n\n                # Secondary: Model Match (Internal KB)\n                if not matched_rule:\n                    for rule in kb_machines:\n                        if rule.get(\"model_name\") == eq.model_name:\n                            # It's a model match, so we should probably copy the zones\n                            matches_man = not rule.get(\"manufacturer\") or (\n                                rule.get(\"manufacturer\") == eq.manufacturer)\n                            if matches_man:\n                                matched_rule = rule.copy()\n                                matched_rule[\"serial_number\"] = eq.device_serial_number\n                                matched_rule[\"comment\"] = f\"Auto-matched from Model Knowledge Base ({\n                                    eq.model_name})\"\n                                break\n\n                # 3.b Check for Burned In Annotations (Safety Check)\n                # query index for this machine\n                instances = service.index.get_by_machine(eq.device_serial_number)\n                burned_in_count = 0\n                for inst in instances:\n                    val = inst.attributes.get(\"0028,0301\", \"NO\")\n                    if isinstance(val, str) and \"YES\" in val.upper():\n                        burned_in_count += 1\n\n                safety_comment = \"\"\n                if burned_in_count &gt; 0:\n                    safety_comment = f\"WARNING: {burned_in_count} images have 'Burned In Annotation' flag. Verify pixel redaction.\"\n\n                if matched_rule:\n                    # Use the template\n                    rule_copy = matched_rule.copy()  # Ensure we don't mutate KB\n                    if safety_comment:\n                        existing = rule_copy.get(\"comment\", \"\")\n                        rule_copy[\"comment\"] = f\"{existing} {safety_comment}\".strip()\n                    missing_configs.append(rule_copy)\n                else:\n                    # Create empty scaffold\n                    new_rule = {\n                        \"manufacturer\": eq.manufacturer or \"Unknown\",\n                        \"model_name\": eq.model_name or \"Unknown\",\n                        \"serial_number\": eq.device_serial_number,\n                        \"redaction_zones\": []\n                    }\n                    if safety_comment:\n                        new_rule[\"comment\"] = safety_comment\n                    missing_configs.append(new_rule)\n\n        # 4. Load PHI Tags Default (if not loaded)\n        phi_tags = self.configuration.phi_tags\n        if not phi_tags:\n            # Load default config for scaffold\n            try:\n                phi_tags = ConfigLoader.load_phi_config()\n            except Exception as e:\n                get_logger().warning(f\"Failed to load research tags: {e}\")\n\n        # 4b. Enhance PHI Tags (Transform to structured defaults)\n        structured_tags = {}\n\n        # Ensure critical tags are present\n        if \"0008,0020\" not in phi_tags:\n            phi_tags[\"0008,0020\"] = \"Study Date\"\n        if \"0010,0040\" not in phi_tags:\n            phi_tags[\"0010,0040\"] = \"Patient Sex\"\n        if \"0010,1010\" not in phi_tags:\n            phi_tags[\"0010,1010\"] = \"Patient Age\"  # Helper\n\n        for tag, val in phi_tags.items():\n            name = val if isinstance(val, str) else val.get(\"name\", \"Unknown\")\n            action = \"REMOVE\"  # Default safety\n\n            # Apply Research-Friendly Smart Defaults\n            if tag == \"0008,0020\":  # Study Date\n                action = \"JITTER\"\n            elif tag == \"0010,0040\":  # Sex\n                action = \"KEEP\"\n            elif tag == \"0010,1010\":  # Age\n                action = \"KEEP\"\n            elif \"Date\" in name or \"Time\" in name:\n                action = \"REMOVE\"  # Times are sensitive\n            elif \"ID\" in name:\n                action = \"REMOVE\"  # IDs are sensitive\n\n            # Preserve existing structure if it was already structured\n            if isinstance(val, dict):\n                structured_tags[tag] = val\n            else:\n                # Minimal Scaffold: Skip tags that are simply REMOVED (covered by Basic profile)\n                # Unless explicitly requested to show all? For now, match tests.\n                if action == \"REMOVE\":\n                    continue\n\n                structured_tags[tag] = {\n                    \"name\": name,\n                    \"action\": action\n                }\n\n        # 5. Construct Unified Data\n        data = {\n            \"version\": \"2.0\",\n            \"privacy_profile\": \"basic\",\n            # No _instructions dict anymore, we use comments!\n            \"phi_tags\": structured_tags,\n            \"date_jitter\": self.configuration.date_jitter,\n            \"remove_private_tags\": self.configuration.remove_private_tags,\n            \"machines\": missing_configs + self.configuration.rules\n        }\n\n        if not missing_configs and not self.configuration.rules:\n            print(\"No machines detected to scaffold.\")\n\n        # Pre-process data to ensure comments are single-line strings\n        # And ensure redaction_zones use FlowList for bracketed style\n        for m in data.get(\"machines\", []):\n            if \"comment\" in m and isinstance(m[\"comment\"], str):\n                # Replace newlines with spaces/semicolons\n                m[\"comment\"] = m[\"comment\"].replace(\"\\n\", \" \").replace(\"\\r\", \"\")\n                # collapse multiple spaces\n                m[\"comment\"] = re.sub(r'\\s+', ' ', m[\"comment\"]).strip()\n\n            if \"redaction_zones\" in m and isinstance(m[\"redaction_zones\"], list):\n                # Wrap inner lists (zones) in FlowList\n                # And assume user wants [[...], [...]] so wrap outer too?\n\n                zones = m[\"redaction_zones\"]\n                new_zones = FlowList()\n                for z in zones:\n                    if isinstance(z, list):\n                        new_zones.append(FlowList(z))\n                    else:\n                        new_zones.append(z)\n                m[\"redaction_zones\"] = new_zones  # Assign flow list wrapper\n\n        try:\n            # Generate YAML string\n            # sort_keys=False ensures order is preserved (machines list)\n            # width=float(\"inf\") prevents line wrapping for long strings\n            yaml_content = yaml.dump(\n                data,\n                sort_keys=False,\n                default_flow_style=False,\n                width=float(\"inf\"))\n\n            # Post-process: Convert \"comment: ...\" into \"# ...\"\n            lines = yaml_content.splitlines()\n            new_lines = []\n            for line in lines:\n                # Simple match for key-value pair\n                match = re.search(r'^(\\s*)comment:\\s*(.*)$', line)\n                if match:\n                    indent = match.group(1)\n                    content = match.group(2).strip()\n\n                    # Check for surrounding quotes and strip them\n                    if content.startswith(\"'\") and content.endswith(\"'\"):\n                        content = content[1:-1]\n                        content = content.replace(\"''\", \"'\")\n                    elif content.startswith('\"') and content.endswith('\"'):\n                        content = content[1:-1]\n                        content = content.replace('\\\\\"', '\"')\n\n                    new_lines.append(f\"{indent}# {content}\")\n                else:\n                    if line.strip().startswith(\n                            \"- \") and len(new_lines) &gt; 0 and new_lines[-1].strip() != \"\":\n                        new_lines.append(\"\")\n\n                    new_lines.append(line)\n\n            # Prepend Header Comments\n            header = \"\"\"# Gantry Privacy Configuration (v2.0)\n# ==========================================\n#\n#\n# privacy_profile: \"basic\"\n#   - Standard profile handling common PHI (Name, ID, etc).\n#   - Set to \"none\" for manual control.\n#\n# phi_tags:\n#   - Define custom overrides here.\n#   - Actions: KEEP, REMOVE, EMPTY, REPLACE, JITTER (SHIFT)\n#\n# date_jitter:\n#   - Range of days to shift dates by (negative = into past).\n#\n# remove_private_tags:\n#   - If true, removes all odd-group tags except Gantry Metadata.\n#\n#\n\"\"\"\n            final_content = header + \"\\n\" + \"\\n\".join(new_lines) + \"\\n\"\n\n            with open(output_path, 'w') as f:\n                f.write(final_content)\n\n            get_logger().info(\n                f\"Scaffolded Unified Config to {output_path} ({\n                    len(missing_configs)} new machines)\")\n            print(f\"Scaffolded Unified Config to {output_path}\")\n        except Exception as e:\n            get_logger().error(f\"Failed to write scaffold: {e}\")\n</code></pre>"},{"location":"api/session/#gantry.session.DicomSession.preview_config","title":"<code>preview_config()</code>","text":"<p>Performs a dry-run of the currently loaded configuration.</p> <p>Checks the active redaction rules against the current session inventory and prints a summary of which instances would be affected (matched) by the rules. Does not modify any data.</p> Source code in <code>gantry/session.py</code> <pre><code>def preview_config(self):\n    \"\"\"\n    Performs a dry-run of the currently loaded configuration.\n\n    Checks the active redaction rules against the current session inventory and\n    prints a summary of which instances would be affected (matched) by the rules.\n    Does not modify any data.\n    \"\"\"\n    if not self.configuration.rules:\n        get_logger().warning(\"No configuration loaded. Use .load_config() first.\")\n        print(\"No configuration loaded. Use .load_config() first.\")\n        return\n\n    print(\"\\n--- Dry Run / Configuration Preview ---\")\n\n    # We need the index to check matches\n    # We instantiate the service just to query the index, not to modify\n    service = RedactionService(self.store, self.store_backend)\n\n    match_count = 0\n\n    for rule in self.configuration.rules:\n        serial = rule.get(\"serial_number\", \"UNKNOWN\")\n        model = rule.get(\"model_name\", \"Unknown Model\")\n        zones = rule.get(\"redaction_zones\", [])\n\n        # check matches in store\n        targets = service.index.get_by_machine(serial)\n\n        if targets:\n            count = len(targets)\n            match_count += count\n            print(f\"MATCH: '{serial}' ({model})\")\n            print(f\"    - Found {count} images in current session.\")\n            print(f\"    - Actions: Will apply {len(zones)} redaction zones.\")\n        else:\n            print(f\"NO MATCH: '{serial}'. Rule loaded, but no images found.\")\n\n    print(f\"\\nSummary: Execution will modify approximately {match_count} images.\")\n    print(\"---------------------------------------\")\n</code></pre>"},{"location":"api/session/#gantry.session.DicomSession.scan_pixel_content","title":"<code>scan_pixel_content(serial_number=None)</code>","text":"<p>Scans instances in the session for burned-in text using OCR.</p> <p>Performs \"Intelligent Verification\":. Only scans instances belonging to machines (Serial Numbers) that are present in the current configuration. Unconfigured machines are skipped.</p> <p>Parameters:</p> Name Type Description Default <code>serial_number</code> <code>str</code> <p>If provided, restricts the scan to ONLY                            machines with this serial number.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>PhiReport</code> <code>PhiReport</code> <p>A report containing findings of filtered (uncovered) burned-in text.</p> Source code in <code>gantry/session.py</code> <pre><code>def scan_pixel_content(self, serial_number: str = None) -&gt; \"PhiReport\":\n    \"\"\"\n    Scans instances in the session for burned-in text using OCR.\n\n    Performs \"Intelligent Verification\":.\n    Only scans instances belonging to machines (Serial Numbers) that are present\n    in the current configuration. Unconfigured machines are skipped.\n\n    Args:\n        serial_number (str, optional): If provided, restricts the scan to ONLY\n                                       machines with this serial number.\n\n    Returns:\n        PhiReport: A report containing findings of filtered (uncovered) burned-in text.\n    \"\"\"\n    get_logger().info(\"Scanning pixel content for text (OCR)...\")\n    print(\"Scanning pixel content for text (OCR)...\")\n\n    # Gather all instances with their equipment context\n    current_rules = self.configuration.rules\n\n    # Build set of valid serials from config\n    configured_serials = {r.get(\"serial_number\") for r in current_rules if r.get(\"serial_number\")}\n\n    worker_items = []\n    skipped_count = 0\n\n    for p in self.store.patients:\n        for st in p.studies:\n            for se in st.series:\n                equip = se.equipment\n                if not equip or not equip.device_serial_number:\n                    skipped_count += len(se.instances)\n                    continue\n\n                sn = equip.device_serial_number\n\n                # Filter 1: Must be in Config\n                # We check if we have a rule for this serial\n                matched_rule = None\n                for r in current_rules:\n                    if r.get(\"serial_number\") == sn:\n                        matched_rule = r\n                        break\n\n                if not matched_rule:\n                    skipped_count += len(se.instances)\n                    continue\n\n                # Rule Refinement: Skip if NO ZONES defined (Scaffolded state)\n                # Unless user explicitly wants to scan? No, user req says skip.\n                if not matched_rule.get(\"redaction_zones\"):\n                     # Log once per serial?\n                     # For now just skip\n                     skipped_count += len(se.instances)\n                     continue\n\n                # Filter 2: Explicit User Filter\n                if serial_number and sn != serial_number:\n                    continue\n\n                for inst in se.instances:\n                    worker_items.append((inst, equip, current_rules))\n\n    if not worker_items:\n        msg = \"No matching configured instances found to scan.\"\n        if skipped_count &gt; 0:\n            msg += f\" (Skipped {skipped_count} unconfigured instances)\"\n        print(msg)\n        return PhiReport([])\n\n    results = run_parallel(_verify_worker, worker_items, desc=\"OCR Verification\")\n\n    all_findings = []\n    for r in results:\n        all_findings.extend(r)\n\n    print(f\"OCR Scan Complete. Found {len(all_findings)} suspicious regions (Uncovered).\")\n    return PhiReport(all_findings)\n</code></pre>"},{"location":"api/session/#gantry.session.DicomSession.discover_redaction_zones","title":"<code>discover_redaction_zones(serial_number, sample_size=50)</code>","text":"<p>Analyzes instances of a specific machine to discover potential redaction zones.</p> <p>Parameters:</p> Name Type Description Default <code>serial_number</code> <code>str</code> <p>The serial number of the machine to target.</p> required <code>sample_size</code> <code>int</code> <p>Max number of instances to analyze (for speed).</p> <code>50</code> <p>Returns:</p> Type Description <code>List[List[int]]</code> <p>List[List[int]]: A list of suggested zones [x, y, w, h].</p> Source code in <code>gantry/session.py</code> <pre><code>def discover_redaction_zones(self, serial_number: str, sample_size: int = 50) -&gt; List[List[int]]:\n    \"\"\"\n    Analyzes instances of a specific machine to discover potential redaction zones.\n\n    Args:\n        serial_number (str): The serial number of the machine to target.\n        sample_size (int): Max number of instances to analyze (for speed).\n\n    Returns:\n        List[List[int]]: A list of suggested zones [x, y, w, h].\n    \"\"\"\n    get_logger().info(f\"Discovering zones for {serial_number}...\")\n\n    # 1. Gather instances\n    target_instances = []\n    for p in self.store.patients:\n        for st in p.studies:\n            for se in st.series:\n                if se.equipment and se.equipment.device_serial_number == serial_number:\n                    target_instances.extend(se.instances)\n\n    if not target_instances:\n        print(f\"No instances found for serial {serial_number}\")\n        return []\n\n    print(f\"Found {len(target_instances)} instances. Using sample of {min(len(target_instances), sample_size)}.\")\n\n    # 2. Sample\n    import random\n    if len(target_instances) &gt; sample_size:\n        sample = random.sample(target_instances, sample_size)\n    else:\n        sample = target_instances\n\n    # 3. Analyze (Parallel?)\n    # Discovery logic is currently serial inside discover_zones?\n    # Actually ZoneDiscoverer.discover_zones iterates list and calls analyze_pixels.\n    # We should parallelize this part if heavy.\n\n    # Let's re-use run_parallel logic? \n    # But ZoneDiscoverer expects list.\n    # Let's map analyze_pixels then pass results to merger.\n\n    raw_regions_lists = run_parallel(pixel_analysis.analyze_pixels, sample, desc=\"Discovery Scan\")\n\n    # Flatten\n    all_regions = []\n    for lst in raw_regions_lists:\n        all_regions.extend(lst)\n\n    # 4. Merge\n    # We need to construct a dummy instance list? No, we need regions.\n    # ZoneDiscoverer logic was: takes instances -&gt; analyzes -&gt; merges.\n    # We just did analysis.\n    # Let's modify discovery usage or extract merge logic.\n\n    # Access internal merge method or refactor ZoneDiscoverer to accept regions?\n    # Since I just wrote it, I know I can just call _merge_overlapping_boxes with box lists.\n    # Boxes needed as [x,y,w,h]\n\n    boxes = [list(r.box) for r in all_regions]\n\n    # We need to access the static method. ideally public.\n    # I'll use the private one for now as it's in same package context effectively.\n    merged = ZoneDiscoverer._merge_overlapping_boxes(boxes)\n\n    # Filter tiny\n    final_zones = [b for b in merged if b[2] &gt; 5 and b[3] &gt; 5]\n\n    print(f\"Discovery complete. Suggested {len(final_zones)} zones.\")\n    return final_zones\n</code></pre>"},{"location":"api/session/#gantry.session.DicomSession.auto_remediate_config","title":"<code>auto_remediate_config(report)</code>","text":"<p>Analyzes the provided OCR report and automatically updates the session's configuration to fix detected leaks (by expanding zones or adding new ones).</p> <p>Parameters:</p> Name Type Description Default <code>report</code> <code>PhiReport</code> <p>The findings from .scan_pixel_content()</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of rules updated.</p> Source code in <code>gantry/session.py</code> <pre><code>def auto_remediate_config(self, report: \"PhiReport\") -&gt; int:\n    \"\"\"\n    Analyzes the provided OCR report and automatically updates the session's\n    configuration to fix detected leaks (by expanding zones or adding new ones).\n\n    Args:\n        report (PhiReport): The findings from .scan_pixel_content()\n\n    Returns:\n        int: The number of rules updated.\n    \"\"\"\n    get_logger().info(\"Analyzing report for auto-remediation...\")\n\n    suggestions = ConfigAutomator.suggest_config_updates(report, self.configuration)\n\n    if not suggestions:\n        print(\"No configuration updates suggested.\")\n        return 0\n\n    print(f\"Generated {len(suggestions)} suggestions for config updates.\")\n\n    count = ConfigAutomator.apply_suggestions(self, suggestions)\n\n    if count &gt; 0:\n        print(f\"Applied {count} updates to in-memory configuration.\")\n        print(\"Tip: Run .scan_pixel_content() again to verify fix, then .configuration.save_config() to persist.\")\n\n    return count\n\n    return count\n</code></pre>"},{"location":"api/session/#gantry.session.DicomSession.examine","title":"<code>examine()</code>","text":"<p>Prints a summary of the session contents and equipment.</p> Source code in <code>gantry/session.py</code> <pre><code>def examine(self):\n    \"\"\"Prints a summary of the session contents and equipment.\"\"\"\n    get_logger().info(\"Generating inventory report.\")\n\n    # 1. Object Counts\n    n_p = len(self.store.patients)\n    n_st = sum(len(p.studies) for p in self.store.patients)\n    n_se = sum(len(st.series) for p in self.store.patients for st in p.studies)\n    n_i = sum(len(se.instances)\n              for p in self.store.patients for st in p.studies for se in st.series)\n\n    # 2. Equipment Grouping\n    eq_counts = {}  # (man, model) -&gt; count\n\n    for p in self.store.patients:\n        for st in p.studies:\n            for se in st.series:\n                for inst in se.instances:\n                    if se.equipment:\n                        key = (se.equipment.manufacturer, se.equipment.model_name)\n                        eq_counts[key] = eq_counts.get(key, 0) + 1\n\n    print(f\"\\nInventory Summary:\")\n    print(f\" Patients:  {n_p}\")\n    print(f\" Studies:   {n_st}\")\n    print(f\" Series:    {n_se}\")\n    print(f\" Instances: {n_i}\")\n\n    print(f\"\\nEquipment Inventory:\")\n    if not eq_counts:\n        print(\" No equipment metadata found.\")\n    else:\n        for (man, mod), count in sorted(eq_counts.items()):\n            print(f\" - {man} - {mod} (Count: {count})\")\n</code></pre>"},{"location":"api/session/#gantry.session.DicomSession.compact","title":"<code>compact()</code>","text":"<p>Manually triggers Sidecar Compaction to reclaim disk space. Rewrites the _pixels.bin file, removing orphaned data from deleted or redacted instances. WARNING: This is an expensive I/O operation.</p> Source code in <code>gantry/session.py</code> <pre><code>def compact(self):\n    \"\"\"\n    Manually triggers Sidecar Compaction to reclaim disk space.\n    Rewrites the _pixels.bin file, removing orphaned data from deleted or redacted instances.\n    WARNING: This is an expensive I/O operation.\n    \"\"\"\n    if hasattr(self, 'store_backend'):\n        print(\"Beginning Sidecar Compaction (this may take a while)...\")\n\n        # 1. Sync DB so compaction knows true state\n        self.save(sync=True)\n\n        # 2. Compact and get updates\n        # Returns Dict[sop_instance_uid, (new_offset, new_length)]\n        updates = self.store_backend.compact_sidecar()\n\n        if not updates:\n            print(\"Compaction finished (no changes or empty).\")\n            return\n\n        # 3. Patch In-Memory Instances (Preserve References)\n        print(f\"Updating {len(updates)} in-memory instances...\")\n        count = 0\n\n        # Optimization: Pre-check if we have SidecarPixelLoader imported\n\n\n        # We must traverse the whole graph.\n        # DicomStore doesn't index by UID (yet).\n        for p in self.store.patients:\n            for st in p.studies:\n                for se in st.series:\n                    for inst in se.instances:\n                        if inst.sop_instance_uid in updates:\n                            new_off, new_len = updates[inst.sop_instance_uid]\n\n                            # Update Loader\n                            if inst._pixel_loader and isinstance(\n                                    inst._pixel_loader, SidecarPixelLoader):\n                                inst._pixel_loader.offset = new_off\n                                inst._pixel_loader.length = new_len\n                                count += 1\n\n                            # Note: If inst._pixel_loader is None (e.g. loaded from original DICOM file),\n                            # it doesn't use sidecar, so no update needed.\n                            # If it has pixel_array loaded (RAM), it's fine.\n                            # If we unload() later, we need correct loader.\n                            # BUT if it has pixel_array, does it have a loader?\n                            # persist_pixel_data ensures loader is created.\n                            # So if it was persisted, it has a loader.\n\n        print(f\"Patched {count} active objects.\")\n\n    else:\n        print(\"Persistence backend does not support compaction.\")\n</code></pre>"},{"location":"api/session/#gantry.session.DicomSession.release_memory","title":"<code>release_memory()</code>","text":"<p>Attempts to release memory by unloading pixel data from all instances. Safe to call: only unloads data that is safely persisted (on disk or sidecar). Useful after running extensive redaction or export operations.</p> Source code in <code>gantry/session.py</code> <pre><code>def release_memory(self):\n    \"\"\"\n    Attempts to release memory by unloading pixel data from all instances.\n    Safe to call: only unloads data that is safely persisted (on disk or sidecar).\n    Useful after running extensive redaction or export operations.\n    \"\"\"\n    get_logger().info(\"Releasing memory (RAM cleanup)...\")\n    count = 0\n    freed = 0\n\n    # Count total instances first for progress bar\n    total_instances = sum(len(se.instances)\n                          for p in self.store.patients for st in p.studies for se in st.series)\n\n    if total_instances == 0:\n        return\n\n    with tqdm(total=total_instances, desc=\"Releasing Memory\", unit=\"img\") as pbar:\n        for p in self.store.patients:\n            for st in p.studies:\n                for se in st.series:\n                    for inst in se.instances:\n                        count += 1\n                        if inst.unload_pixel_data():\n                            freed += 1\n                        pbar.update(1)\n\n    get_logger().info(\n        f\"Memory release complete. Unloaded pixels for {freed}/{count} instances.\")\n    if freed &gt; 0:\n        print(f\"Memory Cleanup: Released {freed} images from RAM.\")\n</code></pre>"}]}